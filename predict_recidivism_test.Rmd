---
title: "predict_recidivism"
author: "Beau Coker"
date: "11/5/2018"
output: html_document
---

Here, we use out-of-box ML methods to predict recidivism (currently, xgBoost)
```{r}
library(tidyverse)

source('util.R')
load("expanded_features.Rdata")
load("compas_psa.Rdata")
```

### Prepare data 

```{r}
### Add useful columns to features and apply row filters used for all models
features_filt = features_before_on %>%
  inner_join(
    data_before %>% 
      select(person_id, screening_date, people) %>%
      unnest() %>%
      select(person_id, screening_date, race, sex, name),
    by = c("person_id","screening_date")
  ) %>%
  inner_join(features_on, by = c("person_id","screening_date")) %>%
  inner_join(
    psa_features%>%
      select(-c(p_current_age,p_prison)), 
    by = c("person_id","screening_date"))%>%
  inner_join(outcomes, by = c("person_id","screening_date")) %>%
  filter(`Risk of Recidivism_decile_score` != -1, `Risk of Violence_decile_score` != -1) %>% # Filter 1
  filter(!is.na(current_offense_date)) %>% # Filter 3
  filter(screening_date <= current_offense_date_limit) %>% # Filter 4
  mutate(recid_use = as.factor(recid), # Select recidivism or violent recidivism to use in this script 
         decile_use = `Risk of Recidivism_decile_score`) # Select recidivism or violent recidivism decile score to use in this script

## Select features and round count features
train = features_filt %>%
  transmute(
    #COMPAS Risk of Recidivism Features
    p_current_age,
    p_age_first_offense,
    p_charge,
    p_jail30 = pmin(p_jail30,5),
    p_prison = pmin(p_prison,5),
    p_probation = pmin(p_probation,5),
    
    #COMPAS Risk of violent recidivism features
    p_juv_fel_count,
    p_felprop_violarrest,
    p_murder_arrest,
    p_felassault_arrest,
    p_misdemassault_arrest,
    p_famviol_arrest,
    p_sex_arrest,
    p_weapons_arrest,
    
    #Misc Features
    p_arrest,
    p_property,
    p_traffic,
    p_drug,
    p_dui,
    p_domestic,
    p_stalking,
    p_voyeurism,
    p_fraud,
    p_stealing,
    p_trespass,
    recid_use)

# train = train[1:100,] # Comment for full training set. This is just for testing.
```


### Train xgboost

```{r}
library(xgboost)
```


```{r}
## Format for xgboost
train_xgb = xgb.DMatrix(
  "data" = train %>% select(-recid_use) %>% as.matrix(),
  "label" = train %>% select(recid_use) %>% as.matrix()
)

# Specify each parameter as a single value or a vector of values
# Each combination will be tested
param_xgb <- list(
  objective = "binary:logistic",
  eta = c(.05,.1),
  gamma = c(.5), 
  max_depth = c(2),
  min_child_weight = c(5),
  subsample = c(1),
  colsample_bytree = c(1),
  early_stopping_rounds=50
)

param_xgb = expand.grid(param_xgb) # Each row is a set of parameters to be cross validated

# Only one value for each of these parameters is allowed
setup_xgb = list(
  nrounds=10000,
  nfold=5
)
```

```{r}
set.seed(2812)
out = fit_xgb_auc(train_xgb, param_xgb, setup_xgb)
```

```{r}
out$performance
```

### Train BART

```{r}
options(java.parameters = "-Xmx2g") 
library(bartMachine)
```


```{r}
param_bart = expand.grid(list(
  num_trees = c(50, 75),
  alpha = 0.95, 
  beta = 2, 
  k = c(2), 
  q = 0.9, 
  nu = 3)
)

setup_bart = list(
  nfold=2
)

out_bart = train %>%
  mutate(y = as.factor(recid_use)) %>%
  select(-recid_use) %>%
  fit_bart_auc(param_bart,setup_bart)
```

```{r}
out_bart$performance
```


```{r}
plot_convergence_diagnostics(out_bart$mdl_best)
```

```{r}
investigate_var_importance(out_bart$mdl_best, num_replicates_for_avg = 20)
```