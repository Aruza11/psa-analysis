{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is now:  C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning:\n",
      "\n",
      "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../../../')\n",
    "print(\"Current working directory is now: \", os.getcwd())\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "import utils.interpretable_functions as interpret\n",
    "import utils.RiskSLIM as slim\n",
    "import utils.stumps as stumps\n",
    "import utils.Corel as Corel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# restore saved variables\n",
    "%store -r summary_violent2_FL_interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART & EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_data.csv\")\n",
    "x = data.loc[:,:'five_year']\n",
    "y = data['recid_violent2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [0]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [0]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [7]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [22]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [33]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [0]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [0]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [0]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [2]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### CART\n",
    "depth = [1,2,3]\n",
    "impurity = [0.001, 0.003]\n",
    "split = [2,3,4]\n",
    "cart_summary = interpret.CART(X=x,\n",
    "                         Y=y,\n",
    "                         depth=depth,\n",
    "                         split=split,\n",
    "                         impurity=impurity, \n",
    "                         seed = 816)\n",
    "\n",
    "#### GAM\n",
    "estimators = [60,80,100]\n",
    "depth = [1,2]\n",
    "learning_rate = [0.01]\n",
    "holdout_split = [0.7, 0.9]\n",
    "ebm_summary = interpret.EBM(X=x,\n",
    "                       Y=y,\n",
    "                       learning_rate = learning_rate,\n",
    "                       depth = depth,\n",
    "                       estimators=estimators,\n",
    "                       holdout_split=holdout_split,\n",
    "                       seed=816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6108315420562821, 0.05540142818992251)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6753137344731238, 0.03499226291170741)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load whole data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_stumps.csv\")\n",
    "X_stumps, Y_stumps = data.loc[:,:'five_year>=1'], data['recid_violent2'].values\n",
    "Y_stumps[Y_stumps == -1] = 0\n",
    "cols = X_stumps.columns[3:]\n",
    "\n",
    "## load train & test data\n",
    "train_stumps = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_train_stumps.csv\")\n",
    "test_stumps = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_test_stumps.csv\")\n",
    "X_train_stumps, Y_train_stumps = train_stumps.loc[:,:'five_year>=1'], train_stumps['recid_violent2'].values\n",
    "X_test_stumps, Y_test_stumps = test_stumps.loc[:,:'five_year>=1'], test_stumps['recid_violent2'].values\n",
    "Y_train_stumps[Y_train_stumps == -1] = 0\n",
    "Y_test_stumps[Y_test_stumps == -1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [171]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [150]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [154]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [178]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:84: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [154]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stump_summary = stumps.stump_cv(X = X_stumps, \n",
    "                                Y = Y_stumps, \n",
    "                                columns=cols, \n",
    "                                c_grid={'C': [0.01, 0.03, 0.05, 0.07, 0.09, 0.11, 0.13, 0.15, 0.17, 0.19]}, \n",
    "                                seed = 816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'C': 0.17}, {'C': 0.11}, {'C': 0.15}, {'C': 0.13}, {'C': 0.09}],\n",
       " 0.6823710656672844,\n",
       " 0.046907038728775996)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stump_summary['best_params'], np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6459593609430743,\n",
       " 0.6963713080168776,\n",
       " 0.6780527271292129,\n",
       " 0.7221804511278196,\n",
       " 0.6692914811194379]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stump_summary['holdout_test_auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Stump Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_stump_model = stumps.stump_model(X_train_stumps, \n",
    "                                      Y_train_stumps, \n",
    "                                      X_test_stumps, \n",
    "                                      Y_test_stumps, \n",
    "                                      c=0.13, \n",
    "                                      columns=cols, \n",
    "                                      seed=816)\n",
    "len(best_stump_model['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\begin{tabular}{|l|r|r|} \\hline\n",
      "1. sex>=1 & 29.4 & +... \\ \\hline\n",
      "2. p_current_age>=19 & 36.2 & -... \\ \\hline\n",
      "3. p_current_age>=23 & 3.9 & -... \\ \\hline\n",
      "4. p_current_age>=31 & 33.0 & -... \\ \\hline\n",
      "5. p_current_age>=33 & 25.5 & -... \\ \\hline\n",
      "6. p_age_first_offense<=19 & 8.3 & +... \\ \\hline\n",
      "7. p_age_first_offense<=25 & 14.4 & -... \\ \\hline\n",
      "8. p_prison>=1 & 5.1 & +... \\ \\hline\n",
      "9. p_prison>=2 & 15.9 & +... \\ \\hline\n",
      "10. p_felassault_arrest>=1 & 8.3 & -... \\ \\hline\n",
      "11. p_misdemassault_arrest>=1 & 6.6 & +... \\ \\hline\n",
      "12. current_violent>=1 & 48.7 & +... \\ \\hline\n",
      "13. pending_charge>=6 & 10.4 & -... \\ \\hline\n",
      "14. prior_conviction_F>=4 & 1.1 & -... \\ \\hline\n",
      "15. prior_conviction_M>=5 & 2.4 & +... \\ \\hline\n",
      "16. prior_conviction_M>=7 & 20.4 & +... \\ \\hline\n",
      "17. violent_conviction>=1 & 6.4 & +... \\ \\hline\n",
      "18. violent_conviction>=2 & 8.4 & +... \\ \\hline\n",
      "19. violent_conviction>=3 & 31.0 & +... \\ \\hline\n",
      "20. violent_conviction>=4 & 22.3 & +... \\ \\hline\n",
      "21. violent_conviction>=5 & 22.5 & +... \\ \\hline\n",
      "22. total_convictions>=7 & 22.1 & +... \\ \\hline\n",
      "23. p_arrest>=5 & 0.6 & -... \\ \\hline\n",
      "24. p_property>=5 & 28.1 & +... \\ \\hline\n",
      "25. p_drug>=2 & 2.3 & -... \\ \\hline\n",
      "26. p_drug>=4 & 9.6 & -... \\ \\hline\n",
      "27. p_dui>=1 & 28.5 & -... \\ \\hline\n",
      "28. p_trespass>=2 & 14.0 & -... \\ \\hline\n",
      "29. years_since_last_crime>=1 & 15.7 & -... \\ \\hline\n",
      "30. years_since_last_crime>=1.5 & 10.5 & -... \\ \\hline\n",
      "31. years_since_last_crime>=3 & 19.7 & -... \\ \\hline\n",
      "32. years_since_last_crime>=4 & 27.1 & -... \\ \\hline\n",
      "33. Intercept & 0.0 & -... \\ \\hline\n",
      "\textbf{ADD POINTS FROM ROWS 1 TO 33}  &  \textbf{SCORE} & = ..... \\ \\hline\n",
      "\\multicolumn{3}{l}{Pr(Y = 1) = exp(score/100) / (1 + exp(score/100))} \\ \\hline\n"
     ]
    }
   ],
   "source": [
    "stumps.latex_stump_table(best_stump_model['coefs'], \n",
    "                         best_stump_model['features'], \n",
    "                         best_stump_model['intercept'], \n",
    "                         best_stump_model['dictionary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RiskSLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load stumps data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_stumps.csv\")\n",
    "x, y = data.loc[:,:'five_year>=1'], data['recid_violent2'].values\n",
    "cols = x.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train on best param chosen by Lasso Stumps from above\n",
    "x_train = x.copy().drop(['race', 'person_id', 'screening_date'], axis=1)\n",
    "lasso = LogisticRegression(class_weight='balanced', solver='liblinear', penalty='l1', C=0.13, random_state=816).fit(x_train,y)\n",
    "selected_features = cols[lasso.coef_[0] != 0].tolist()\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset features\n",
    "if 'sex>=1' in selected_features:\n",
    "    selected_features = ['recid_violent2', 'person_id', 'screening_date', 'race'] + selected_features\n",
    "    indicator = 1\n",
    "else:\n",
    "    selected_features = ['recid_violent2', 'person_id', 'screening_date', 'race', 'sex>=1'] + selected_features\n",
    "    indicator = 0\n",
    "    \n",
    "sub_data = data[selected_features]\n",
    "sub_X, sub_Y = sub_data.iloc[:,1:], sub_data.iloc[:,0].values\n",
    "sub_X.insert(0, '(Intercept)', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "09/30/19 @ 10:25 AM | 1701 rows in lookup table\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | runnning initialization procedure\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | CPA produced 2 cuts\n",
      "09/30/19 @ 10:25 AM | running naive rounding on 70 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4707\n",
      "09/30/19 @ 10:25 AM | rounding produced 4 integer solutions\n",
      "09/30/19 @ 10:25 AM | best objective value is 0.4864\n",
      "09/30/19 @ 10:25 AM | running sequential rounding on 70 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4707\n",
      "09/30/19 @ 10:25 AM | sequential rounding produced 5 integer solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4863\n",
      "09/30/19 @ 10:25 AM | polishing 9 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4863\n",
      "09/30/19 @ 10:25 AM | polishing produced 5 integer solutions\n",
      "09/30/19 @ 10:25 AM | initialization produced 7 feasible solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4863\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | completed initialization procedure\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | 1701 rows in lookup table\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               200\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.4681533623292915\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.48627294869286158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "09/30/19 @ 10:25 AM | adding 249 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.4863.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 42 rows, 84 columns, and 163 nonzeros.\n",
      "Reduced MIP has 40 binaries, 42 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.00 sec. (0.10 ticks)\n",
      "Probing time = 0.00 sec. (0.03 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.05 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.4863        0.4681             3.73%\n",
      "      0     0        0.4682     1        0.4863        0.4682        1    3.73%\n",
      "      0     0        0.4682     1        0.4863      Fract: 1        2    3.73%\n",
      "      0     0        0.4682     5        0.4863      Fract: 1        3    3.73%\n",
      "      0     2        0.4682     7        0.4863        0.4682        3    3.73%                        0             0\n",
      "Elapsed time = 0.09 sec. (3.40 ticks, tree = 0.01 MB, solutions = 1)\n",
      "   1620   688        cutoff              0.4863        0.4682     6443    3.73%          rho_23 U   1620    525     16\n",
      "*  2210+  853                            0.4850        0.4682             3.48%\n",
      "*  2290+  885                            0.4850        0.4682             3.48%\n",
      "*  2335   823      integral     0        0.4825        0.4682     9540    2.97%           rho_1 U   2335   2332     21\n",
      "   3046  1039        0.4698    13        0.4825        0.4682    13907    2.97%           rho_0 D   3046   3044     21\n",
      "   3734  1278        0.4745     7        0.4825        0.4682    18455    2.97%          rho_10 D   3734   3732     18\n",
      "*  3976  1253      integral     0        0.4806        0.4682    19738    2.60%          rho_25 D   3976   3975     28\n",
      "   4580  1406        0.4682    11        0.4806        0.4682    23896    2.60%          rho_24 D   4580   4579     16\n",
      "   5205  1584        cutoff              0.4806        0.4682    27825    2.60%           rho_9 U   5205   5203     19\n",
      "   5770  1775        0.4771     4        0.4806        0.4682    32272    2.60%          rho_25 D   5770   5769     16\n",
      "*  5869  1779      integral     0        0.4805        0.4682    32823    2.57%          rho_17 D   5869   5868     27\n",
      "   8013  2412        0.4731     6        0.4805        0.4682    47899    2.57%           rho_0 U   8013   8012     16\n",
      "Elapsed time = 1.89 sec. (2700.09 ticks, tree = 0.83 MB, solutions = 6)\n",
      "  10399  2920        0.4768    10        0.4805        0.4698    62620    2.23%           rho_8 U  10399   6033     20\n",
      "  12981  3064        0.4714    12        0.4805        0.4714    75410    1.89%          rho_10 D  12981   7636     21\n",
      "  15469  2982        0.4804     1        0.4805        0.4730    87676    1.56%          rho_12 D  15469  15468     27\n",
      "  17961  2668        cutoff              0.4805        0.4746    99150    1.22%          rho_10 U  17961  17960     19\n",
      "* 18260+ 2584                            0.4805        0.4748             1.18%\n",
      "  20347  2081        0.4803     7        0.4805        0.4763   109681    0.88%          rho_17 U  20347  12633     24\n",
      "  23000   709        cutoff              0.4805        0.4787   119929    0.36%           rho_1 U  23000   2321     18\n",
      "\n",
      "Implied bound cuts applied:  1\n",
      "Gomory fractional cuts applied:  2\n",
      "User cuts applied:  434\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.09 sec. (3.45 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    5.86 sec. (8687.83 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    5.95 sec. (8691.29 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-4 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| sex>=1                                       |         1 points |   + ..... |\n",
      "| p_age_first_offense<=22                      |         1 points |   + ..... |\n",
      "| current_violent>=1                           |         1 points |   + ..... |\n",
      "| prior_conviction_M>=7                        |         1 points |   + ..... |\n",
      "| violent_conviction>=5                        |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 5                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "model_id, score_thresholds 0 {'rank_abs': [8]}\n",
      "get_disparity_predefined_group()\n",
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "09/30/19 @ 10:25 AM | 1701 rows in lookup table\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | runnning initialization procedure\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/30/19 @ 10:25 AM | CPA produced 2 cuts\n",
      "09/30/19 @ 10:25 AM | running naive rounding on 76 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4836\n",
      "09/30/19 @ 10:25 AM | rounding produced 5 integer solutions\n",
      "09/30/19 @ 10:25 AM | best objective value is 0.5028\n",
      "09/30/19 @ 10:25 AM | running sequential rounding on 76 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4836\n",
      "09/30/19 @ 10:25 AM | sequential rounding produced 4 integer solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4993\n",
      "09/30/19 @ 10:25 AM | polishing 9 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4993\n",
      "09/30/19 @ 10:25 AM | polishing produced 5 integer solutions\n",
      "09/30/19 @ 10:25 AM | initialization produced 9 feasible solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4993\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | completed initialization procedure\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | 1701 rows in lookup table\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               200\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.48220545938705484\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.49929308670760819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "09/30/19 @ 10:25 AM | adding 215 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.4993.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 42 rows, 84 columns, and 163 nonzeros.\n",
      "Reduced MIP has 40 binaries, 42 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.02 sec. (0.10 ticks)\n",
      "Probing time = 0.00 sec. (0.03 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.05 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.4993        0.4822             3.42%\n",
      "      0     0        0.4822     1        0.4993        0.4822        1    3.42%\n",
      "      0     0        0.4822     1        0.4993      Fract: 1        2    3.42%\n",
      "      0     0        0.4822     4        0.4993      Fract: 1        4    3.42%\n",
      "      0     2        0.4822     7        0.4993        0.4822        4    3.42%                        0             0\n",
      "Elapsed time = 0.09 sec. (3.34 ticks, tree = 0.01 MB, solutions = 1)\n",
      "   1520   554        0.4958     9        0.4993        0.4822     6450    3.42%           rho_0 D   1520   1518     22\n",
      "   2400   902        0.4861     7        0.4993        0.4822    11074    3.42%           rho_1 U   2400   2364     13\n",
      "   3129  1180        cutoff              0.4993        0.4822    15144    3.42%           rho_2 D   3129   3128     24\n",
      "   3780  1435        0.4868     6        0.4993        0.4822    19227    3.42%          rho_24 D   3780   3779     17\n",
      "   4437  1751        0.4822     8        0.4993        0.4822    23550    3.42%          rho_15 U   4437   4341     10\n",
      "   5073  1968        0.4904     9        0.4993        0.4822    27290    3.42%          rho_15 U   5073    458     12\n",
      "   5662  2208        cutoff              0.4993        0.4822    30927    3.42%          rho_27 U   5662   5660     24\n",
      "   6254  2431        0.4884     9        0.4993        0.4822    34599    3.42%          rho_30 D   6254   6252     22\n",
      "   6813  2615        0.4836    11        0.4993        0.4822    37954    3.42%          rho_36 U   6813   4237     16\n",
      "*  8886  3338      integral     0        0.4985        0.4822    51066    3.27%           rho_3 D   8886   8885     27\n",
      "Elapsed time = 2.17 sec. (3051.42 ticks, tree = 1.07 MB, solutions = 2)\n",
      "*  9520+ 3226                            0.4959        0.4822             2.77%\n",
      "* 10031  3414      integral     0        0.4959        0.4822    58967    2.77%          rho_12 D  10031  10030     18\n",
      "  12098  4021        0.4907     9        0.4959        0.4822    72280    2.77%           rho_9 D  12098  12097     17\n",
      "  14101  4536        cutoff              0.4959        0.4830    85448    2.62%          rho_27 U  14101  14100     20\n",
      "  16275  4832        0.4918     5        0.4959        0.4842    96695    2.38%          rho_16 U  16275   8439     13\n",
      "  18554  5125        0.4953     7        0.4959        0.4852   108424    2.17%           rho_0 D  18554  18553     14\n",
      "  20871  5388        0.4926     6        0.4959        0.4860   119849    2.00%          rho_30 D  20871  20869     18\n",
      "  23132  5490        0.4890     6        0.4959        0.4868   130554    1.84%          rho_30 D  23132  20340     19\n",
      "  25400  5452        0.4884     4        0.4959        0.4877   141302    1.67%          rho_10 D  25400  21711     17\n",
      "  27610  5366        0.4916     5        0.4959        0.4884   151788    1.53%           rho_8 D  27610  27608     14\n",
      "  29812  5197        0.4946     7        0.4959        0.4891   162159    1.39%          rho_16 U  29812  18572     16\n",
      "Elapsed time = 6.66 sec. (12185.02 ticks, tree = 1.80 MB, solutions = 4)\n",
      "  31997  4932        0.4913     9        0.4959        0.4897   172400    1.25%           rho_3 D  31997  31995     28\n",
      "  34191  4566        0.4924    11        0.4959        0.4905   182216    1.11%          rho_24 D  34191  30791     23\n",
      "  36369  4037        cutoff              0.4959        0.4913   191843    0.94%          rho_10 D  36369  36367     20\n",
      "  38677  3207        cutoff              0.4959        0.4923   201413    0.74%          rho_27 U  38677  12374     23\n",
      "  41097  1951        cutoff              0.4959        0.4935   211018    0.49%          rho_12 D  41097  41096     23\n",
      "* 43156   345      integral     0        0.4959        0.4954   217415    0.12%          rho_12 D  43156  43155     25\n",
      "\n",
      "Gomory fractional cuts applied:  1\n",
      "User cuts applied:  510\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.09 sec. (3.40 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    9.06 sec. (17901.67 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    9.16 sec. (17905.07 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-3 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| p_age_first_offense<=22                      |         1 points |   + ..... |\n",
      "| current_violent>=1                           |         1 points |   + ..... |\n",
      "| prior_conviction_M>=7                        |         1 points |   + ..... |\n",
      "| p_property>=5                                |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 4                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "model_id, score_thresholds 0 {'rank_abs': [13]}\n",
      "get_disparity_predefined_group()\n",
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "09/30/19 @ 10:25 AM | 1701 rows in lookup table\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | runnning initialization procedure\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/30/19 @ 10:25 AM | CPA produced 2 cuts\n",
      "09/30/19 @ 10:25 AM | running naive rounding on 71 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4732\n",
      "09/30/19 @ 10:25 AM | rounding produced 5 integer solutions\n",
      "09/30/19 @ 10:25 AM | best objective value is 0.4924\n",
      "09/30/19 @ 10:25 AM | running sequential rounding on 71 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4732\n",
      "09/30/19 @ 10:25 AM | sequential rounding produced 5 integer solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4889\n",
      "09/30/19 @ 10:25 AM | polishing 10 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4889\n",
      "09/30/19 @ 10:25 AM | polishing produced 5 integer solutions\n",
      "09/30/19 @ 10:25 AM | initialization produced 10 feasible solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4889\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | completed initialization procedure\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | 1701 rows in lookup table\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               200\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.47193512727580789\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.48888210788520364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "09/30/19 @ 10:25 AM | adding 215 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.4889.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 42 rows, 84 columns, and 163 nonzeros.\n",
      "Reduced MIP has 40 binaries, 42 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.00 sec. (0.10 ticks)\n",
      "Probing time = 0.00 sec. (0.03 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.02 sec. (0.05 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.4889        0.4719             3.47%\n",
      "      0     0        0.4719     1        0.4889        0.4719        1    3.47%\n",
      "      0     0        0.4719     1        0.4889      Fract: 1        2    3.47%\n",
      "      0     0        0.4719     4        0.4889      Fract: 1        4    3.47%\n",
      "      0     2        0.4719     7        0.4889        0.4719        4    3.47%                        0             0\n",
      "Elapsed time = 0.08 sec. (3.32 ticks, tree = 0.01 MB, solutions = 1)\n",
      "   1607   631        0.4719     2        0.4889        0.4719     7230    3.47%           rho_9 U   1607   1594     17\n",
      "   2545   955        cutoff              0.4889        0.4719    11874    3.47%        alpha_16 U   2545   2544     24\n",
      "*  2630+  870                            0.4862        0.4719             2.93%\n",
      "   3216  1039        0.4791     5        0.4862        0.4719    15533    2.93%           rho_8 D   3216   3214     18\n",
      "   3914  1322        0.4841     5        0.4862        0.4719    20090    2.93%          rho_16 D   3914   3912     13\n",
      "   4591  1524        0.4792    13        0.4862        0.4719    23895    2.93%          rho_24 D   4591   4589     14\n",
      "   5241  1754        cutoff              0.4862        0.4719    28141    2.93%          rho_22 U   5241   5240     21\n",
      "   5863  1949        cutoff              0.4862        0.4719    32159    2.93%          rho_12 U   5863   5862     27\n",
      "   6462  2151        cutoff              0.4862        0.4719    36202    2.93%           rho_9 U   6462   6461     17\n",
      "   7049  2352        0.4767    14        0.4862        0.4719    40253    2.93%           rho_0 D   7049   7048     15\n",
      "   9464  3032        0.4859    10        0.4862        0.4734    54023    2.64%          rho_27 D   9464   9462     21\n",
      "Elapsed time = 2.17 sec. (3104.73 ticks, tree = 1.00 MB, solutions = 2)\n",
      "  12070  3427        cutoff              0.4862        0.4749    67002    2.31%          rho_24 U  12070   8495     17\n",
      "  14552  3615        0.4785    11        0.4862        0.4764    79313    2.02%           rho_1 U  14552   8476      7\n",
      "  16913  3716        0.4793     9        0.4862        0.4775    90763    1.77%           rho_2 D  16913  13180     10\n",
      "  19240  3717        0.4812     6        0.4862        0.4787   102361    1.54%           rho_2 U  19240  13937     17\n",
      "* 19970  3705      integral     0        0.4862        0.4790   105643    1.47%\n",
      "  21610  3580        0.4855     6        0.4862        0.4797   113337    1.34%          rho_30 D  21610  21609     24\n",
      "* 23315  3311      integral     0        0.4862        0.4804   121016    1.18%          rho_27 U  23315  23314     21\n",
      "* 23415+ 3291                            0.4862        0.4804             1.18%\n",
      "  25681  2812        0.4849     8        0.4862        0.4814   131190    0.97%          rho_28 D  25681  25679     23\n",
      "  27964  2047        0.4861     3        0.4862        0.4828   140889    0.70%          rho_25 D  27964  27963     18\n",
      "  30489   360        cutoff              0.4862        0.4853   149994    0.18%          rho_15 U  30489   8020     17\n",
      "\n",
      "Gomory fractional cuts applied:  1\n",
      "User cuts applied:  491\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.08 sec. (3.38 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    6.95 sec. (11556.06 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    7.03 sec. (11559.44 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-4 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| sex>=1                                       |         1 points |   + ..... |\n",
      "| p_age_first_offense<=22                      |         1 points |   + ..... |\n",
      "| current_violent>=1                           |         1 points |   + ..... |\n",
      "| prior_conviction_M>=7                        |         1 points |   + ..... |\n",
      "| violent_conviction>=4                        |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 5                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "model_id, score_thresholds 0 {'rank_abs': [12]}\n",
      "get_disparity_predefined_group()\n",
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "09/30/19 @ 10:25 AM | 1701 rows in lookup table\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | runnning initialization procedure\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/30/19 @ 10:25 AM | CPA produced 2 cuts\n",
      "09/30/19 @ 10:25 AM | running naive rounding on 79 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4823\n",
      "09/30/19 @ 10:25 AM | rounding produced 4 integer solutions\n",
      "09/30/19 @ 10:25 AM | best objective value is 0.4977\n",
      "09/30/19 @ 10:25 AM | running sequential rounding on 79 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4823\n",
      "09/30/19 @ 10:25 AM | sequential rounding produced 4 integer solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4972\n",
      "09/30/19 @ 10:25 AM | polishing 8 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4972\n",
      "09/30/19 @ 10:25 AM | polishing produced 3 integer solutions\n",
      "09/30/19 @ 10:25 AM | initialization produced 7 feasible solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4972\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | completed initialization procedure\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | 1701 rows in lookup table\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               200\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.48158333362285677\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.49715591304146739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "09/30/19 @ 10:25 AM | adding 166 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.4972.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 42 rows, 84 columns, and 163 nonzeros.\n",
      "Reduced MIP has 40 binaries, 42 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.00 sec. (0.10 ticks)\n",
      "Probing time = 0.00 sec. (0.03 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.05 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.4972        0.4816             3.13%\n",
      "      0     0        0.4816     1        0.4972        0.4816        1    3.13%\n",
      "      0     0        0.4816     1        0.4972      Fract: 1        2    3.13%\n",
      "      0     2        0.4816     6        0.4972        0.4816        2    3.13%                        0             0\n",
      "Elapsed time = 0.06 sec. (2.55 ticks, tree = 0.01 MB, solutions = 1)\n",
      "   1661   543        0.4850     5        0.4972        0.4816     7067    3.13%          rho_31 D   1661   1653     14\n",
      "   2568   777        cutoff              0.4972        0.4816    12356    3.13%           rho_8 U   2568   2565     19\n",
      "   3375   984        0.4816     9        0.4972        0.4816    17208    3.13%           rho_0 D   3375   2615      6\n",
      "*  3580+ 1026                            0.4966        0.4816             3.03%\n",
      "   4027  1156        0.4867     6        0.4966        0.4816    21102    3.03%          rho_31 U   4027   4026     17\n",
      "*  4150  1184      integral     0        0.4966        0.4816    21826    3.03%          rho_31 U   4150   4149     16\n",
      "   4820  1370        0.4878    12        0.4966        0.4816    25952    3.03%          rho_17 D   4820   4804     13\n",
      "   5424  1549        0.4896    10        0.4966        0.4821    30162    2.91%           rho_0 D   5424   1255     22\n",
      "   6121  1619        0.4921    10        0.4966        0.4833    33402    2.68%          rho_17 D   6121   4809     13\n",
      "   6815  1669        0.4914     7        0.4966        0.4842    36863    2.49%           rho_2 D   6815   6814     16\n",
      "   9547  1527        0.4894     4        0.4966        0.4882    49572    1.70%           rho_9 U   9547   4701     20\n",
      "Elapsed time = 2.80 sec. (2905.39 ticks, tree = 0.49 MB, solutions = 3)\n",
      "  12498   811        0.4962     2        0.4966        0.4925    62637    0.82%          rho_30 U  12498   6388     14\n",
      "\n",
      "Implied bound cuts applied:  1\n",
      "Gomory fractional cuts applied:  1\n",
      "User cuts applied:  375\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.06 sec. (2.59 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    3.89 sec. (4228.67 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    3.95 sec. (4231.27 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-3 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| p_age_first_offense<=22                      |         1 points |   + ..... |\n",
      "| current_violent>=1                           |         1 points |   + ..... |\n",
      "| prior_conviction_M>=7                        |         1 points |   + ..... |\n",
      "| p_property>=5                                |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 4                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "model_id, score_thresholds 0 {'rank_abs': [5]}\n",
      "get_disparity_predefined_group()\n",
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "09/30/19 @ 10:25 AM | 1701 rows in lookup table\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | runnning initialization procedure\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:84: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/30/19 @ 10:25 AM | CPA produced 2 cuts\n",
      "09/30/19 @ 10:25 AM | running naive rounding on 76 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4613\n",
      "09/30/19 @ 10:25 AM | rounding produced 3 integer solutions\n",
      "09/30/19 @ 10:25 AM | best objective value is 0.4996\n",
      "09/30/19 @ 10:25 AM | running sequential rounding on 76 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4613\n",
      "09/30/19 @ 10:25 AM | sequential rounding produced 6 integer solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4729\n",
      "09/30/19 @ 10:25 AM | polishing 9 solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4729\n",
      "09/30/19 @ 10:25 AM | polishing produced 4 integer solutions\n",
      "09/30/19 @ 10:25 AM | initialization produced 9 feasible solutions\n",
      "09/30/19 @ 10:25 AM | best objective value: 0.4729\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | completed initialization procedure\n",
      "09/30/19 @ 10:25 AM | ------------------------------------------------------------\n",
      "09/30/19 @ 10:25 AM | 1701 rows in lookup table\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               200\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.46081643420309215\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.47286088090180045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "09/30/19 @ 10:25 AM | adding 195 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.4729.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 42 rows, 84 columns, and 163 nonzeros.\n",
      "Reduced MIP has 40 binaries, 42 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.00 sec. (0.10 ticks)\n",
      "Probing time = 0.00 sec. (0.03 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.05 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.4729        0.4608             2.55%\n",
      "      0     0        0.4608     1        0.4729        0.4608        1    2.55%\n",
      "      0     0        0.4608     1        0.4729      Fract: 1        2    2.55%\n",
      "      0     2        0.4608     5        0.4729        0.4608        2    2.55%                        0             0\n",
      "Elapsed time = 0.08 sec. (2.66 ticks, tree = 0.01 MB, solutions = 1)\n",
      "   1714   551        0.4608     6        0.4729        0.4608     7558    2.55%          rho_28 D   1714   1713      6\n",
      "   2822   888        0.4681     9        0.4729        0.4608    13688    2.55%           rho_0 D   2822   2821     21\n",
      "   3780  1181        0.4608     9        0.4729        0.4608    19070    2.55%          rho_28 D   3780   3779      9\n",
      "   4650  1408        cutoff              0.4729        0.4608    24522    2.55%          rho_12 D   4650   4649     27\n",
      "   5485  1617        0.4678     8        0.4729        0.4614    29797    2.42%           rho_1 U   5485   1141     14\n",
      "   6390  1694        cutoff              0.4729        0.4627    33757    2.14%          rho_25 U   6390   6389     18\n",
      "   7238  1686        0.4707    11        0.4729        0.4638    37492    1.91%           rho_7 U   7238   5326     15\n",
      "   8046  1638        cutoff              0.4729        0.4647    41109    1.73%          rho_24 U   8046    838     17\n",
      "   8861  1571        0.4660    10        0.4729        0.4657    44589    1.52%          rho_26 U   8861   4320     24\n",
      "  12035   624        0.4702     7        0.4729        0.4702    57773    0.56%           rho_2 U  12035   7688     14\n",
      "Elapsed time = 3.23 sec. (3103.69 ticks, tree = 0.25 MB, solutions = 1)\n",
      "\n",
      "Gomory fractional cuts applied:  1\n",
      "User cuts applied:  330\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.09 sec. (2.70 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    3.31 sec. (3322.70 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    3.41 sec. (3325.39 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-3 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| p_age_first_offense<=22                      |         1 points |   + ..... |\n",
      "| current_violent>=1                           |         1 points |   + ..... |\n",
      "| prior_conviction_M>=7                        |         1 points |   + ..... |\n",
      "| violent_conviction>=5                        |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 4                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "model_id, score_thresholds 0 {'rank_abs': [8]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "riskslim_summary = slim.risk_cv(X=sub_X, \n",
    "                                Y=sub_Y, \n",
    "                                indicator=indicator,\n",
    "                                y_label='recid_violent2', \n",
    "                                max_coef=20, \n",
    "                                max_coef_number=10, \n",
    "                                max_runtime=200, \n",
    "                                c=1e-6, \n",
    "                                seed=816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6701326088074134, 0.6552927814068338)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(riskslim_summary['train_auc']), np.mean(riskslim_summary['test_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arnold PSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_arnold.csv\")\n",
    "X_arnold = data['arnold_nvca_raw'].values\n",
    "Y_arnold = data['recid_violent2'].values\n",
    "## set up cross validation\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=816)\n",
    "arnold_auc = []\n",
    "for train, test in cv.split(X_arnold, Y_arnold):\n",
    "    y_pred_arnold, y_test = X_arnold[test], Y_arnold[test]\n",
    "    arnold_auc.append(roc_auc_score(y_test, y_pred_arnold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load stumps data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_stumps.csv\")\n",
    "x, y = data.loc[:,:'five_year>=1'], data['recid_violent2'].values\n",
    "y[y==-1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:84: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:82: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:86: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:95: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corel_summary = Corel.corel_cv(x, y, max_card=2, c=1e-4, seed=816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5305310722193755, 0.003853785462585502)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(corel_summary['test_auc']), np.std(corel_summary['test_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'summary_violent2_FL_interpret' (dict)\n"
     ]
    }
   ],
   "source": [
    "#### save results\n",
    "summary_violent2_FL_interpret = {\"CART\": cart_summary,\n",
    "                                 \"EBM\": ebm_summary, \n",
    "                                 'Lasso Stumps': stump_summary, \n",
    "                                 'RiskSLIM': riskslim_summary, \n",
    "                                 'Corel': corel_summary,\n",
    "                                 'Arnold PSA': arnold_auc}\n",
    "%store summary_violent2_FL_interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CART', 0.6108315420562821, 0.05540142818992251],\n",
       " ['EBM', 0.6753137344731238, 0.03499226291170741],\n",
       " ['Lasso Stumps', 0.6823710656672844, 0.046907038728775996],\n",
       " ['RiskSLIM', 0.6552927814068338, 0.014839827400579653],\n",
       " ['Corel', 0.5],\n",
       " ['Arnold PSA', 0.649]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [[\"CART\", np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs'])],\n",
    "           [\"EBM\", np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs'])], \n",
    "           [\"Lasso Stumps\", np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs'])],\n",
    "           ['RiskSLIM', np.mean(riskslim_summary['test_auc']), np.mean(riskslim_summary['train_auc'])-np.mean(riskslim_summary['test_auc'])],\n",
    "           ['Corel', np.mean(corel_summary['test_auc'])],\n",
    "           ['Arnold PSA', round(np.mean(arnold_auc), 3)]]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = [np.mean(cart_summary['holdout_test_auc']), \n",
    "       np.mean(ebm_summary['holdout_test_auc']), \n",
    "       np.mean(stump_summary['holdout_test_auc']), \n",
    "       np.mean(riskslim_summary['test_auc']), \n",
    "       np.mean(corel_summary['test_auc'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/model results/Interpretable Models/Two Year/\"\n",
    "results = [[\"Violent\", np.str((round(np.mean(cart_summary['holdout_test_auc']), 3))) + \" (\" + np.str(round(np.std(cart_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(ebm_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(ebm_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(stump_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(stump_summary['holdout_test_auc']), 3)) + \")\",             \n",
    "            np.str(round(np.mean(riskslim_summary['test_auc']),3)) + \" (\" + np.str(round(np.std(riskslim_summary['test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(corel_summary['test_auc']),3)) + \" (\" + np.str(round(np.std(corel_summary['test_auc']), 3)) + \")\", \n",
    "            round(np.max(auc) - np.min(auc), 3),\n",
    "            np.str(round(np.mean(arnold_auc), 3)) + \" (\" + np.str(round(np.std(arnold_auc),3)) + \")\"]]\n",
    "with open(path + 'Interpretable Models Summary.csv', 'a') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_confusion = cart_summary['confusion_matrix_stats']\n",
    "ebm_confusion = ebm_summary['confusion_matrix_stats']\n",
    "riskslim_confusion = riskslim_summary['confusion_matrix_stats']\n",
    "stumps_confusion = stump_summary['confusion_matrix_stats']\n",
    "corel_confusion = corel_summary['confusion_matrix_stats']\n",
    "#arnold_confusion = cart_summary['confusion_matrix_stats']\n",
    "\n",
    "## save results\n",
    "cart_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/model fairness/Two Year/violent/cart_confusion.csv', index=None,header=True)\n",
    "ebm_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/model fairness/Two Year/violent/ebm_confusion.csv', index=None,header=True)\n",
    "riskslim_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/model fairness/Two Year/violent/riskslim_confusion.csv', index=None,header=True)\n",
    "stumps_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/model fairness/Two Year/violent/stumps_confusion.csv', index=None,header=True)\n",
    "corel_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/model fairness/Two Year/violent/corel_confusion.csv', index=None,header=True)\n",
    "#arnold_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/model fairness/Two Year/violent/arnold_confusion.csv', index=None,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corel_confusion = corel_summary['confusion_matrix_stats']\n",
    "corel_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/model fairness/Two Year/violent/corel_confusion.csv', index=None,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
