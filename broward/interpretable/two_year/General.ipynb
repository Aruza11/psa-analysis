{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('../../../')\n",
    "print(\"Current working directory is now: \", os.getcwd())\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "import utils.interpretable_functions as interpret\n",
    "import utils.RiskSLIM as slim\n",
    "import utils.stumps as stumps\n",
    "import utils.fairness_functions as fairness\n",
    "from utils.load_settings import load_settings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from pprint import pprint\n",
    "from riskslim.helper_functions import print_model\n",
    "\n",
    "# restore saved variables\n",
    "%store -r summary_general2_FL_interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## CART & EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#### Load Data Here ####\n",
    "x = data.loc[:,:'five_year']\n",
    "y = data['general_two_year'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#### CART\n",
    "depth = [1,2,3,4,5]\n",
    "impurity = [0.001, 0.002, 0.003]\n",
    "cart_summary = interpret.CART(X=x,\n",
    "                              Y=y,\n",
    "                              depth=depth,\n",
    "                              impurity=impurity, \n",
    "                              seed = 816)\n",
    "\n",
    "#### EBM\n",
    "estimators = [60,80,100]\n",
    "depth = [1,2]\n",
    "learning_rate = [0.01]\n",
    "holdout_split = [0.7, 0.9]\n",
    "ebm_summary = interpret.EBM(X=x,\n",
    "                            Y=y,\n",
    "                            learning_rate = learning_rate,\n",
    "                            depth = depth,\n",
    "                            estimators=estimators,\n",
    "                            holdout_split=holdout_split,\n",
    "                            seed=816)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Lasso Stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "## load all stumps data -- called \"data\"\n",
    "data = data.sort_values('person_id')\n",
    "\n",
    "## load original continuous data -- called \"original_data\"\n",
    "original_data = original_data.sort_values('person_id')\n",
    "original_data = original_data.loc[:, ['person_id', 'screening_date', 'age_at_current_charge', 'p_charges']]\n",
    "data = pd.merge(original_data, data, on=['person_id', 'screening_date'])\n",
    "X_stumps, Y_stumps = data.loc[:,:'five_year1'], data['general_two_year'].values\n",
    "Y_stumps[Y_stumps == -1] = 0\n",
    "cols = X_stumps.columns[5:]\n",
    "\n",
    "## load train & test stump data -- called \"train_stumps\" & \"test_stumps\"\n",
    "X_train_stumps, Y_train_stumps = train_stumps.loc[:,:'five_year1'], train_stumps['general_two_year'].values\n",
    "X_test_stumps, Y_test_stumps = test_stumps.loc[:,:'five_year1'], test_stumps['general_two_year'].values\n",
    "Y_train_stumps[Y_train_stumps == -1] = 0\n",
    "Y_test_stumps[Y_test_stumps == -1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Stump Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_stump_model = stumps.stump_model(X_train_stumps, \n",
    "                                        Y_train_stumps, \n",
    "                                        X_test_stumps, \n",
    "                                        Y_test_stumps, \n",
    "                                        c=0.1, \n",
    "                                        columns=cols, \n",
    "                                        seed=816)\n",
    "len(single_stump_model['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_stump_model['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### Nested Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "stump_summary = stumps.stump_cv(X = X_stumps, \n",
    "                                Y = Y_stumps, \n",
    "                                columns=cols, \n",
    "                                c_grid={'C': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]}, \n",
    "                                seed = 816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "stump_summary['best_params'], np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## RiskSLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "## load stumps data -- called \"data\"\n",
    "data = data.sort_values('person_id')\n",
    "\n",
    "## load original continuous data -- called \"original data\"\n",
    "original_data = original_data.sort_values('person_id')\n",
    "original_data = original_data.loc[:, ['person_id', 'screening_date', 'age_at_current_charge', 'p_charges']]\n",
    "\n",
    "## load train & test stumps data -- called \"train_data\" & \"test_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "single_stump_model = stumps.stump_model(X_train_stumps, \n",
    "                                        Y_train_stumps, \n",
    "                                        X_test_stumps, \n",
    "                                        Y_test_stumps, \n",
    "                                        c=0.05, \n",
    "                                        columns=cols, \n",
    "                                        seed=816)\n",
    "len(single_stump_model['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "selected_features = single_stump_model['features']\n",
    "\n",
    "if 'sex1' in selected_features:\n",
    "    selected_features = ['general_two_year', 'person_id', 'screening_date', 'race'] + selected_features\n",
    "    indicator = 1\n",
    "else:\n",
    "    selected_features = ['general_two_year', 'person_id', 'screening_date', 'race', 'sex1'] + selected_features\n",
    "    indicator = 0\n",
    "    \n",
    "sub_data = data[selected_features]\n",
    "sub_data = pd.merge(sub_data, original_data, on=['person_id', 'screening_date'])\n",
    "sub_X, sub_Y = sub_data.iloc[:,1:], sub_data.iloc[:,0].values\n",
    "sub_X.insert(0, '(Intercept)', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "riskslim_summary = slim.risk_nested_cv(X=sub_X, \n",
    "                                       Y=sub_Y, \n",
    "                                       indicator=indicator,\n",
    "                                       y_label='general_two_year', \n",
    "                                       max_coef=5,\n",
    "                                       max_coef_number=5, \n",
    "                                       max_runtime=1000, \n",
    "                                       c=1e-6, \n",
    "                                       max_offset=100,\n",
    "                                       seed=816)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Single RiskSLIM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "selected_features = [\"general_two_year\"] + best_stump_model['features']\n",
    "sub_train_data = train_data[selected_features]\n",
    "sub_test_data = test_data[selected_features]\n",
    "\n",
    "## split x \n",
    "sub_train_X = sub_train_data.iloc[:,1:]\n",
    "sub_train_X.insert(0, '(Intercept)', 1)\n",
    "cols = sub_train_X.columns.tolist()\n",
    "sub_train_X = sub_train_X.values\n",
    "sub_test_X = sub_test_data.iloc[:,1:].values\n",
    "\n",
    "## split y\n",
    "sub_train_Y = sub_train_data.iloc[:,0].values.reshape(-1,1)\n",
    "sub_test_Y = sub_test_data.iloc[:,0].values.reshape(-1,1)\n",
    "\n",
    "## sample weight\n",
    "sample_weights = np.repeat(1, len(sub_train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "new_train_data = {\n",
    "    'X': sub_train_X,\n",
    "    'Y': sub_train_Y,\n",
    "    'variable_names': cols,\n",
    "    'outcome_name': 'general_two_year',\n",
    "    'sample_weights': sample_weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "model_info, mip_info, lcpa_info = slim.risk_slim(new_train_data, \n",
    "                                                 max_coefficient=5, \n",
    "                                                 max_L0_value=5, \n",
    "                                                 c0_value=1e-6, \n",
    "                                                 max_offset=100, \n",
    "                                                 max_runtime=1000)\n",
    "print_model(model_info['solution'], new_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "sub_train_X = sub_train_X[:,1:]\n",
    "sub_train_Y[sub_train_Y == -1] = 0\n",
    "sub_test_Y[sub_test_Y == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6480377791858072"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(sub_train_Y, slim.riskslim_prediction(sub_train_X, np.array(cols), model_info).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6487615321578682"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(sub_test_Y, slim.riskslim_prediction(sub_test_X, np.array(cols), model_info).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Arnold PSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "### load data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_arnold.csv\").sort_values('person_id')\n",
    "X_arnold = data.loc[:,['arnold_nca', 'sex', 'race', 'person_id', 'screening_date', 'age_at_current_charge', 'p_charges']]\n",
    "Y_arnold = data['general_two_year'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "## set up cross validation\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=816)\n",
    "arnold_auc = []\n",
    "race_auc = []\n",
    "condition_pn = []\n",
    "no_condition_pn = []\n",
    "\n",
    "i = 0\n",
    "for train, test in cv.split(X_arnold, Y_arnold):\n",
    "    \n",
    "    train_x, train_y = X_arnold.iloc[train], Y_arnold[train]\n",
    "    test_x, test_y = X_arnold.iloc[test], Y_arnold[test]\n",
    "    holdout_with_attrs = test_x.copy()\n",
    "    \n",
    "    ################################\n",
    "    ## arnold_auc\n",
    "    arnold_auc.append(roc_auc_score(test_y, test_x['arnold_nca'].values))\n",
    "    \n",
    "    ################################\n",
    "    ## race_auc\n",
    "    try:\n",
    "        arnold_race_auc = fairness.fairness_in_auc(df = holdout_with_attrs,\n",
    "                                                   probs = test_x['arnold_nca'],\n",
    "                                                   labels = test_y)\n",
    "        arnold_race_auc_final = arnold_race_auc.assign(fold_num = [i]*arnold_race_auc['Attribute'].count())\n",
    "        race_auc.append(arnold_race_auc_final)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ################################\n",
    "    ## condition pn\n",
    "    arnold_condition_pn = fairness.conditional_balance_positive_negative(df = holdout_with_attrs,\n",
    "                                                                         probs = test_x['arnold_nca'],\n",
    "                                                                         labels = test_y)\n",
    "    arnold_condition_pn_final = arnold_condition_pn.assign(fold_num = [i]*arnold_condition_pn['Attribute'].count())\n",
    "    condition_pn.append(arnold_condition_pn_final)\n",
    "    \n",
    "    ################################\n",
    "    ## no condition pn\n",
    "    arnold_no_condition_pn = fairness.balance_positive_negative(df = holdout_with_attrs,\n",
    "                                                                probs = test_x['arnold_nca'],\n",
    "                                                                labels = test_y)\n",
    "    arnold_no_condition_pn_final = arnold_no_condition_pn.assign(fold_num = [i]*arnold_no_condition_pn['Attribute'].count())\n",
    "    no_condition_pn.append(arnold_no_condition_pn_final)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "## race_auc\n",
    "arnold_race_auc = []\n",
    "try:\n",
    "    arnold_race_auc = pd.concat(race_auc, ignore_index=True)\n",
    "    arnold_race_auc.sort_values([\"fold_num\", \"Attribute\"], inplace=True)\n",
    "    arnold_race_auc = arnold_race_auc.reset_index(drop=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "## condition_pn\n",
    "arnold_condition_pn = pd.concat(condition_pn, ignore_index=True)\n",
    "arnold_condition_pn.sort_values([\"fold_num\", \"Attribute\"], inplace=True)\n",
    "arnold_condition_pn = arnold_condition_pn.reset_index(drop=True)\n",
    "\n",
    "## no_condition_pn\n",
    "arnold_no_condition_pn = pd.concat(no_condition_pn, ignore_index=True)\n",
    "arnold_no_condition_pn.sort_values([\"fold_num\", \"Attribute\"], inplace=True)\n",
    "arnold_no_condition_pn = arnold_no_condition_pn.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Compass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "### load data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_arnold.csv\").sort_values('person_id')\n",
    "X_arnold = data.loc[:,['Risk of Recidivism_decile_score', 'sex', 'race', 'person_id', 'screening_date', 'age_at_current_charge', 'p_charges']]\n",
    "Y_arnold = data['general_two_year'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "## set up cross validation\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=816)\n",
    "compas_auc = []\n",
    "race_auc = []\n",
    "condition_pn = []\n",
    "no_condition_pn = []\n",
    "\n",
    "i = 0\n",
    "for train, test in cv.split(X_arnold, Y_arnold):\n",
    "    \n",
    "    train_x, train_y = X_arnold.iloc[train], Y_arnold[train]\n",
    "    test_x, test_y = X_arnold.iloc[test], Y_arnold[test]\n",
    "    holdout_with_attrs = test_x.copy()\n",
    "    \n",
    "    ################################\n",
    "    ## arnold_auc\n",
    "    compas_auc.append(roc_auc_score(test_y, test_x['Risk of Recidivism_decile_score'].values))\n",
    "    \n",
    "    ################################\n",
    "    ## race_auc\n",
    "    try:\n",
    "        compas_race_auc = fairness.fairness_in_auc(df = holdout_with_attrs,\n",
    "                                                   probs = test_x['Risk of Recidivism_decile_score'],\n",
    "                                                   labels = test_y)\n",
    "        compas_race_auc_final = compas_race_auc.assign(fold_num = [i]*compas_race_auc['Attribute'].count())\n",
    "        race_auc.append(compas_race_auc_final)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ################################\n",
    "    ## condition pn\n",
    "    compas_condition_pn = fairness.conditional_balance_positive_negative(df = holdout_with_attrs,\n",
    "                                                                         probs = test_x['Risk of Recidivism_decile_score'],\n",
    "                                                                         labels = test_y)\n",
    "    compas_condition_pn_final = compas_condition_pn.assign(fold_num = [i]*compas_condition_pn['Attribute'].count())\n",
    "    condition_pn.append(compas_condition_pn_final)\n",
    "    \n",
    "    ################################\n",
    "    ## no condition pn\n",
    "    compas_no_condition_pn = fairness.balance_positive_negative(df = holdout_with_attrs,\n",
    "                                                                probs = test_x['Risk of Recidivism_decile_score'],\n",
    "                                                                labels = test_y)\n",
    "    compas_no_condition_pn_final = compas_no_condition_pn.assign(fold_num = [i]*compas_no_condition_pn['Attribute'].count())\n",
    "    no_condition_pn.append(compas_no_condition_pn_final)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "## race_auc\n",
    "compas_race_auc = []\n",
    "try:  \n",
    "    compas_race_auc = pd.concat(race_auc, ignore_index=True)\n",
    "    compas_race_auc.sort_values([\"fold_num\", \"Attribute\"], inplace=True)\n",
    "    compas_race_auc = compas_race_auc.reset_index(drop=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "## condition_pn\n",
    "compas_condition_pn = pd.concat(condition_pn, ignore_index=True)\n",
    "compas_condition_pn.sort_values([\"fold_num\", \"Attribute\"], inplace=True)\n",
    "compas_condition_pn = compas_condition_pn.reset_index(drop=True)\n",
    "\n",
    "## no_condition_pn\n",
    "compas_no_condition_pn = pd.concat(no_condition_pn, ignore_index=True)\n",
    "compas_no_condition_pn.sort_values([\"fold_num\", \"Attribute\"], inplace=True)\n",
    "compas_no_condition_pn = compas_no_condition_pn.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'summary_general2_FL_interpret' (dict)\n"
     ]
    }
   ],
   "source": [
    "#### save results\n",
    "summary_general2_FL_interpret = {\"CART\": cart_summary,\n",
    "                                 \"EBM\": ebm_summary, \n",
    "                                 'Lasso Stumps': stump_summary, \n",
    "                                 'RiskSLIM': riskslim_summary, \n",
    "                                 'Arnold PSA': arnold_auc, \n",
    "                                 'Compas': compas_auc}\n",
    "%store summary_general2_FL_interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CART', 0.619685037968058, 0.045261875314365964],\n",
       " ['EBM', 0.6612716221382582, 0.03882637292264166],\n",
       " ['Lasso Stumps', 0.6526496716309407, 0.033289339938198916],\n",
       " ['RiskSLIM', 0.6263022451754223],\n",
       " ['Arnold PSA', 0.605],\n",
       " ['Compas', 0.631]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [[\"CART\", np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs'])],\n",
    "           [\"EBM\", np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs'])], \n",
    "           [\"Lasso Stumps\", np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs'])],\n",
    "           ['RiskSLIM', np.mean(riskslim_summary['test_auc'])],\n",
    "           ['Arnold PSA', round(np.mean(arnold_auc), 3)], \n",
    "           ['Compas', round(np.mean(compas_auc), 3)]]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "auc = [np.mean(cart_summary['holdout_test_auc']), \n",
    "       np.mean(ebm_summary['holdout_test_auc']), \n",
    "       np.mean(stump_summary['holdout_test_auc']), \n",
    "       np.mean(riskslim_summary['test_auc'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "path = \"C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/model results/Interpretable Models/Two Year/\"\n",
    "results = [[\"\", \"CART\", \"EBM\", \"Lasso Stumps\", \"RiskSLIM\", \"Performance Range\", \"Arnold PSA\", \"Compas\"],\n",
    "           [\"General\", np.str((round(np.mean(cart_summary['holdout_test_auc']), 3))) + \" (\" + np.str(round(np.std(cart_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(ebm_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(ebm_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(stump_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(stump_summary['holdout_test_auc']), 3)) + \")\",             \n",
    "            np.str(round(np.mean(riskslim_summary['test_auc']),3)) + \" (\" + np.str(round(np.std(riskslim_summary['test_auc']), 3)) + \")\", \n",
    "            round(np.max(auc) - np.min(auc), 3),\n",
    "            np.str(round(np.mean(arnold_auc), 3)) + \" (\" + np.str(round(np.std(arnold_auc),3)) + \")\", \n",
    "            np.str(round(np.mean(compas_auc), 3)) + \" (\" + np.str(round(np.std(compas_auc),3)) + \")\"]]\n",
    "with open(path + 'Interpretable Models Summary.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cart_confusion = cart_summary['confusion_matrix_stats']\n",
    "ebm_confusion = ebm_summary['confusion_matrix_stats']\n",
    "riskslim_confusion = riskslim_summary['confusion_matrix_stats']\n",
    "stumps_confusion = stump_summary['confusion_matrix_stats']\n",
    "\n",
    "cart_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/confusion/two-year/general/cart_confusion.csv', index=None,header=True)\n",
    "ebm_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/confusion/two-year/general/ebm_confusion.csv', index=None,header=True)\n",
    "riskslim_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/confusion/two-year/general/riskslim_confusion.csv', index=None,header=True)\n",
    "stumps_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/confusion/two-year/general/stumps_confusion.csv', index=None,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "cart_calibration = cart_summary['calibration_stats']\n",
    "ebm_calibration = ebm_summary['calibration_stats']\n",
    "riskslim_calibration = riskslim_summary['calibration_stats']\n",
    "stumps_calibration = stump_summary['calibration_stats']\n",
    "\n",
    "## save results\n",
    "cart_calibration.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/calibration/two-year/general/cart_calibration.csv', index=None,header=True)\n",
    "ebm_calibration.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/calibration/two-year/general/ebm_calibration.csv', index=None,header=True)\n",
    "riskslim_calibration.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/calibration/two-year/general/riskslim_calibration.csv', index=None,header=True)\n",
    "stumps_calibration.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/calibration/two-year/general/stumps_calibration.csv', index=None,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_race_auc = cart_summary['race_auc']\n",
    "ebm_race_auc = ebm_summary['race_auc']\n",
    "riskslim_race_auc = riskslim_summary['race_auc']\n",
    "stumps_race_auc = stump_summary['race_auc']\n",
    "\n",
    "## save results\n",
    "cart_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/race-auc/two-year/general/cart_race_auc.csv', index=None,header=True)\n",
    "ebm_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/race-auc/two-year/general/ebm_race_auc.csv', index=None,header=True)\n",
    "riskslim_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/race-auc/two-year/general/riskslim_race_auc.csv', index=None,header=True)\n",
    "stumps_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/race-auc/two-year/general/stumps_race_auc.csv', index=None,header=True)\n",
    "arnold_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/race-auc/two-year/general/arnold_race_auc.csv', index=None,header=True)\n",
    "compas_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/race-auc/two-year/general/compas_race_auc.csv', index=None,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_condition_pn = cart_summary['condition_pn']\n",
    "ebm_condition_pn = ebm_summary['condition_pn']\n",
    "riskslim_condition_pn = riskslim_summary['condition_pn']\n",
    "stumps_condition_pn = stump_summary['condition_pn']\n",
    "\n",
    "## save results\n",
    "cart_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/condition-pn/two-year/general/cart_condition_pn.csv', index=None,header=True)\n",
    "ebm_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/condition-pn/two-year/general/ebm_condition_pn.csv', index=None,header=True)\n",
    "riskslim_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/condition-pn/two-year/general/riskslim_condition_pn.csv', index=None,header=True)\n",
    "stumps_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/condition-pn/two-year/general/stumps_condition_pn.csv', index=None,header=True)\n",
    "arnold_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/condition-pn/two-year/general/arnold_condition_pn.csv', index=None,header=True)\n",
    "compas_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/condition-pn/two-year/general/compas_condition_pn.csv', index=None,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Condition PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_no_condition_pn = cart_summary['no_condition_pn']\n",
    "ebm_no_condition_pn = ebm_summary['no_condition_pn']\n",
    "riskslim_no_condition_pn = riskslim_summary['no_condition_pn']\n",
    "stumps_no_condition_pn = stump_summary['no_condition_pn']\n",
    "\n",
    "## save results\n",
    "cart_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/no-condition-pn/two-year/general/cart_no_condition_pn.csv', index=None,header=True)\n",
    "ebm_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/no-condition-pn/two-year/general/ebm_no_condition_pn.csv', index=None,header=True)\n",
    "riskslim_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/no-condition-pn/two-year/general/riskslim_no_condition_pn.csv', index=None,header=True)\n",
    "stumps_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/no-condition-pn/two-year/general/stumps_no_condition_pn.csv', index=None,header=True)\n",
    "arnold_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/no-condition-pn/two-year/general/arnold_no_condition_pn.csv', index=None,header=True)\n",
    "compas_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/no-condition-pn/two-year/general/compas_no_condition_pn.csv', index=None,header=True)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
