{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is now:  C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../../')\n",
    "print(\"Current working directory is now: \", os.getcwd())\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from broward.models.advanced_models.six_month import stumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data/make predictions. Currently, testing on the six-month violent felonies problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load whole data\n",
    "data = pd.read_csv(\"broward/data/broward_stumps.csv\")\n",
    "X_stumps, Y_stumps = data.loc[:,:'five_year>=1'], data['recid_violent6'].values\n",
    "Y_stumps[Y_stumps == -1] = 0\n",
    "cols = X_stumps.columns[3:]\n",
    "\n",
    "## load train & test data\n",
    "train_stumps = pd.read_csv(\"broward/data/broward_train_stumps.csv\")\n",
    "test_stumps = pd.read_csv(\"broward/data/broward_test_stumps.csv\")\n",
    "\n",
    "X_train_stumps, Y_train_stumps = train_stumps.loc[:,:'five_year>=1'], train_stumps['recid_violent6'].values\n",
    "X_test_stumps, Y_test_stumps = test_stumps.loc[:,:'five_year>=1'], test_stumps['recid_violent6'].values\n",
    "\n",
    "Y_train_stumps[Y_train_stumps == -1] = 0\n",
    "Y_test_stumps[Y_test_stumps == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 1 {'rank_abs': [136]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:87: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  fnr = fn / (fn + tp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 1 {'rank_abs': [140]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:87: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  fnr = fn / (fn + tp)\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:96: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 1 {'rank_abs': [149]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:87: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  fnr = fn / (fn + tp)\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:96: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 1 {'rank_abs': [168]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:87: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  fnr = fn / (fn + tp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 1 {'rank_abs': [160]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:87: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  fnr = fn / (fn + tp)\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\utils\\fairness_functions.py:96: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    }
   ],
   "source": [
    "stump_summary = stumps.stump_cv(X = X_stumps, \n",
    "                                Y = Y_stumps, \n",
    "                                columns=cols, \n",
    "                                c_grid={'C': [0.05]}, \n",
    "                                seed = 816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Attribute Value</th>\n",
       "      <th>PPV</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Treatment Equality</th>\n",
       "      <th>Individuals Evaluated On</th>\n",
       "      <th>fold_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>race</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.660633</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>221</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>race</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0.132530</td>\n",
       "      <td>0.373057</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>210</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>race</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.369458</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.631818</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>220</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>race</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>238</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>race</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.451282</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.565611</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>221</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>race</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>race</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>race</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>race</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>race</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>124</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>race</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>132</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>race</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.304762</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>118</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>race</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>100</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>race</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>122</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>race</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>race</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>race</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>race</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>race</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>race</td>\n",
       "      <td>Native American</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>race</td>\n",
       "      <td>Native American</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>race</td>\n",
       "      <td>Native American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>race</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>race</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>race</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>race</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>race</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>female</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.325658</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.664671</td>\n",
       "      <td>0.131313</td>\n",
       "      <td>334</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex</td>\n",
       "      <td>female</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>0.341853</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.657817</td>\n",
       "      <td>0.084112</td>\n",
       "      <td>339</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sex</td>\n",
       "      <td>female</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.356913</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.642012</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>338</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sex</td>\n",
       "      <td>female</td>\n",
       "      <td>0.158621</td>\n",
       "      <td>0.401316</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.615616</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>333</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sex</td>\n",
       "      <td>female</td>\n",
       "      <td>0.173611</td>\n",
       "      <td>0.387622</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.084034</td>\n",
       "      <td>342</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sex</td>\n",
       "      <td>male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>53</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sex</td>\n",
       "      <td>male</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>48</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sex</td>\n",
       "      <td>male</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sex</td>\n",
       "      <td>male</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sex</td>\n",
       "      <td>male</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attribute   Attribute Value       PPV       FPR       FNR  Accuracy  \\\n",
       "2       race  African-American  0.142857  0.328358  0.450000  0.660633   \n",
       "11      race  African-American  0.132530  0.373057  0.352941  0.628571   \n",
       "18      race  African-American  0.127907  0.369458  0.352941  0.631818   \n",
       "25      race  African-American  0.142857  0.436364  0.111111  0.588235   \n",
       "32      race  African-American  0.169811  0.451282  0.307692  0.565611   \n",
       "7       race             Asian  0.000000  1.000000       NaN  0.000000   \n",
       "14      race             Asian       NaN  0.000000       NaN  1.000000   \n",
       "22      race             Asian       NaN  0.000000       NaN  1.000000   \n",
       "29      race             Asian  0.000000  0.500000       NaN  0.500000   \n",
       "5       race         Caucasian  0.075000  0.318966  0.625000  0.661290   \n",
       "12      race         Caucasian  0.125000  0.341463  0.333333  0.659091   \n",
       "20      race         Caucasian  0.219512  0.304762  0.307692  0.694915   \n",
       "27      race         Caucasian  0.200000  0.311111  0.300000  0.690000   \n",
       "34      race         Caucasian  0.214286  0.300000  0.250000  0.704918   \n",
       "4       race          Hispanic  0.090909  0.454545  0.000000  0.565217   \n",
       "13      race          Hispanic  0.000000  0.192308       NaN  0.807692   \n",
       "21      race          Hispanic  0.000000  0.346154       NaN  0.653846   \n",
       "26      race          Hispanic  0.166667  0.454545  0.333333  0.560000   \n",
       "33      race          Hispanic  0.000000  0.296296       NaN  0.703704   \n",
       "6       race   Native American  0.000000  1.000000       NaN  0.000000   \n",
       "19      race   Native American  0.000000  0.500000       NaN  0.500000   \n",
       "36      race   Native American       NaN  0.000000       NaN  1.000000   \n",
       "3       race             Other  0.333333  0.266667  0.000000  0.764706   \n",
       "10      race             Other  0.250000  0.187500  0.500000  0.777778   \n",
       "17      race             Other  0.000000  0.631579  1.000000  0.350000   \n",
       "28      race             Other  0.125000  0.333333  0.000000  0.681818   \n",
       "35      race             Other  0.000000  0.250000       NaN  0.750000   \n",
       "0        sex            female  0.146552  0.325658  0.433333  0.664671   \n",
       "8        sex            female  0.137097  0.341853  0.346154  0.657817   \n",
       "15       sex            female  0.132812  0.356913  0.370370  0.642012   \n",
       "23       sex            female  0.158621  0.401316  0.206897  0.615616   \n",
       "30       sex            female  0.173611  0.387622  0.285714  0.622807   \n",
       "1        sex              male  0.000000  0.384615  1.000000  0.603774   \n",
       "9        sex              male  0.062500  0.326087  0.500000  0.666667   \n",
       "16       sex              male  0.142857  0.400000  0.250000  0.612245   \n",
       "24       sex              male  0.130435  0.392157  0.000000  0.629630   \n",
       "31       sex              male  0.125000  0.333333  0.333333  0.666667   \n",
       "\n",
       "    Treatment Equality  Individuals Evaluated On  fold_num  \n",
       "2             0.136364                       221        13  \n",
       "11            0.083333                       210        14  \n",
       "18            0.080000                       220        16  \n",
       "25            0.020833                       238        13  \n",
       "32            0.090909                       221        18  \n",
       "7             0.000000                         1        13  \n",
       "14                 NaN                         1        14  \n",
       "22                 NaN                         1        16  \n",
       "29            0.000000                         2        13  \n",
       "5             0.135135                       124        13  \n",
       "12            0.071429                       132        14  \n",
       "20            0.125000                       118        16  \n",
       "27            0.107143                       100        13  \n",
       "34            0.090909                       122        18  \n",
       "4             0.000000                        23        13  \n",
       "13            0.000000                        26        14  \n",
       "21            0.000000                        26        16  \n",
       "26            0.100000                        25        13  \n",
       "33            0.000000                        27        18  \n",
       "6             0.000000                         1        13  \n",
       "19            0.000000                         2        16  \n",
       "36                 NaN                         1        18  \n",
       "3             0.000000                        17        13  \n",
       "10            0.333333                        18        14  \n",
       "17            0.083333                        20        16  \n",
       "28            0.000000                        22        13  \n",
       "35            0.000000                        16        18  \n",
       "0             0.131313                       334        13  \n",
       "8             0.084112                       339        14  \n",
       "15            0.090090                       338        16  \n",
       "23            0.049180                       333        13  \n",
       "30            0.084034                       342        18  \n",
       "1             0.050000                        53        13  \n",
       "9             0.066667                        48        14  \n",
       "16            0.055556                        49        16  \n",
       "24            0.000000                        54        13  \n",
       "31            0.071429                        45        18  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stump_summary['confusion_matrix_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def stump_preds(X_train, Y_train, X_test, Y_test, c, columns, seed):\n",
    "        \n",
    "    ## remove unused feature in modeling\n",
    "    preds_df = X_test\n",
    "    X_train = X_train.drop(['person_id', 'screening_date', 'race'], axis=1)\n",
    "    X_test = X_test.drop(['person_id', 'screening_date', 'race'], axis=1)\n",
    "    \n",
    "    ## estimator\n",
    "    lasso = LogisticRegression(class_weight = 'balanced', solver='liblinear', \n",
    "                               random_state=seed, penalty='l1', C = c).fit(X_train, Y_train)\n",
    "    coefs = lasso.coef_[lasso.coef_ != 0]\n",
    "    features = columns[lasso.coef_[0] != 0].tolist()\n",
    "    intercept = round(lasso.intercept_[0],3)\n",
    "     \n",
    "    ## dictionary\n",
    "    lasso_dict_rounding = {}\n",
    "    for i in range(len(features)):\n",
    "        lasso_dict_rounding.update({features[i]: round(round(coefs[i], 3)*100, 1)})\n",
    "    \n",
    "    ## prediction on test set\n",
    "    prob = 0\n",
    "    for k in features:\n",
    "        test_values = X_test[k]*(lasso_dict_rounding[k]/100)\n",
    "        prob += test_values\n",
    "    \n",
    "    holdout_prob = np.exp(prob)/(1+np.exp(prob))\n",
    "    preds_df['prediction'] = holdout_prob \n",
    "    preds_df['label'] = Y_test\n",
    "#     test_auc = roc_auc_score(Y_test, holdout_prob)\n",
    "    \n",
    "    return {'coefs': coefs, \n",
    "            'features': features, \n",
    "            'intercept': intercept, \n",
    "            'dictionary': lasso_dict_rounding, \n",
    "#             'test_auc': test_auc,\n",
    "            'preds_df': preds_df[['person_id',  'screening_date', 'race', 'prediction', 'label']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.565128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.435118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.450414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.502250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.340290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.398672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.301114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.368420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.252750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.495250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.437577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.301114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.576641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.332922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.349554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.280698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.452395</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.529715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.314104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.309598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.467795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.601807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.371450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.356635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.470285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.321039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.383906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.490751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.467795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.332034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.502750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.553297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.357553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.590250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.601807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.512747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.559221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.391503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.552802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.475769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.321912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.519490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.384853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.335592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.507749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.360775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.423603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.550576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.465555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.347057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.335592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.335592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.354801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.497750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0.421163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0.450909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                group  prediction  label\n",
       "2    African-American    0.565128      1\n",
       "3    African-American    0.435118      0\n",
       "4    African-American    0.450414      0\n",
       "6    African-American    0.502250      0\n",
       "7    African-American    0.497500      0\n",
       "..                ...         ...    ...\n",
       "367  African-American    0.335592      0\n",
       "368  African-American    0.354801      0\n",
       "369  African-American    0.497750      1\n",
       "370  African-American    0.421163      0\n",
       "371         Caucasian    0.450909      0\n",
       "\n",
       "[314 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on nested CV procedure, best c value was .05\n",
    "# 163 columns, 372 rows)\n",
    "best_stumps_summary = stump_preds(X_train_stumps, Y_train_stumps, \n",
    "                          X_test_stumps, Y_test_stumps, \n",
    "                          c=0.05, columns=cols, seed=816)\n",
    "stumps_violence6 = best_stumps_summary['preds_df'].rename(columns={\"race\": \"group\"})\n",
    "stumps_violence6 = stumps_violence6[(stumps_violence6['group']==\"Caucasian\") | (stumps_violence6['group']==\"African-American\")]\n",
    "stumps_violence6.drop(labels = [\"person_id\",\"screening_date\"], inplace=True, axis=1)\n",
    "stumps_violence6['group'] = stumps_violence6[0].map({'Caucasian': 0, 'African-American': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enforce Equalized Odds (Hardt, Srebo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairness_enforcers.equalized_odds.eq_odds import run_eq_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:211: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  group_0_val_model = Model(group_0_val_data['prediction'].as_matrix(), group_0_val_data['label'].as_matrix())\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:212: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  group_1_val_model = Model(group_1_val_data['prediction'].as_matrix(), group_1_val_data['label'].as_matrix())\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:213: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  group_0_test_model = Model(group_0_test_data['prediction'].as_matrix(), group_0_test_data['label'].as_matrix())\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:214: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  group_1_test_model = Model(group_1_test_data['prediction'].as_matrix(), group_1_test_data['label'].as_matrix())\n",
      "C:\\Users\\Caroline Wang\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Caroline Wang\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:143: RuntimeWarning: Mean of empty slice.\n",
      "  spn_given_p = (sn2p * (sflip * sm_fn).mean() + sn2n * (sconst * sm_fn).mean()) / sbr + \\\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:144: RuntimeWarning: Mean of empty slice.\n",
      "  (sp2p * (sconst * sm_tp).mean() + sp2n * (sflip * sm_tp).mean()) / sbr\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:146: RuntimeWarning: Mean of empty slice.\n",
      "  spp_given_n = (sp2n * (sflip * sm_fp).mean() + sp2p * (sconst * sm_fp).mean()) / (1 - sbr) + \\\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:147: RuntimeWarning: Mean of empty slice.\n",
      "  (sn2p * (sflip * sm_tn).mean() + sn2n * (sconst * sm_tn).mean()) / (1 - sbr)\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:149: RuntimeWarning: Mean of empty slice.\n",
      "  opn_given_p = (on2p * (oflip * om_fn).mean() + on2n * (oconst * om_fn).mean()) / obr + \\\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:150: RuntimeWarning: Mean of empty slice.\n",
      "  (op2p * (oconst * om_tp).mean() + op2n * (oflip * om_tp).mean()) / obr\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:152: RuntimeWarning: Mean of empty slice.\n",
      "  opp_given_n = (op2n * (oflip * om_fp).mean() + op2p * (oconst * om_fp).mean()) / (1 - obr) + \\\n",
      "C:\\Users\\Caroline Wang\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py:153: RuntimeWarning: Mean of empty slice.\n",
      "  (on2p * (oflip * om_tn).mean() + on2n * (oconst * om_tn).mean()) / (1 - obr)\n",
      "C:\\Users\\Caroline Wang\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\data.py:201: RuntimeWarning: invalid value encountered in reduce\n",
      "  m = min_or_max.reduce(self._deduped_data().ravel())\n",
      "C:\\Users\\Caroline Wang\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\data.py:203: RuntimeWarning: invalid value encountered in maximum\n",
      "  m = min_or_max(zero, m)\n",
      "C:\\Users\\Caroline Wang\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\data.py:203: RuntimeWarning: invalid value encountered in minimum\n",
      "  m = min_or_max(zero, m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR in LDL_factor: Error in KKT matrix LDL factorization when computing the nonzero elements. The problem seems to be non-convex\n",
      "ERROR in osqp_setup: KKT matrix factorization.\n",
      "The problem seems to be non-convex.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Workspace allocation error!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1b63bdbcf280>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_eq_odds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_and_val_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstumps_violence6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py\u001b[0m in \u001b[0;36mrun_eq_odds\u001b[1;34m(test_and_val_data)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;31m# Find mixing rates for equalized odds models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmix_rates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq_odds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_0_val_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_1_val_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;31m# Apply the mixing rates to the test models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py\u001b[0m in \u001b[0;36meq_odds\u001b[1;34m(self, othr, mix_rates)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mhas_mix_rates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmix_rates\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_mix_rates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mmix_rates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq_odds_optimal_mix_rates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mothr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0msp2p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msn2p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop2p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon2p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmix_rates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Duke\\Criminal Recidivism\\psa-analysis\\fairness_enforcers\\equalized_odds\\eq_odds.py\u001b[0m in \u001b[0;36meq_odds_optimal_mix_rates\u001b[1;34m(self, othr)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProblem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msp2p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msn2p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop2p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon2p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[0msolve_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msolve_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(self, solver, warm_start, verbose, parallel, gp, qcp, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m             self._intermediate_problem)\n\u001b[0;32m    570\u001b[0m         solution = self._solving_chain.solve_via_data(\n\u001b[1;32m--> 571\u001b[1;33m             self, data, warm_start, verbose, kwargs)\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mfull_chain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solving_chain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_intermediate_chain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0minverse_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_intermediate_inverse_data\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msolving_inverse_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py\u001b[0m in \u001b[0;36msolve_via_data\u001b[1;34m(self, problem, data, warm_start, verbose, solver_opts)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m    193\u001b[0m         return self.solver.solve_via_data(data, warm_start, verbose,\n\u001b[1;32m--> 194\u001b[1;33m                                           solver_opts, problem._solver_cache)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\reductions\\solvers\\qp_solvers\\osqp_qpif.py\u001b[0m in \u001b[0;36msolve_via_data\u001b[1;34m(self, data, warm_start, verbose, solver_opts, solver_cache)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0msolver_opts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'polish'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver_opts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'polish'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mosqp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOSQP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msolver_opts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\osqp\\interface.py\u001b[0m in \u001b[0;36msetup\u001b[1;34m(self, P, q, A, l, u, **settings)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0munpacked_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msettings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munpacked_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     def update(self, q=None, l=None, u=None,\n",
      "\u001b[1;31mValueError\u001b[0m: Workspace allocation error!"
     ]
    }
   ],
   "source": [
    "run_eq_odds(test_and_val_data=stumps_violence6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
