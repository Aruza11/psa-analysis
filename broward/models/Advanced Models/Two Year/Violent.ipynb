{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is now:  C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning:\n",
      "\n",
      "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable summary_violent2_broward_interpret\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../../../../')\n",
    "print(\"Current working directory is now: \", os.getcwd())\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "import utils.baseline_functions as base\n",
    "import stumps\n",
    "import RiskSLIM as slim\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# restore saved variables\n",
    "%store -r summary_violent2_broward_interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART & EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_data.csv\")\n",
    "x = data.loc[:,:'five_year']\n",
    "y = data['recid_violent2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [0]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [0]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [7]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [22]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [33]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n",
      "WARNING:interpret.utils.all:Passing a numpy array to schema autogen when it should be dataframe.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3]}\n",
      "get_disparity_predefined_group()\n"
     ]
    }
   ],
   "source": [
    "#### CART\n",
    "depth = [1,2,3]\n",
    "impurity = [0.001, 0.003]\n",
    "split = [2,3,4]\n",
    "cart_summary = base.CART(X=x,\n",
    "                         Y=y,\n",
    "                         depth=depth,\n",
    "                         split=split,\n",
    "                         impurity=impurity, \n",
    "                         seed = 816)\n",
    "\n",
    "#### EBM\n",
    "estimators = [60,80,100]\n",
    "depth = [1]\n",
    "learning_rate = [0.05]\n",
    "holdout_split = [0.7, 0.9]\n",
    "ebm_summary = base.EBM(X=x,\n",
    "                       Y=y,\n",
    "                       learning_rate = learning_rate,\n",
    "                       depth = depth,\n",
    "                       estimators=estimators,\n",
    "                       holdout_split=holdout_split,\n",
    "                       seed=816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.619227380329298, 0.060089375526912625)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6750425985586144, 0.035468888427059884)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load whole data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_stumps.csv\")\n",
    "X_stumps, Y_stumps = data.loc[:,:'five_year>=1'], data['recid_violent2'].values\n",
    "Y_stumps[Y_stumps == -1] = 0\n",
    "cols = X_stumps.columns[3:]\n",
    "\n",
    "## load train & test data\n",
    "train_stumps = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_train_stumps.csv\")\n",
    "test_stumps = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_test_stumps.csv\")\n",
    "\n",
    "X_train_stumps, Y_train_stumps = train_stumps.loc[:,:'five_year>=1'], train_stumps['recid_violent2'].values\n",
    "X_test_stumps, Y_test_stumps = test_stumps.loc[:,:'five_year>=1'], test_stumps['recid_violent2'].values\n",
    "\n",
    "Y_train_stumps[Y_train_stumps == -1] = 0\n",
    "Y_test_stumps[Y_test_stumps == -1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [167]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [171]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [168]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [156]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [153]}\n",
      "get_disparity_predefined_group()\n"
     ]
    }
   ],
   "source": [
    "stump_summary = stumps.stump_cv(X = X_stumps, \n",
    "                                Y = Y_stumps, \n",
    "                                columns=cols, \n",
    "                                c_grid={'C': [0.01, 0.05]}, \n",
    "                                seed = 816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'C': 0.05}, {'C': 0.05}, {'C': 0.05}, {'C': 0.05}, {'C': 0.05}],\n",
       " 0.6810825736881314,\n",
       " 0.03892631709527117)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stump_summary['best_params'], np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Stump Model\n",
    "- alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_stump_model = stumps.stump_model(X_train_stumps, Y_train_stumps, \n",
    "                                      X_test_stumps, Y_test_stumps, \n",
    "                                      c=0.05, columns=cols, seed=816)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+----------------+\n",
      "| Features                          | Score          |\n",
      "|====================================================|\n",
      "| p_current_age>=19                 | -2.4           |\n",
      "| p_current_age>=23                 | -23.2          |\n",
      "| p_current_age>=30                 | -25.6          |\n",
      "| p_current_age>=31                 | -0.1           |\n",
      "| current_violent>=1                | 33.6           |\n",
      "| prior_conviction_M>=5             | 8.1            |\n",
      "| prior_conviction_M>=7             | 4.5            |\n",
      "| violent_conviction>=3             | 34.4           |\n",
      "| violent_conviction>=4             | 11.8           |\n",
      "| violent_conviction>=5             | 21.0           |\n",
      "| total_convictions>=7              | 6.0            |\n",
      "| p_property>=2                     | 2.5            |\n",
      "| p_property>=5                     | 11.5           |\n",
      "| years_since_last_crime>=1         | -12.9          |\n",
      "| years_since_last_crime>=3         | -15.1          |\n",
      "| years_since_last_crime>=4         | -11.1          |\n",
      "| Intercept                         | 0.0            |\n",
      "|====================================================|\n",
      "| ADD POINTS FROM ROWS 1 TO 16      | Total Score    |\n",
      "+-----------------------------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "stumps.stump_table(best_stump_model['coefs'], \n",
    "                   best_stump_model['features'], \n",
    "                   best_stump_model['intercept'], \n",
    "                   best_stump_model['dictionary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RiskSLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load stumps data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_stumps.csv\")\n",
    "x, y = data.loc[:,:'five_year>=1'], data['recid_violent2'].values\n",
    "cols = x.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train on best param chosen by Lasso Stumps from above\n",
    "x_train = x.copy().drop(['race', 'person_id', 'screening_date'], axis=1)\n",
    "lasso = LogisticRegression(class_weight='balanced', solver='liblinear', penalty='l1', C=0.05, random_state=816).fit(x_train,y)\n",
    "selected_features = cols[lasso.coef_[0] != 0].tolist()\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset features\n",
    "if 'sex' in selected_features:\n",
    "    selected_features = ['recid_violent2', 'person_id', 'screening_date', 'race'] + selected_features\n",
    "    indicator = 1\n",
    "else:\n",
    "    selected_features = ['recid_violent2', 'person_id', 'screening_date', 'race', 'sex'] + selected_features\n",
    "    indicator = 0\n",
    "    \n",
    "sub_data = data[selected_features]\n",
    "sub_X, sub_Y = sub_data.iloc[:,1:], sub_data.iloc[:,0].values\n",
    "sub_X.insert(0, '(Intercept)', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "09/10/19 @ 09:57 AM | switching loss computation from lookup to weighted\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | runnning initialization procedure\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | CPA produced 2 cuts\n",
      "09/10/19 @ 09:57 AM | running naive rounding on 120 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4751\n",
      "09/10/19 @ 09:57 AM | rounding produced 3 integer solutions\n",
      "09/10/19 @ 09:57 AM | best objective value is 0.4913\n",
      "09/10/19 @ 09:57 AM | running sequential rounding on 120 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4751\n",
      "09/10/19 @ 09:57 AM | sequential rounding produced 2 integer solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4913\n",
      "09/10/19 @ 09:57 AM | polishing 5 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4913\n",
      "09/10/19 @ 09:57 AM | polishing produced 3 integer solutions\n",
      "09/10/19 @ 09:57 AM | initialization produced 5 feasible solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4913\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | completed initialization procedure\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | switching loss computation from lookup to weighted\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               200\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.47506692677843154\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.49133918964663165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "09/10/19 @ 09:57 AM | adding 119 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.4913.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 24 rows, 48 columns, and 91 nonzeros.\n",
      "Reduced MIP has 22 binaries, 24 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.00 sec. (0.05 ticks)\n",
      "Probing time = 0.00 sec. (0.01 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.03 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.4913        0.4751             3.31%\n",
      "      0     0        0.4751     1        0.4913        0.4751        1    3.31%\n",
      "      0     0        0.4751     1        0.4913      Fract: 2        4    3.31%\n",
      "      0     0        0.4751     5        0.4913    MIRcuts: 1        5    3.31%\n",
      "      0     2        0.4751     5        0.4913        0.4751        5    3.31%                        0             0\n",
      "Elapsed time = 0.06 sec. (1.39 ticks, tree = 0.01 MB, solutions = 1)\n",
      "*   520+  147                            0.4887        0.4751             2.79%\n",
      "*  1490+  256                            0.4887        0.4797             1.84%\n",
      "\n",
      "Gomory fractional cuts applied:  1\n",
      "User cuts applied:  121\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.05 sec. (1.40 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    0.44 sec. (196.75 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    0.48 sec. (198.15 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-3 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| p_age_first_offense<=19                      |         1 points |   + ..... |\n",
      "| current_violent>=1                           |         1 points |   + ..... |\n",
      "| prior_conviction_M>=7                        |         1 points |   + ..... |\n",
      "| p_property>=5                                |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 4                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "model_id, score_thresholds 0 {'rank_abs': [9]}\n",
      "get_disparity_predefined_group()\n",
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "09/10/19 @ 09:57 AM | switching loss computation from lookup to weighted\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | runnning initialization procedure\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | CPA produced 2 cuts\n",
      "09/10/19 @ 09:57 AM | running naive rounding on 129 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4768\n",
      "09/10/19 @ 09:57 AM | rounding produced 1 integer solutions\n",
      "09/10/19 @ 09:57 AM | best objective value is 0.5057\n",
      "09/10/19 @ 09:57 AM | running sequential rounding on 129 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4768\n",
      "09/10/19 @ 09:57 AM | sequential rounding produced 1 integer solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4952\n",
      "09/10/19 @ 09:57 AM | polishing 2 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4952\n",
      "09/10/19 @ 09:57 AM | polishing produced 2 integer solutions\n",
      "09/10/19 @ 09:57 AM | initialization produced 2 feasible solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4952\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | completed initialization procedure\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | switching loss computation from lookup to weighted\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               200\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.47678203236167438\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.49524626160046864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "09/10/19 @ 09:57 AM | adding 128 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.4952.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 24 rows, 48 columns, and 91 nonzeros.\n",
      "Reduced MIP has 22 binaries, 24 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.00 sec. (0.05 ticks)\n",
      "Probing time = 0.00 sec. (0.01 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.03 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.4952        0.4768             3.73%\n",
      "      0     0        0.4768     1        0.4952        0.4768        1    3.73%\n",
      "      0     0        0.4768     1        0.4952      Fract: 2        2    3.73%\n",
      "      0     0        0.4768     5        0.4952      Fract: 1        4    3.73%\n",
      "      0     2        0.4768     5        0.4952        0.4768        4    3.73%                        0             0\n",
      "Elapsed time = 0.08 sec. (1.45 ticks, tree = 0.01 MB, solutions = 1)\n",
      "*   120+   47                            0.4939        0.4768             3.46%\n",
      "*   420+  156                            0.4932        0.4768             3.33%\n",
      "*   424   160      integral     0        0.4932        0.4768     1476    3.33%        alpha_17 D    424    423     21\n",
      "*   740+  239                            0.4925        0.4768             3.20%\n",
      "*   870   284      integral     0        0.4925        0.4768     3531    3.20%\n",
      "*  2086   458      integral     0        0.4916        0.4820     8696    1.94%           rho_3 D   2086   2085     25\n",
      "\n",
      "Gomory fractional cuts applied:  2\n",
      "User cuts applied:  144\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.08 sec. (1.46 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    0.63 sec. (363.77 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    0.70 sec. (365.23 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-3 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| p_age_first_offense<=19                      |         1 points |   + ..... |\n",
      "| current_violent>=1                           |         1 points |   + ..... |\n",
      "| prior_conviction_M>=7                        |         1 points |   + ..... |\n",
      "| violent_conviction>=4                        |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 4                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "model_id, score_thresholds 0 {'rank_abs': [13]}\n",
      "get_disparity_predefined_group()\n",
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "09/10/19 @ 09:57 AM | 981 rows in lookup table\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | runnning initialization procedure\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | CPA produced 2 cuts\n",
      "09/10/19 @ 09:57 AM | running naive rounding on 108 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4692\n",
      "09/10/19 @ 09:57 AM | rounding produced 2 integer solutions\n",
      "09/10/19 @ 09:57 AM | best objective value is 0.4813\n",
      "09/10/19 @ 09:57 AM | running sequential rounding on 108 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4692\n",
      "09/10/19 @ 09:57 AM | sequential rounding produced 1 integer solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4813\n",
      "09/10/19 @ 09:57 AM | polishing 3 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4813\n",
      "09/10/19 @ 09:57 AM | polishing produced 2 integer solutions\n",
      "09/10/19 @ 09:57 AM | initialization produced 2 feasible solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4813\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | completed initialization procedure\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | 981 rows in lookup table\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               200\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.46917397483369999\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.48128008022908897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "09/10/19 @ 09:57 AM | adding 107 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.4813.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 24 rows, 48 columns, and 91 nonzeros.\n",
      "Reduced MIP has 22 binaries, 24 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.02 sec. (0.05 ticks)\n",
      "Probing time = 0.00 sec. (0.01 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.03 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.4813        0.4692             2.52%\n",
      "      0     0        0.4692     1        0.4813        0.4692        1    2.52%\n",
      "      0     0        0.4692     1        0.4813      Fract: 1        2    2.52%\n",
      "      0     0        0.4692     4        0.4813      Fract: 1        4    2.52%\n",
      "      0     2        0.4692     6        0.4813        0.4692        4    2.52%                        0             0\n",
      "Elapsed time = 0.05 sec. (1.35 ticks, tree = 0.01 MB, solutions = 1)\n",
      "*   460+  134                            0.4812        0.4692             2.49%\n",
      "\n",
      "Gomory fractional cuts applied:  1\n",
      "User cuts applied:  102\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.05 sec. (1.36 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    0.30 sec. (153.79 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    0.34 sec. (155.15 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-3 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| p_age_first_offense<=19                      |         1 points |   + ..... |\n",
      "| current_violent>=1                           |         1 points |   + ..... |\n",
      "| prior_conviction_M>=7                        |         1 points |   + ..... |\n",
      "| violent_conviction>=3                        |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 4                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "model_id, score_thresholds 0 {'rank_abs': [12]}\n",
      "get_disparity_predefined_group()\n",
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "09/10/19 @ 09:57 AM | 981 rows in lookup table\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | runnning initialization procedure\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | CPA produced 2 cuts\n",
      "09/10/19 @ 09:57 AM | running naive rounding on 134 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4622\n",
      "09/10/19 @ 09:57 AM | rounding produced 1 integer solutions\n",
      "09/10/19 @ 09:57 AM | best objective value is 0.4897\n",
      "09/10/19 @ 09:57 AM | running sequential rounding on 134 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4622\n",
      "09/10/19 @ 09:57 AM | sequential rounding produced 1 integer solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4822\n",
      "09/10/19 @ 09:57 AM | polishing 2 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4822\n",
      "09/10/19 @ 09:57 AM | polishing produced 2 integer solutions\n",
      "09/10/19 @ 09:57 AM | initialization produced 2 feasible solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4822\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | completed initialization procedure\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | 981 rows in lookup table\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               200\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.46218577638187486\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.48219579815324204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "09/10/19 @ 09:57 AM | adding 133 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.4822.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 24 rows, 48 columns, and 91 nonzeros.\n",
      "Reduced MIP has 22 binaries, 24 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.00 sec. (0.05 ticks)\n",
      "Probing time = 0.00 sec. (0.01 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.03 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.4822        0.4622             4.15%\n",
      "      0     0        0.4622     1        0.4822        0.4622        1    4.15%\n",
      "      0     0        0.4622     1        0.4822       Cuts: 3        2    4.15%\n",
      "      0     0        0.4622     4        0.4822      Fract: 1        4    4.15%\n",
      "      0     2        0.4622     7        0.4822        0.4622        4    4.15%                        0             0\n",
      "Elapsed time = 0.05 sec. (1.65 ticks, tree = 0.01 MB, solutions = 1)\n",
      "*   150    57      integral     0        0.4818        0.4622      531    4.07%          rho_15 D    150    149     19\n",
      "*   320+  107                            0.4768        0.4622             3.07%\n",
      "*   904   266      integral     0        0.4768        0.4622     3723    3.07%           rho_0 U    904    903     13\n",
      "*  1310   358      integral     0        0.4759        0.4634     5639    2.63%           rho_7 D   1310   1309     19\n",
      "*  1545   361      integral     0        0.4759        0.4654     6600    2.19%          rho_14 U   1545   1544     20\n",
      "\n",
      "Gomory fractional cuts applied:  1\n",
      "User cuts applied:  148\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.05 sec. (1.66 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    0.42 sec. (236.18 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    0.47 sec. (237.84 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-3 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| p_age_first_offense<=19                      |         1 points |   + ..... |\n",
      "| current_violent>=1                           |         1 points |   + ..... |\n",
      "| prior_conviction_M>=7                        |         1 points |   + ..... |\n",
      "| violent_conviction>=5                        |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 4                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "model_id, score_thresholds 0 {'rank_abs': [2]}\n",
      "get_disparity_predefined_group()\n",
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "09/10/19 @ 09:57 AM | 981 rows in lookup table\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | runnning initialization procedure\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | CPA produced 2 cuts\n",
      "09/10/19 @ 09:57 AM | running naive rounding on 126 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4732\n",
      "09/10/19 @ 09:57 AM | rounding produced 1 integer solutions\n",
      "09/10/19 @ 09:57 AM | best objective value is 0.5125\n",
      "09/10/19 @ 09:57 AM | running sequential rounding on 126 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4732\n",
      "09/10/19 @ 09:57 AM | sequential rounding produced 1 integer solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4942\n",
      "09/10/19 @ 09:57 AM | polishing 2 solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4942\n",
      "09/10/19 @ 09:57 AM | polishing produced 2 integer solutions\n",
      "09/10/19 @ 09:57 AM | initialization produced 3 feasible solutions\n",
      "09/10/19 @ 09:57 AM | best objective value: 0.4942\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | completed initialization procedure\n",
      "09/10/19 @ 09:57 AM | ------------------------------------------------------------\n",
      "09/10/19 @ 09:57 AM | 981 rows in lookup table\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               200\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.47317336874147797\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.49419757615819693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "09/10/19 @ 09:57 AM | adding 133 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.4942.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 24 rows, 48 columns, and 91 nonzeros.\n",
      "Reduced MIP has 22 binaries, 24 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.00 sec. (0.05 ticks)\n",
      "Probing time = 0.00 sec. (0.01 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.03 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.4942        0.4732             4.26%\n",
      "      0     0        0.4732     1        0.4942        0.4732        1    4.25%\n",
      "      0     0        0.4732     1        0.4942      Fract: 1        2    4.25%\n",
      "      0     0        0.4732     5        0.4942      Fract: 1        3    4.25%\n",
      "      0     2        0.4732     5        0.4942        0.4732        3    4.25%                        0             0\n",
      "Elapsed time = 0.05 sec. (1.51 ticks, tree = 0.01 MB, solutions = 1)\n",
      "*    40+   22                            0.4904        0.4732             3.51%\n",
      "*   260+  103                            0.4899        0.4732             3.40%\n",
      "*   320+  122                            0.4896        0.4732             3.35%\n",
      "*   416   158      integral     0        0.4896        0.4732     1637    3.35%\n",
      "*   700   217      integral     0        0.4881        0.4732     2743    3.07%           rho_7 D    700    699     18\n",
      "*   740+  223                            0.4878        0.4732             2.99%\n",
      "*   890   257      integral     0        0.4878        0.4732     3577    2.99%          rho_12 D    890    888     20\n",
      "\n",
      "Gomory fractional cuts applied:  1\n",
      "User cuts applied:  149\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.06 sec. (1.52 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =    0.45 sec. (211.04 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    0.52 sec. (212.56 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-3 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| p_age_first_offense<=19                      |         1 points |   + ..... |\n",
      "| current_violent>=1                           |         1 points |   + ..... |\n",
      "| prior_conviction_M>=7                        |         1 points |   + ..... |\n",
      "| violent_conviction>=5                        |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 4                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "model_id, score_thresholds 0 {'rank_abs': [4]}\n",
      "get_disparity_predefined_group()\n"
     ]
    }
   ],
   "source": [
    "riskslim_summary = slim.risk_cv(X=sub_X, \n",
    "                                Y=sub_Y, \n",
    "                                indicator=indicator,\n",
    "                                y_label='recid_violent2', \n",
    "                                max_coef=20, \n",
    "                                max_coef_number=10, \n",
    "                                max_runtime=200, \n",
    "                                c=1e-6, \n",
    "                                seed=816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6718532238478044, 0.6637897653857593)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(riskslim_summary['train_auc']), np.mean(riskslim_summary['test_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arnold PSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/broward_arnold.csv\")\n",
    "X_arnold_raw = data['arnold_nvca_raw'].values\n",
    "Y_arnold = data['recid_violent2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up cross validation\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=816)\n",
    "raw_auc = []\n",
    "\n",
    "## raw score\n",
    "i = 1\n",
    "for train, test in cv.split(X_arnold_raw, Y_arnold):\n",
    "    y_pred_raw, y_test = X_arnold_raw[test], Y_arnold[test]\n",
    "    raw_auc.append(roc_auc_score(y_test, y_pred_raw))\n",
    "    i+=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'summary_violent2_broward_interp' (dict)\n"
     ]
    }
   ],
   "source": [
    "#### save results\n",
    "summary_violent2_broward_interp = {\"CART\": cart_summary,\n",
    "                                   \"EBM\": ebm_summary, \n",
    "                                   'Lasso Stumps': stump_summary, \n",
    "                                   'RiskSLIM': riskslim_summary, \n",
    "                                   'Arnold PSA Raw': raw_auc}\n",
    "%store summary_violent2_broward_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CART', 0.619227380329298, 0.060089375526912625],\n",
       " ['EBM', 0.6750425985586144, 0.035468888427059884],\n",
       " ['Lasso Stumps', 0.6810825736881314, 0.03892631709527117],\n",
       " ['RiskSLIM', 0.6637897653857593],\n",
       " ['Arnold PSA Raw', 0.649]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [[\"CART\", np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs'])],\n",
    "           [\"EBM\", np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs'])], \n",
    "           [\"Lasso Stumps\", np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs'])],\n",
    "           ['RiskSLIM', np.mean(riskslim_summary['test_auc'])],\n",
    "           ['Arnold PSA Raw', round(np.mean(raw_auc), 3)]]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = [np.mean(cart_summary['holdout_test_auc']), \n",
    "       np.mean(ebm_summary['holdout_test_auc']), \n",
    "       np.mean(stump_summary['holdout_test_auc']), \n",
    "       np.mean(riskslim_summary['test_auc'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/broward models/model results/Advanced Models/Two Year/\"\n",
    "results = [[\"Violent\", np.str((round(np.mean(cart_summary['holdout_test_auc']), 3))) + \" (\" + np.str(round(np.std(cart_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(ebm_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(ebm_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(stump_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(stump_summary['holdout_test_auc']), 3)) + \")\",             \n",
    "            np.str(round(np.mean(riskslim_summary['test_auc']),3)) + \" (\" + np.str(round(np.std(riskslim_summary['test_auc']), 3)) + \")\", \n",
    "            round(np.max(auc) - np.min(auc), 3),\n",
    "            np.str(round(np.mean(raw_auc), 3)) + \" (\" + np.str(round(np.std(raw_auc),3)) + \")\", \n",
    "            '-']]\n",
    "with open(path + 'Interpretable Models Summary.csv', 'a') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
