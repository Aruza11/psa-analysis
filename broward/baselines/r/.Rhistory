knitr::opts_chunk$set(warning=F, message=F,echo = TRUE)
knitr::opts_knit$set(root.dir = '/tmp')
library(xgboost)
install.packages("xgboost")
library(xgboost)
train <- readRDS("~/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/train.rds")
test <- readRDS("~/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/test.rds")
library(xgboost)
## Format for xgboost
train_xgb = xgb.DMatrix(
"data" = train %>% select(-recid_use) %>% data.matrix(),
"label" = train %>% select(recid_use) %>% data.matrix() - 1
)
library(dplyr)
## Format for xgboost
train_xgb = xgb.DMatrix(
"data" = train %>% select(-recid_use) %>% data.matrix(),
"label" = train %>% select(recid_use) %>% data.matrix() - 1
)
param_xgb <- list(
objective = "binary:logistic",
eta = c(.1),
gamma = c(.1),
max_depth = c(6),
min_child_weight = c(5),
subsample = c(1),
colsample_bytree = c(1),
early_stopping_rounds=10
)
param_xgb = expand.grid(param_xgb) # Each row is a set of parameters to be cross validated
# Only one value for each of these parameters is allowed
setup_xgb = list(
nrounds=10000,
nfold=5
)
set.seed(2812)
out_xgb = fit_xgb_auc(train_xgb, test, param_xgb, setup_xgb)
library(tidyverse)
library(magrittr)
library(ROCR)
source('baseline_util.R')
log_path = "C:/Users/Caroline Wang/OneDrive/Duke/Criminal Recidivism/psa-analysis/broward/logs/baselines/"
set.seed(2812)
out_xgb = fit_xgb_auc(train_xgb, test, param_xgb, setup_xgb)
out_xgb$performance
knitr::opts_chunk$set(warning=F, message=F,echo = TRUE)
knitr::opts_knit$set(root.dir = '/tmp')
library(tidyverse)
library(magrittr)
library(ROCR)
source('baseline_util.R')
log_path = "C:/Users/Caroline Wang/OneDrive/Duke/Criminal Recidivism/psa-analysis/broward/logs/baselines/"
fit_glm_auc()
?fit_glm_auc()
train <- readRDS("~/Duke/Cynthia Research/psa-analysis-gitversion/broward/data/train.rds")
test <- readRDS("~/Duke/Cynthia Research/psa-analysis-gitversion/broward/data/test.rds")
setup_glm = list(
nfold=5
)
out_glm = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_glm_auc(test, setup_glm)
View(out_glm)
out_glm$performance
plot(out_glm$roc,
print.auc = T,
main = paste("GLM ROC curve using N = ", nrow(test)),
legacy.axes = T,
grid =T )
out_glm$performance
setup_glm = list(
nfold=5
)
out_glm = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_glm_auc(test, setup_glm)
out_glm$performance
log_path = "~/Documents"
log_performance(out_glm, log_path, "glm")
log_path = "~Documents"
log_performance(out_glm, log_path, "glm")
log_path = "~Documents/Duke"
log_path = "~Documents/Duke"
log_performance(out_glm, log_path, "glm")
log_path = "~/Documents/Duke"
log_performance(out_glm, log_path, "glm")
out_glm$performance
View(train)
options(java.parameters = "-Xmx2g")
library(bartMachine)
install.packages("bartMachine")
options(java.parameters = "-Xmx2g")
library(bartMachine)
install.packages("rJava")
options(java.parameters = "-Xmx2g")
library(bartMachine)
options(java.parameters = "-Xmx2g")
library(rJava)
library(glmnet)
setup_lasso = list(
nfold=5
)
out_lasso = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_lasso_auc(test, setup_lasso)
#output res
out_lasso$performance
options(java.parameters = "-Xmx2g")
library(bartMachine)
library("rJava", lib.loc="~/R/win-library/3.4")
options(java.parameters = "-Xmx2g")
library(bartMachine)
library(rpart)
setup_cart = list(
nfold=5
)
param_cart = expand.grid(list(
cp=c(.01, .05),
minsplit = c(20,40),
maxdepth = c(15,30)
)
)
out_cart =  train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_cart_auc(test, param_cart, setup_cart)
out_cart$performance
setup_svm = list(
nfold=5
)
param_svm = expand.grid(list(
type = 'C-classification',
cost = c(0.5,1,2),
epsilon = .1, # This parameter isn't used for classification but need to set anyway or it will break
gamma = c(0.5,1,2)
))
out_svm = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_svm_auc(test, param_svm, setup_svm)
library(tidyverse)
library(magrittr)
library(ROCR)
source('baseline_util.R')
log_path = "C:/Users/Caroline Wang/OneDrive/Duke/Criminal Recidivism/psa-analysis/broward/logs/baselines/"
data_path = "../data/"
load(paste0(data_path, "expanded_features.Rdata"))
load(paste0(data_path, "compas_psa.Rdata"))
### Add useful columns to features and apply row filters used for all models
features_filt = features_before_on %>%
inner_join(
data_before %>%
select(person_id, screening_date, people) %>%
unnest() %>%
select(person_id, screening_date, race, sex, name),
by = c("person_id","screening_date")
) %>%
mutate(sex = ifelse(sex == "Male", 0, 1)) %>% #change sex variable to numeric encoding
inner_join(features_on, by = c("person_id","screening_date")) %>%
inner_join(
psa_features%>%
select(-c(p_current_age,p_prison)),
by = c("person_id","screening_date"))%>%
inner_join(outcomes, by = c("person_id","screening_date")) %>%
filter(`Risk of Recidivism_decile_score` != -1, `Risk of Violence_decile_score` != -1) %>% # Filter 1
filter(!is.na(current_offense_date)) %>% # Filter 3
filter(screening_date <= current_offense_date_limit) %>% # Filter 4
mutate(recid_use = as.factor(recid), # Select recidivism or violent recidivism to use in this script
decile_use = `Risk of Recidivism_decile_score`) # Select recidivism or violent recidivism decile score to use in this script
## Select features
df = features_filt %>%
transmute(
person_id,
sex,
#COMPAS Risk of Recidivism Features\
p_current_age,
p_age_first_offense,
p_charge,
p_jail30 = p_jail30,
p_prison = p_prison,
p_probation = p_probation,
#COMPAS Risk of violent recidivism features
p_juv_fel_count,
p_felprop_violarrest,
p_murder_arrest,
p_felassault_arrest,
p_misdemassault_arrest,
p_famviol_arrest,
p_sex_arrest,
p_weapons_arrest,
#PSA Features (which were not named above)
fail_appear_two_yr,
fail_appear_two_plus,
current_violent,
current_violent20,
pending_charge,
prior_conviction_F,
prior_conviction_M,
violent_conviction,
total_convictions,
#Misc Features
p_arrest,
p_property,
p_traffic,
p_drug,
p_dui,
p_domestic,
p_stalking,
p_voyeurism,
p_fraud,
p_stealing,
p_trespass,
recid_use) %>%
na.omit()
df = df[1:100,] # Comment for full training set. This is just for testing.
set.seed(283)
train = sample_frac(df,.8)
test = anti_join(df, train, by = 'person_id') #change to account for screening date!
scores_outcomes = compas_psa_wide %>%
filter(`Risk of Violence_decile_score`>=0,
`Risk of Recidivism_decile_score`>=0,
`Risk of Failure to Appear_decile_score`>=0)%>%
left_join(outcomes, by=c("person_id","screening_date")) %>%
mutate(in_test = person_id %in% test$person_id)
train = select(train, -person_id)
test = select(test, -person_id)
#Only 353 obs remain when we only consider individuals in test set for Arnold PSA, so we also consider all non-na obs.
data = "arnold_nona"
if (data == "heldout_test"){scores_outcomes = scores_outcomes %>% filter(in_test == T)}
if (data == "arnold_nona"){scores_outcomes = scores_outcomes = scores_outcomes %>% filter(!is.na(arnold_nca_raw))}
pred_arnold_nca_raw = prediction(scores_outcomes$arnold_nca_raw, scores_outcomes$recid)
pred_arnold_nca = prediction(scores_outcomes$arnold_nca,scores_outcomes$recid)
pred_RR_raw = prediction(scores_outcomes$`Risk of Recidivism_raw_score`,scores_outcomes$recid)
pred_RR_decile = prediction(scores_outcomes$`Risk of Recidivism_decile_score`,scores_outcomes$recid)
riskscore_aucs = data.frame(
"Score" = c(paste0("Arnold NCA Raw ", data),
paste0("Arnold NCA ", data),
paste0("COMPAS Risk of Recid Raw ",data),
paste0("COMPAS Risk of Recid Decile f",data)),
"heldout_test_auc" = c(
performance(pred_arnold_nca_raw, "auc")@y.values[[1]],
performance(pred_arnold_nca, "auc")@y.values[[1]],
performance(pred_RR_raw, "auc")@y.values[[1]],
performance(pred_RR_decile, "auc")@y.values[[1]]
),
"heldout_test_acc" = c(
max(performance(pred_arnold_nca_raw, "acc")@y.values[[1]]),
max(performance(pred_arnold_nca, "acc")@y.values[[1]]),
max(performance(pred_RR_raw, "acc")@y.values[[1]]),
max(performance(pred_RR_decile, "acc")@y.values[[1]])
),
"Number of observations" = c(
nrow(scores_outcomes),
nrow(scores_outcomes),
nrow(scores_outcomes),
nrow(scores_outcomes)
)
)
train <- readRDS("~/Duke/Cynthia Research/psa-analysis-gitversion/broward/data/train.rds")
test <- readRDS("~/Duke/Cynthia Research/psa-analysis-gitversion/broward/data/test.rds")
setup_glm = list(
nfold=5
)
out_glm = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_glm_auc(test, setup_glm)
library(tidyverse)
library(magrittr)
library(ROCR)
source('baseline_util.R')
log_path = "C:/Users/Caroline Wang/OneDrive/Duke/Criminal Recidivism/psa-analysis/broward/logs/baselines/"
library(tidyverse)
library(magrittr)
library(ROCR)
source('baseline_util.R')
log_path = "C:/Users/Caroline Wang/OneDrive/Duke/Criminal Recidivism/psa-analysis/broward/logs/baselines/"
data_path = "../data/"
load(paste0(data_path, "expanded_features.Rdata"))
load(paste0(data_path, "compas_psa.Rdata"))
### Add useful columns to features and apply row filters used for all models
features_filt = features_before_on %>%
inner_join(
data_before %>%
select(person_id, screening_date, people) %>%
unnest() %>%
select(person_id, screening_date, race, sex, name),
by = c("person_id","screening_date")
) %>%
mutate(sex = ifelse(sex == "Male", 0, 1)) %>% #change sex variable to numeric encoding
inner_join(features_on, by = c("person_id","screening_date")) %>%
inner_join(
psa_features%>%
select(-c(p_current_age,p_prison)),
by = c("person_id","screening_date"))%>%
inner_join(outcomes, by = c("person_id","screening_date")) %>%
filter(`Risk of Recidivism_decile_score` != -1, `Risk of Violence_decile_score` != -1) %>% # Filter 1
filter(!is.na(current_offense_date)) %>% # Filter 3
filter(screening_date <= current_offense_date_limit) %>% # Filter 4
mutate(recid_use = as.factor(recid), # Select recidivism or violent recidivism to use in this script
decile_use = `Risk of Recidivism_decile_score`) # Select recidivism or violent recidivism decile score to use in this script
## Select features
df = features_filt %>%
transmute(
person_id,
sex,
#COMPAS Risk of Recidivism Features\
p_current_age,
p_age_first_offense,
p_charge,
p_jail30 = p_jail30,
p_prison = p_prison,
p_probation = p_probation,
#COMPAS Risk of violent recidivism features
p_juv_fel_count,
p_felprop_violarrest,
p_murder_arrest,
p_felassault_arrest,
p_misdemassault_arrest,
p_famviol_arrest,
p_sex_arrest,
p_weapons_arrest,
#PSA Features (which were not named above)
fail_appear_two_yr,
fail_appear_two_plus,
current_violent,
current_violent20,
pending_charge,
prior_conviction_F,
prior_conviction_M,
violent_conviction,
total_convictions,
#Misc Features
p_arrest,
p_property,
p_traffic,
p_drug,
p_dui,
p_domestic,
p_stalking,
p_voyeurism,
p_fraud,
p_stealing,
p_trespass,
recid_use) %>%
na.omit()
df = df[1:100,] # Comment for full training set. This is just for testing.
set.seed(283)
train = sample_frac(df,.8)
test = anti_join(df, train, by = 'person_id') #change to account for screening date!
scores_outcomes = compas_psa_wide %>%
filter(`Risk of Violence_decile_score`>=0,
`Risk of Recidivism_decile_score`>=0,
`Risk of Failure to Appear_decile_score`>=0)%>%
left_join(outcomes, by=c("person_id","screening_date")) %>%
mutate(in_test = person_id %in% test$person_id)
train = select(train, -person_id)
test = select(test, -person_id)
# saveRDS(train, file="train.rds")
# saveRDS(test, file="test.rds")
setup_glm = list(
nfold=5
)
out_glm = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_glm_auc(test, setup_glm)
out_glm$performance
library(glmnet)
setup_lasso = list(
nfold=5
)
out_lasso = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_lasso_auc(test, setup_lasso)
#output res
out_lasso$performance
out_lasso = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_lasso_auc(test, setup_lasso)
#output res
out_lasso$performance
out_lasso = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_lasso_auc(test, setup_lasso)
#output res
out_lasso$performance
setup_glm = list(
nfold=5
)
out_glm = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_glm_auc(test, setup_glm)
out_glm$performance
train <- readRDS("~/Duke/Cynthia Research/psa-analysis-gitversion/broward/data/train.rds")
test <- readRDS("~/Duke/Cynthia Research/psa-analysis-gitversion/broward/data/test.rds")
View(train)
knitr::opts_chunk$set(warning=F, message=F,echo = TRUE)
knitr::opts_knit$set(root.dir = '/tmp')
library(tidyverse)
library(magrittr)
library(ROCR)
source('baseline_util.R')
log_path = "C:/Users/binha/Documents/Duke/Cynthia Research"
test <- readRDS("~/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/test.rds")
train <- readRDS("~/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/train.rds")
## Format for xgboost
train_xgb = xgb.DMatrix(
"data" = train %>% select(-recid_use) %>% data.matrix(),
"label" = train %>% select(recid_use) %>% data.matrix() - 1
)
library(tidyverse)
library(magrittr)
library(ROCR)
source('baseline_util.R')
log_path = "C:/Users/binha/Documents/Duke/Cynthia Research"
library(xgboost)
## Format for xgboost
train_xgb = xgb.DMatrix(
"data" = train %>% select(-recid_use) %>% data.matrix(),
"label" = train %>% select(recid_use) %>% data.matrix() - 1
)
# Specify each parameter as a single value or a vector of values
# Each combination will be tested
# param_xgb <- list(
#   objective = "binary:logistic",
#   eta = c(.01,.1),
#   gamma = c(.01,.1),
#   max_depth = c(2,6),
#   min_child_weight = c(.1,5),
#   subsample = c(0.5,1),
#   colsample_bytree = c(1),
#   early_stopping_rounds=50
# )
param_xgb <- list(
objective = "binary:logistic",
eta = c(.1),
gamma = c(.1),
max_depth = c(6),
min_child_weight = c(5),
subsample = c(1),
colsample_bytree = c(1),
early_stopping_rounds=10
)
param_xgb = expand.grid(param_xgb) # Each row is a set of parameters to be cross validated
# Only one value for each of these parameters is allowed
setup_xgb = list(
nrounds=10000,
nfold=5
)
set.seed(2812)
out_xgb = fit_xgb_auc(train_xgb, test, param_xgb, setup_xgb)
out_xgb$performance
plot(out_xgb$roc,
print.auc = T,
main = paste("XGBoost ROC curve using N = ", nrow(test)),
legacy.axes = T,
grid =T )
log_performance(out_xgb, log_path, "xgb_performance")
log_path = "C:/Users/binha/Documents/Duke/Cynthia Research/"
log_performance(out_xgb, log_path, "xgb_performance")
out_xgb$performance
setup_glm = list(
nfold=5
)
out_glm = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_glm_auc(test, setup_glm)
out_glm$performance
setup_glm = list(
nfold=5
)
out_glm = train %>%
mutate(y = as.factor(recid_use)) %>%
select(-recid_use) %>%
fit_glm_auc(test, setup_glm)
out_glm$performance
