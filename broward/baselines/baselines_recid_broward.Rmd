---
title: "baselines_recid_broward"
author: "Beau Coker"
date: "11/5/2018"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(warning=F, message=F,echo = TRUE)
knitr::opts_knit$set(root.dir = '/tmp')
```


Here, we use out-of-box ML methods to get baselines for the recidivism prediction problem
```{r include = FALSE}
library(tidyverse)
library(magrittr)
library(ROCR)
source('baseline_util.R')
log_path = "C:/Users/Caroline Wang/OneDrive/Duke/Criminal Recidivism/psa-analysis/logs/baselines/"
```

```{r}
load("expanded_features.Rdata")
load("compas_psa.Rdata")
```

### Prepare data 
Data processing is similar to Age of Unfairness repo except we remove var caps here.
```{r}
### Add useful columns to features and apply row filters used for all models
features_filt = features_before_on %>%
  inner_join(
    data_before %>% 
      select(person_id, screening_date, people) %>%
      unnest() %>%
      select(person_id, screening_date, race, sex, name),
    by = c("person_id","screening_date")
  ) %>%
  mutate(sex = ifelse(sex == "Male", 0, 1)) %>% #change sex variable to numeric encoding
  inner_join(features_on, by = c("person_id","screening_date")) %>%
  inner_join(
    psa_features%>%
      select(-c(p_current_age,p_prison)), 
    by = c("person_id","screening_date"))%>%
  inner_join(outcomes, by = c("person_id","screening_date")) %>%
  filter(`Risk of Recidivism_decile_score` != -1, `Risk of Violence_decile_score` != -1) %>% # Filter 1
  filter(!is.na(current_offense_date)) %>% # Filter 3
  filter(screening_date <= current_offense_date_limit) %>% # Filter 4
  mutate(recid_use = as.factor(recid), # Select recidivism or violent recidivism to use in this script 
         decile_use = `Risk of Recidivism_decile_score`) # Select recidivism or violent recidivism decile score to use in this script

## Select features
df = features_filt %>%
  transmute(
    person_id,
    sex,
    #COMPAS Risk of Recidivism Features\
    p_current_age,
    p_age_first_offense,
    p_charge,
    p_jail30 = p_jail30,
    p_prison = p_prison,
    p_probation = p_probation,
    
    #COMPAS Risk of violent recidivism features
    p_juv_fel_count,
    p_felprop_violarrest,
    p_murder_arrest,
    p_felassault_arrest,
    p_misdemassault_arrest,
    p_famviol_arrest,
    p_sex_arrest,
    p_weapons_arrest,
    
    #PSA Features (which were not named above)
    fail_appear_two_yr, 
    fail_appear_two_plus,
    current_violent, 
    current_violent20, 
    pending_charge, 
    prior_conviction_F, 
    prior_conviction_M, 
    violent_conviction, 
    total_convictions, 
    
    #Misc Features
    p_arrest,
    p_property,
    p_traffic,
    p_drug,
    p_dui,
    p_domestic,
    p_stalking,
    p_voyeurism,
    p_fraud,
    p_stealing,
    p_trespass,
    recid_use) %>%
  na.omit()
df = df[1:100,] # Comment for full training set. This is just for testing.

set.seed(283)
train = sample_frac(df,.8)
test = anti_join(df, train, by = 'person_id') #change to account for screening date!

scores_outcomes = compas_psa_wide %>%
                  filter(`Risk of Violence_decile_score`>=0, 
                         `Risk of Recidivism_decile_score`>=0, 
                         `Risk of Failure to Appear_decile_score`>=0)%>%
                  left_join(outcomes, by=c("person_id","screening_date")) %>%
                  mutate(in_test = person_id %in% test$person_id)

train = select(train, -person_id)
test = select(test, -person_id)
# saveRDS(train, file="train.rds")
# saveRDS(test, file="test.rds")

```

### COMPAS and ARNOLD PSA AUC 
```{r}
#Only 353 obs remain when we only consider individuals in test set for Arnold PSA, so we also consider all non-na obs. 
data = "arnold_nona"
if (data == "heldout_test"){scores_outcomes = scores_outcomes %>% filter(in_test == T)}
if (data == "arnold_nona"){scores_outcomes = scores_outcomes = scores_outcomes %>% filter(!is.na(arnold_nca_raw))}


pred_arnold_nca_raw = prediction(scores_outcomes$arnold_nca_raw, scores_outcomes$recid)
pred_arnold_nca = prediction(scores_outcomes$arnold_nca,scores_outcomes$recid)
pred_RR_raw = prediction(scores_outcomes$`Risk of Recidivism_raw_score`,scores_outcomes$recid)
pred_RR_decile = prediction(scores_outcomes$`Risk of Recidivism_decile_score`,scores_outcomes$recid)

riskscore_aucs = data.frame(
  "Score" = c(paste0("Arnold NCA Raw ", data), 
              paste0("Arnold NCA ", data), 
              paste0("COMPAS Risk of Recid Raw ",data), 
              paste0("COMPAS Risk of Recid Decile f",data)),

  "heldout_test_auc" = c(
    performance(pred_arnold_nca_raw, "auc")@y.values[[1]],
    performance(pred_arnold_nca, "auc")@y.values[[1]],
    performance(pred_RR_raw, "auc")@y.values[[1]],
    performance(pred_RR_decile, "auc")@y.values[[1]]
  ),
  
  "heldout_test_acc" = c(
    max(performance(pred_arnold_nca_raw, "acc")@y.values[[1]]),
    max(performance(pred_arnold_nca, "acc")@y.values[[1]]),
    max(performance(pred_RR_raw, "acc")@y.values[[1]]),
    max(performance(pred_RR_decile, "acc")@y.values[[1]])
  ),
  
  "Number of observations" = c(
    nrow(scores_outcomes),
    nrow(scores_outcomes),
    nrow(scores_outcomes),
    nrow(scores_outcomes)
  )
  
)

knitr::kable(riskscore_aucs, format = 'markdown')
write.csv(riskscore_aucs, paste0(log_path, "model_eval_metrics/riskscore_aucs_", data, ".csv"))

```

```{r}
riskscore_roc_inputs = list(
  list(scores_outcomes$recid, 
       scores_outcomes$arnold_nca_raw, 
       "Arnold NCA Raw"
  ),
  list(scores_outcomes$recid, 
       scores_outcomes$`arnold_nca`, 
       "Arnold NCA"
  ),
                            
  list(scores_outcomes$recid, 
       scores_outcomes$`Risk of Recidivism_raw_score`, 
       "Risk of Recidivism Raw Score"
  ),
  list(scores_outcomes$recid, 
       scores_outcomes$`Risk of Recidivism_decile_score`, 
       "Risk of Recidivism Decile Score "
  )
)

#Plotting ROC curves 
for(i in c(1,2,3,4)){
    #compute performance measures using ROCR package
  labels = riskscore_roc_inputs[[i]][[1]]
  preds = riskscore_roc_inputs[[i]][[2]]
  pred_obj = prediction(preds, labels)
  
  perf_roc = performance(pred_obj, "tpr", "fpr")

  plot(perf_roc,
       print.auc = T,
       main = paste(riskscore_roc_inputs[[i]][[3]]," ROC curve"),
       legacy.axes = T,
       grid =T )
  
}
```

Class balance
```{r}
#percent recidivated
(features_filt%>%filter(recid_use == 1) %>% nrow()) / (nrow(features_filt))

```


### Train xgboost
```{r include = FALSE}
library(xgboost)
```


```{r}
## Format for xgboost
train_xgb = xgb.DMatrix(
  "data" = train %>% select(-recid_use) %>% data.matrix(),
  "label" = train %>% select(recid_use) %>% data.matrix() - 1
)

# Specify each parameter as a single value or a vector of values
# Each combination will be tested
# param_xgb <- list(
#   objective = "binary:logistic",
#   eta = c(.01,.1),
#   gamma = c(.01,.1),
#   max_depth = c(2,6),
#   min_child_weight = c(.1,5),
#   subsample = c(0.5,1),
#   colsample_bytree = c(1),
#   early_stopping_rounds=50
# )

param_xgb <- list(
  objective = "binary:logistic",
  eta = c(.1),
  gamma = c(.1),
  max_depth = c(6),
  min_child_weight = c(5),
  subsample = c(1),
  colsample_bytree = c(1),
  early_stopping_rounds=10
)

param_xgb = expand.grid(param_xgb) # Each row is a set of parameters to be cross validated

# Only one value for each of these parameters is allowed
setup_xgb = list(
  nrounds=10000,
  nfold=5
)
```

```{r}
set.seed(2812)
out_xgb = fit_xgb_auc(train_xgb, test, param_xgb, setup_xgb)
```

```{r}
out_xgb$performance

plot(out_xgb$roc,
     print.auc = T,
     main = paste("XGBoost ROC curve using N = ", nrow(test)),
     legacy.axes = T,
     grid =T )

log_performance(out_xgb, log_path, "xgb_performance")

```

### Train BART

```{r include = FALSE}
options(java.parameters = "-Xmx2g") 
library(bartMachine)
```


```{r}
param_bart = expand.grid(list(
  num_trees = c(50, 75),
  alpha = 0.95, 
  beta = 2, 
  k = c(2), 
  q = 0.9, 
  nu = 3)
)

setup_bart = list(
  nfold=2
)

out_bart = train %>%
  mutate(y = as.factor(recid_use)) %>%
  select(-recid_use) %>%
  fit_bart_auc(test, param_bart,setup_bart)
```

  i_param seed train_auc_mean train_auc_std test_auc_mean test_auc_std
1       1 5908      0.7317067    0.01156313     0.7041193   0.01156313
2       2 8371      0.7340461    0.01171209     0.7064116   0.01171209
```{r}
out_bart$performance

plot(out_bart$roc,
     print.auc = T,
     main = paste("BART ROC curve using N = ", nrow(test)),
     legacy.axes = T,
     grid =T )

log_performance(out_bart, log_path, "bart")


```


```{r}
plot_convergence_diagnostics(out_bart$mdl_best)
```

```{r}
investigate_var_importance(out_bart$mdl_best, num_replicates_for_avg = 20)
```


### Train logistic regression classifier
train_auc_mean train_auc_std test_auc_mean test_auc_std
1      0.7034106   0.004943927     0.6955958  0.004943927
```{r include = FALSE}
setup_glm = list(
  nfold=5
)

out_glm = train %>%
          mutate(y = as.factor(recid_use)) %>%
          select(-recid_use) %>%
          fit_glm_auc(test, setup_glm)
```

```{r}
out_glm$performance
plot(out_glm$roc,
     print.auc = T,
     main = paste("GLM ROC curve using N = ", nrow(test)),
     legacy.axes = T,
     grid =T )

log_performance(out_glm, log_path, "glm")

```

### Train LASSO 
  seed train_auc_mean train_auc_std test_auc_mean test_auc_std
1 8363      0.7011165    0.00243117     0.6962465   0.00243117
```{r include = FALSE}
library(glmnet)
setup_lasso = list(
  nfold=5
  
)
```

```{r}
out_lasso = train %>%
          mutate(y = as.factor(recid_use)) %>%
          select(-recid_use) %>%
          fit_lasso_auc(test, setup_lasso)

#output res
out_lasso$performance
plot(out_lasso$roc,
     print.auc = T,
     main = paste("LASSO ROC curve using N = ", nrow(test)),
     legacy.axes = T,
     grid =T )
#log res
log_performance(out_lasso, log_path, "lasso")
```

### Train random forest
 seed train_auc_mean train_auc_std test_auc_mean test_auc_std
1  784      0.8856112   0.003304293     0.6066994  0.003304293

```{r include = FALSE}
library(randomForest)
setup_rf = list(
  nfold=5, 
  seed = 784
)

```



```{r}
out_rf =  train %>%
          mutate(y = as.factor(recid_use)) %>%
          select(-recid_use) %>%
          fit_rf_auc(test, setup_rf)

out_rf$performance

plot(out_rf$roc,
     print.auc = T,
     main = paste("RF ROC curve using N = ", nrow(test)),
     legacy.axes = T,
     grid =T )

log_performance(out_rf, log_path, "rf")
```

### Train CART
  i_param seed train_auc_mean train_auc_std test_auc_mean test_auc_std
1       1 5163      0.6135910    0.01825666     0.6048626   0.01825666
2       2 6402      0.5416409    0.05702557     0.5361078   0.05702557
3       3 4991      0.6135910    0.01825666     0.6048626   0.01825666
4       4 1511      0.5416409    0.05702557     0.5361078   0.05702557
5       5 3526      0.6135910    0.01825666     0.6048626   0.01825666
6       6 1592      0.5416409    0.05702557     0.5361078   0.05702557
7       7  181      0.6135910    0.01825666     0.6048626   0.01825666
8       8  805      0.5416409    0.05702557     0.5361078   0.05702557
```{r include = FALSE}
library(rpart)
setup_cart = list(
  nfold=5
)

param_cart = expand.grid(list(
  cp=c(.01, .05), 
  minsplit = c(20,40), 
  maxdepth = c(15,30)
  )
)
```


```{r}
out_cart =  train %>%
          mutate(y = as.factor(recid_use)) %>%
          select(-recid_use) %>%
          fit_cart_auc(test, param_cart, setup_cart)

out_cart$performance

plot(out_cart$roc,
     print.auc = T,
     main = paste("CART ROC curve using N = ", nrow(test)),
     legacy.axes = T,
     grid =T )

log_performance(out_cart, log_path, "cart")

```



### Train SVM
```{r}
setup_svm = list(
  nfold=5
)

param_svm = expand.grid(list(
  type = 'C-classification',
  cost = c(0.5,1,2),
  epsilon = .1, # This parameter isn't used for classification but need to set anyway or it will break
  gamma = c(0.5,1,2)
))

```


```{r}
out_svm = train %>%
          mutate(y = as.factor(recid_use)) %>%
          select(-recid_use) %>%
          fit_svm_auc(test, param_svm, setup_svm)

out_svm$performance

plot(out_svm$roc,
     print.auc = T,
     main = paste("SVM ROC curve using N = ", nrow(test)),
     legacy.axes = T,
     grid =T )

log_performance(out_svm, log_path, "svm")


```


CORELS - Angelino
Recidivism is defined as being charged with a new crime within two years

```{r}
CORELS <- function(p_current_age,sex,priors){
  if(p_current_age %in% c(18,19,20) & sex == "Male"){
    return(1)
  }
  else if(p_current_age %in% c(21,22) & priors %in% c(2,3)) {
    return(1)
  }
  
  #equiv rule list
  else if(p_current_age %in% c(23,24,25) & priors %in% c(2,3)) {
    return(1)
  }

  else if (priors > 3)
    return(1)
  
  else {
    return(0)
  }
}

test_nona = test %>% na.omit()%>%select(recid_use, p_current_age, sex, p_charge) 
cat("Number rows in test set",nrow(test_nona), "\n")
CORELS_preds = apply(test_nona, 1, function(df) CORELS(df['p_current_age'], 
                                                  df['sex'], 
                                                  df['p_charge']))

test_labels = test_nona %>% select(recid_use) %>% unlist()%>%as.numeric() -1
#compute accuracy
cat("Accuracy: ",sum(if_else(test_labels == CORELS_preds, 1, 0)) / length(test_labels), "\n" )

#compute AUC
pROC::auc(test_labels, CORELS_preds)

```

RiskSLIM 

PREDICT STRING:  Pr(RECID_USE = +1) = 1/(1 + exp(-1 - score)  TOTAL STRING:  ADD POINTS FROM ROWS 1 to 3  RHO_NAMES:  ['p_current_age18', 'p_current_age1929', 'prior_conviction_M57']
+-----------------------------------------------+------------------+-----------+
| Pr(RECID_USE = +1) = 1/(1 + exp(-1 - score)   |                  |           |
| ============================================= | ================ | ========= |
| p_current_age18                               |         2 points |   + ..... |
| p_current_age1929                             |         1 points |   + ..... |
| prior_conviction_M57                          |         1 points |   + ..... |
| ============================================= | ================ | ========= |
| ADD POINTS FROM ROWS 1 to 3                   |            SCORE |   = ..... |


```{r}
riskSLIM <- function(p_current_age,prior_conviction_M){
  score = 0
  if(p_current_age == 18){
    score = score + 2
  }
  if(p_current_age %in% c(19:29) ) {
    score = score + 1
  }
  
  #equiv rule list
  if(prior_conviction_M %in% c(5,6,7)) {
    score = score + 1
  }

  return(1/(1+exp(-1-score)))
         
}

test_nona_riskSLIM = test %>% select(recid_use, p_current_age, prior_conviction_M) %>%na.omit()
cat("Number rows in test set",nrow(test_nona_riskSLIM), "\n")
riskSLIM_preds = apply(test_nona_riskSLIM, 1, function(df) riskSLIM(df['p_current_age'], 
                                                  df['prior_conviction_M'] 
                                                  ))

riskSLIM_labels = test_nona_riskSLIM %>% select(recid_use) %>% unlist()%>%as.numeric() -1

#compute performance measures using ROCR package
riskSLIM_pred_obj = prediction(riskSLIM_preds, riskSLIM_labels)

riskSLIM_perf_roc = performance(riskSLIM_pred_obj, "tpr", "fpr")
riskSLIM_perf_acc = performance(riskSLIM_pred_obj, "acc")
riskSLIM_perf_auc = performance(riskSLIM_pred_obj, "auc")

riskSLIM_acc = max(riskSLIM_perf_acc@y.values[[1]])
riskSLIM_auc= riskSLIM_perf_auc@y.values[[1]]

cat("RiskSLIM accuracy: ", riskSLIM_acc, "\nRiskSLIM AUC: ", riskSLIM_auc)
plot(riskSLIM_perf_roc,
     # print.auc = T,
     main = "riskSLIM ROC Curve",
     legacy.axes = T,
     grid =T )

# #compute accuracy
# cat("Accuracy: ",sum(if_else(test_labels_riskSLIM == riskSLIM_preds, 1, 0)) / length(test_labels_riskSLIM), "\n" )
# 
# #compute AUC
# auc(test_labels_riskSLIM, riskSLIM_preds)


```

FRL
if ('prior_conviction_M01=0', 'p_felprop_violarrest7up=0'), then prob. = 0.531557 (+: 379, -: 334, obj.: 0.267415)
else if ('p_property13=1', 'p_felprop_violarrest2=0'), then prob. = 0.409357 (+: 70, -: 101, obj.: 0.080866)
else if ('p_current_age5059=0', 'total_convictions3=0'), then prob. = 0.394737 (+: 120, -: 184, obj.: 0.147319)
else if ('total_convictions1=0', 'p_felprop_violarrest2=0'), then prob. = 0.375000 (+: 15, -: 25, obj.: 0.020017)
else prob. = 0.000000 (+: 0, -: 21, obj.: 0.000000)

```{r}
FRL <- function(p_current_age,prior_conviction_M, p_felprop_violarrest, p_property, total_convictions){
  if(prior_conviction_M >= 2 & p_felprop_violarrest <=6 ){
    return(0.531557)
  }
  else if(p_property %in% c(1,2,3) & p_felprop_violarrest!=2 ) {
    return(0.409357)
  }
  
  else if(p_current_age < 50 & total_convictions!=3) {
    return(0.394737)
  }
  
  else if(total_convictions != 1 & p_felprop_violarrest!=2)
    return(0.375)

  return(0)
}

test_nona_FRL = test %>% select(recid_use, p_current_age, prior_conviction_M, p_felprop_violarrest, p_property, total_convictions) %>%na.omit()
cat("Number rows in test set",nrow(test_nona_FRL), "\n")
FRL_preds = apply(test_nona_FRL, 1, function(df) FRL(df['p_current_age'], 
                                                  df['prior_conviction_M'], 
                                                  df['p_felprop_violarrest'],
                                                  df['p_property'] ,
                                                  df['total_convictions'] 
                                                  ))

FRL_labels = test_nona_FRL %>% select(recid_use) %>% unlist()%>%as.numeric() -1

#compute performance measures using ROCR package
FRL_pred_obj = prediction(FRL_preds, FRL_labels)

FRL_perf_roc = performance(FRL_pred_obj, "tpr", "fpr")
FRL_perf_acc = performance(FRL_pred_obj, "acc")
FRL_perf_auc = performance(FRL_pred_obj, "auc")

FRL_acc = max(FRL_perf_acc@y.values[[1]])
FRL_auc= FRL_perf_auc@y.values[[1]]

cat("FRL accuracy: ", FRL_acc, "\nFRL AUC: ", FRL_auc)
plot(FRL_perf_roc,
     main = "FRL ROC Curve",
     legacy.axes = T,
     grid =T )

```

