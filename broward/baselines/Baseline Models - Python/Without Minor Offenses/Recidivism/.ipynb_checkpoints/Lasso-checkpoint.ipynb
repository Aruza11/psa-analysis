{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data sets\n",
    "train_pd = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/Without Minor Offenses/train_recid_use.csv\")\n",
    "test_pd = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/Without Minor Offenses/test_recid_use.csv\")\n",
    "\n",
    "## get rid of the record with 'p_age_first_offense' == 0\n",
    "train_pd = train_pd.drop(['person_id', 'screening_date'], axis=1)\n",
    "test_pd = test_pd.drop(['person_id', 'screening_date'], axis=1)\n",
    "test_pd = test_pd[test_pd['p_age_first_offense'] != 0]\n",
    "\n",
    "## split train and test\n",
    "x_train, y_train = train_pd.values[:, :-1], train_pd.values[:, -1]\n",
    "x_test, y_test = test_pd.values[:, :-1], test_pd.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['sex', 'current_violent', 'current_violent20', 'six_month', 'one_year', 'three_year', 'five_year', 'recid_drug']\n",
    "for i in variables:\n",
    "    train_pd[i] = train_pd[i].astype('category')\n",
    "    test_pd[i] = test_pd[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(X, Y, nfold, alpha, seed=816):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    @parameters:\n",
    "    - X: training set -- features\n",
    "    - Y: training set -- response variable\n",
    "    - nfold: n-folds cross validation\n",
    "    - alpha: regularazation strength\n",
    "    - seed: random state\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ## n-folds cross validation set up\n",
    "    cv = StratifiedKFold(n_splits=nfold, random_state=seed, shuffle=True)\n",
    "    #cv = KFold(n_splits=nfold, random_state=seed, shuffle=True)\n",
    "    \n",
    "    ## classifier\n",
    "    classifier = Lasso(alpha=alpha, random_state=seed)\n",
    "    train_acc, test_acc = [], []\n",
    "    train_auc, test_auc = [], []\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, Y):\n",
    "    \n",
    "        ## data & classifier\n",
    "        X_train, Y_train = X[train], Y[train]\n",
    "        X_test, Y_test = X[test], Y[test]\n",
    "        fit_model = classifier.fit(X_train, Y_train)\n",
    "    \n",
    "        ## accuracy & probability\n",
    "        train_prob = fit_model.predict(X_train)\n",
    "        test_prob = fit_model.predict(X_test)\n",
    "\n",
    "        train_acc.append(np.mean((train_prob > 0.5) == Y_train))\n",
    "        test_acc.append(np.mean((test_prob > 0.5) == Y_test))\n",
    "        \n",
    "        ## compute ROC curve and AUC\n",
    "    \n",
    "        train_fpr, train_tpr, train_thresholds = roc_curve(Y_train, train_prob)\n",
    "        test_fpr, test_tpr, test_thresholds = roc_curve(Y_test, test_prob)    \n",
    "        train_auc.append(auc(train_fpr, train_tpr))\n",
    "        test_auc.append(auc(test_fpr, test_tpr))\n",
    "        i += 1\n",
    "    \n",
    "    return train_acc, test_acc, train_auc, test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters \n",
    "-- To prevent overfitting and get as good performance as possible.\n",
    "\n",
    "-- criteria: difference between the avg. train accuracy and test accuracy and the difference between avg. train auc and avg. test auc are both smaller than 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alpha = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for a in Alpha:\n",
    "    train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 5, a)\n",
    "    auc_diff = np.mean(train_auc) - np.mean(test_auc)\n",
    "    results.append([a, np.mean(test_auc), auc_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(results, columns=['Penalty', 'Validation AUC', 'AUC Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Penalty</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>AUC Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.658771</td>\n",
       "      <td>0.034852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.658553</td>\n",
       "      <td>0.028825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.658243</td>\n",
       "      <td>0.005878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.658202</td>\n",
       "      <td>0.022269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.651787</td>\n",
       "      <td>0.004754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.642088</td>\n",
       "      <td>0.000597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.515392</td>\n",
       "      <td>0.000614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Penalty  Validation AUC  AUC Diff\n",
       "0    0.001        0.658771  0.034852\n",
       "1    0.005        0.658553  0.028825\n",
       "3    0.050        0.658243  0.005878\n",
       "2    0.010        0.658202  0.022269\n",
       "4    0.100        0.651787  0.004754\n",
       "5    0.500        0.642088  0.000597\n",
       "6    1.000        0.515392  0.000614\n",
       "7    2.000        0.500000  0.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.sort_values(by = 'Validation AUC', axis=0, ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameter: \n",
    "\n",
    "-- alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 5, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.626201662541864, 0.6219141517944962, 0.6641210915617196, 0.6582431168630263)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_acc), np.mean(test_acc), np.mean(train_auc), np.mean(test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heldout Test Set\n",
    "-- use 0.5 as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = Lasso(alpha=0.05, random_state=816).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6451612903225806"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = la.predict(x_test)\n",
    "heldout_test_acc = np.mean((prob > 0.5) == y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7049425422138836"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, prob)\n",
    "heldout_test_auc = auc(fpr, tpr)\n",
    "heldout_test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- use optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#optimal_index = np.argmin(np.sqrt(np.square(1-tpr) + np.square(fpr)))\n",
    "optimal_index = np.argmax(abs(tpr-fpr))\n",
    "optimal_threshold = thresholds[optimal_index]\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heldout_test_acc = np.mean((prob > optimal_threshold) == y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log model results to the model performance folder, as per standards\n",
    "path = \"C:\\\\Users\\\\binha\\\\Documents\\\\Duke\\\\Cynthia Research\\\\KY-analysis-mytrials\\\\broward\\\\broward models\\\\Baseline Model Results\\\\Without Minor Offenses\\\\Recidivism\\\\\"\n",
    "\n",
    "train_auc_mean, train_auc_std = np.mean(train_auc), np.std(train_auc)\n",
    "test_auc_mean, test_auc_std = np.mean(test_auc), np.std(test_auc)\n",
    "\n",
    "results = [\"Lasso\", train_auc_mean, train_auc_std, test_auc_mean, test_auc_std, heldout_test_auc, heldout_test_acc ]\n",
    "\n",
    "with open(path + 'Recidivism Summary.csv', 'a') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
