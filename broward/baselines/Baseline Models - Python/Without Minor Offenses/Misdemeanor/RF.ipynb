{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data sets\n",
    "train_pd = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/Without Minor Offenses/train_recid_M.csv\")\n",
    "test_pd = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward//data/Without Minor Offenses/test_recid_M.csv\")\n",
    "\n",
    "## get rid of the record with 'p_age_first_offense' == 0\n",
    "train_pd = train_pd.drop(['person_id', 'screening_date'], axis=1)\n",
    "test_pd = test_pd.drop(['person_id', 'screening_date'], axis=1)\n",
    "test_pd = test_pd[test_pd['p_age_first_offense'] != 0]\n",
    "\n",
    "## split train and test\n",
    "x_train, y_train = train_pd.values[:, :-1], train_pd.values[:, -1]\n",
    "x_test, y_test = test_pd.values[:, :-1], test_pd.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['sex', 'current_violent', 'current_violent20', 'six_month', 'one_year', 'three_year', 'five_year', 'recid_M']\n",
    "for i in variables:\n",
    "    train_pd[i] = train_pd[i].astype('category')\n",
    "    test_pd[i] = test_pd[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(X, Y, nfold, depth, N, min_samples_split=2, min_impurity_decrease=0, seed=816):\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    @parameters:\n",
    "    - xtrain: training set -- features\n",
    "    - ytrain: training set -- response variable\n",
    "    - nfold: n-folds cross validation\n",
    "    - depth: max split depth\n",
    "    - N: number of trees\n",
    "    - min_samples_splits: the minimum number of samples required to split an internal node\n",
    "    - min_impurity_decrease: a node will be split if that split induced a decrease of the impurity greater\n",
    "                             than or equal to this value\n",
    "    - seed: random state\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ## nfolds cross-validation set up\n",
    "    #cv = KFold(n_splits=nfold, random_state=seed, shuffle=True)\n",
    "    cv = StratifiedKFold(n_splits=nfold, random_state=seed, shuffle=True)\n",
    "    \n",
    "    ## classifier\n",
    "    classifier = RandomForestClassifier(max_depth=depth,\n",
    "                                        n_estimators=N, \n",
    "                                        min_impurity_decrease=min_impurity_decrease,\n",
    "                                        min_samples_split= min_samples_split,\n",
    "                                        bootstrap=True, \n",
    "                                        random_state=seed)\n",
    "    train_acc, test_acc = [], []\n",
    "    train_auc, test_auc = [], []\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, Y):\n",
    "    \n",
    "        ## data & classifier\n",
    "        X_train, Y_train = X[train], Y[train]\n",
    "        X_test, Y_test = X[test], Y[test]\n",
    "        fit_model = classifier.fit(X_train, Y_train)\n",
    "    \n",
    "        ## accuracy & probability\n",
    "        train_acc.append(fit_model.score(X_train, Y_train))\n",
    "        test_acc.append(fit_model.score(X_test, Y_test))\n",
    "    \n",
    "        train_prob = fit_model.predict_proba(X_train)[:,1]\n",
    "        test_prob = fit_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "        ## compute ROC curve and AUC\n",
    "    \n",
    "        train_fpr, train_tpr, train_thresholds = roc_curve(Y_train, train_prob)\n",
    "        test_fpr, test_tpr, test_thresholds = roc_curve(Y_test, test_prob)\n",
    "        train_roc_auc = auc(train_fpr, train_tpr)\n",
    "        test_roc_auc = auc(test_fpr, test_tpr)\n",
    "    \n",
    "        train_auc.append(train_roc_auc)\n",
    "        test_auc.append(test_roc_auc)\n",
    "        i += 1\n",
    "    \n",
    "    return train_acc, test_acc, train_auc, test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters \n",
    "-- To prevent overfitting and get as good performance as possible.\n",
    "\n",
    "-- criteria: difference between the avg. train accuracy and test accuracy and the difference between avg. train auc and avg. test auc are both smaller than 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Depth = [1,2,3,4,5]\n",
    "num_estimator = [30, 40, 50, 60, 70, 80, 90, 100]\n",
    "min_impurity_decrease = [0.007, 0.008, 0.009, 0.011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for d in Depth:\n",
    "    for n in num_estimator:\n",
    "        for i in min_impurity_decrease:\n",
    "            train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 5, depth=d, N=n, min_impurity_decrease=i)\n",
    "            auc_diff = np.mean(train_auc) - np.mean(test_auc)\n",
    "            results.append([d, n, i, np.mean(test_auc), auc_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(results, columns=['Depth', 'Number of Estimators', 'Min Impurity Decrease', 'Validation AUC', 'AUC Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table[table['AUC Diff'] <= 0.026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Number of Estimators</th>\n",
       "      <th>Min Impurity Decrease</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>AUC Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.616052</td>\n",
       "      <td>0.022795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.616052</td>\n",
       "      <td>0.022795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.616052</td>\n",
       "      <td>0.022795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.615887</td>\n",
       "      <td>0.021128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.614882</td>\n",
       "      <td>0.021886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.614829</td>\n",
       "      <td>0.023815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.614829</td>\n",
       "      <td>0.023815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.614829</td>\n",
       "      <td>0.023815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.614482</td>\n",
       "      <td>0.022152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.614074</td>\n",
       "      <td>0.023355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.613722</td>\n",
       "      <td>0.025601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.612983</td>\n",
       "      <td>0.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.612616</td>\n",
       "      <td>0.022509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.612300</td>\n",
       "      <td>0.022553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.612040</td>\n",
       "      <td>0.024190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.611298</td>\n",
       "      <td>0.024490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.611191</td>\n",
       "      <td>0.024946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.609462</td>\n",
       "      <td>0.025793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.608741</td>\n",
       "      <td>0.025692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.593230</td>\n",
       "      <td>0.025613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Depth  Number of Estimators  Min Impurity Decrease  Validation AUC  \\\n",
       "95       3                   100                  0.011        0.616052   \n",
       "127      4                   100                  0.011        0.616052   \n",
       "159      5                   100                  0.011        0.616052   \n",
       "63       2                   100                  0.011        0.615887   \n",
       "21       1                    80                  0.008        0.614882   \n",
       "91       3                    90                  0.011        0.614829   \n",
       "123      4                    90                  0.011        0.614829   \n",
       "155      5                    90                  0.011        0.614829   \n",
       "59       2                    90                  0.011        0.614482   \n",
       "17       1                    70                  0.008        0.614074   \n",
       "9        1                    50                  0.008        0.613722   \n",
       "13       1                    60                  0.008        0.612983   \n",
       "31       1                   100                  0.011        0.612616   \n",
       "27       1                    90                  0.011        0.612300   \n",
       "18       1                    70                  0.009        0.612040   \n",
       "22       1                    80                  0.009        0.611298   \n",
       "14       1                    60                  0.009        0.611191   \n",
       "55       2                    80                  0.011        0.609462   \n",
       "47       2                    60                  0.011        0.608741   \n",
       "7        1                    40                  0.011        0.593230   \n",
       "\n",
       "     AUC Diff  \n",
       "95   0.022795  \n",
       "127  0.022795  \n",
       "159  0.022795  \n",
       "63   0.021128  \n",
       "21   0.021886  \n",
       "91   0.023815  \n",
       "123  0.023815  \n",
       "155  0.023815  \n",
       "59   0.022152  \n",
       "17   0.023355  \n",
       "9    0.025601  \n",
       "13   0.023810  \n",
       "31   0.022509  \n",
       "27   0.022553  \n",
       "18   0.024190  \n",
       "22   0.024490  \n",
       "14   0.024946  \n",
       "55   0.025793  \n",
       "47   0.025692  \n",
       "7    0.025613  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.sort_values(by = ['Validation AUC', 'AUC Diff'], axis=0, ascending = [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameters:\n",
    "- depth: 3 / estimators: 100 / impurity decrease: 0.011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 5, depth=3, N=100, min_impurity_decrease=0.011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7268075400752256, 0.726809314797451, 0.6388476857075507, 0.6160524943994281)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_acc), np.mean(test_acc), np.mean(train_auc), np.mean(test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heldout Test Set\n",
    "-- use 0.5 as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.728494623655914"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=3, n_estimators=100, min_impurity_decrease=0.011, bootstrap=True, random_state=816).fit(x_train, y_train)\n",
    "heldout_test_acc = rf.score(x_test, y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6031200906068466"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = rf.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob)\n",
    "heldout_test_auc = auc(fpr, tpr)\n",
    "heldout_test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- use optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#optimal_index = np.argmin(np.sqrt(np.square(1-tpr) + np.square(fpr)))\n",
    "optimal_index = np.argmax(abs(tpr - fpr))\n",
    "optimal_threshold = thresholds[optimal_index]\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction = rf.predict_proba(x_test)[:,1]\n",
    "heldout_test_acc = np.mean((prediction > optimal_threshold) == y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log model results to the model performance folder, as per standards\n",
    "path = \"C:\\\\Users\\\\binha\\\\Documents\\\\Duke\\\\Cynthia Research\\\\KY-analysis-mytrials\\\\broward\\\\broward models\\\\Baseline Model Results\\\\Without Minor Offenses\\\\Misdemeanor\\\\\"\n",
    "\n",
    "train_auc_mean, train_auc_std = np.mean(train_auc), np.std(train_auc)\n",
    "test_auc_mean, test_auc_std = np.mean(test_auc), np.std(test_auc)\n",
    "                   \n",
    "results = [\"RF\", train_auc_mean, train_auc_std, test_auc_mean, test_auc_std, heldout_test_auc, heldout_test_acc ]\n",
    "\n",
    "with open(path + 'Misdemeanor Summary.csv', 'a') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
