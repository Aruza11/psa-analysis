{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data sets\n",
    "train_pd = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/Without Minor Offenses/train_recid_violent.csv\")\n",
    "test_pd = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward//data/Without Minor Offenses/test_recid_violent.csv\")\n",
    "\n",
    "## get rid of the record with 'p_age_first_offense' == 0\n",
    "train_pd = train_pd.drop(['person_id', 'screening_date'], axis=1)\n",
    "test_pd = test_pd.drop(['person_id', 'screening_date'], axis=1)\n",
    "test_pd = test_pd[test_pd['p_age_first_offense'] != 0]\n",
    "\n",
    "## split train and test\n",
    "x_train, y_train = train_pd.values[:, :-1], train_pd.values[:, -1]\n",
    "x_test, y_test = test_pd.values[:, :-1], test_pd.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['sex', 'current_violent', 'current_violent20', 'six_month', 'one_year', 'three_year', 'five_year', 'recid_violent']\n",
    "for i in variables:\n",
    "    train_pd[i] = train_pd[i].astype('category')\n",
    "    test_pd[i] = test_pd[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare data\n",
    "trainx = xgb.DMatrix(x_train, label=y_train)\n",
    "testx = xgb.DMatrix(x_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(X, parameters, setups, seed = 816):\n",
    "    \n",
    "    crossvalidation = xgb.cv(dtrain = X, \n",
    "                             params=parameters, \n",
    "                             num_boost_round = setup['nrounds'], \n",
    "                             nfold=setup['nfolds'], \n",
    "                             verbose_eval = False, \n",
    "                             metrics='auc', \n",
    "                             maximize=True, \n",
    "                             seed=seed)\n",
    "    \n",
    "    iterations = crossvalidation.index\n",
    "    train_auc = crossvalidation['train-auc-mean'].values\n",
    "    test_auc = crossvalidation['test-auc-mean'].values\n",
    "    \n",
    "    best_index = np.where(test_auc == np.max(test_auc))[0][0]\n",
    "    best_iterations = iterations[best_index]\n",
    "    best_test_auc = test_auc[best_index]\n",
    "    best_train_auc = train_auc[best_index]\n",
    "    \n",
    "    return best_iterations, best_train_auc, best_test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETA = [0.01, 0.03, 0.05]\n",
    "GAMMA = [12,14,16,18]\n",
    "DEPTH = [1,2,3]\n",
    "CHILD_WEIGHT = [12,14,16,18]\n",
    "SUB_SAMPLE = [0.1, 0.3, 0.5, 0.7]\n",
    "setup = {'nfolds': 5, 'nrounds': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for e in ETA:\n",
    "    for g in GAMMA:\n",
    "        for d in DEPTH:\n",
    "            for c in CHILD_WEIGHT:\n",
    "                for s in SUB_SAMPLE:\n",
    "                    parameters = {'objective': \"binary:logistic\", \n",
    "                                  'eta': e, \n",
    "                                  'gamma': g, \n",
    "                                  'max_depth': d, \n",
    "                                  'min_child_weight': c, \n",
    "                                  'subsample': s, \n",
    "                                  'colsample_bytree': 1, \n",
    "                                  'early_stopping_rounds': 10}\n",
    "            \n",
    "                    ite, train_auc, test_auc = crossvalidation(trainx, parameters, setup, seed=816)\n",
    "                    auc_diff = train_auc - test_auc\n",
    "                    results.append([e, g,d,c,s,ite, test_auc, auc_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(results, columns=['Learning Rate', 'Gamma', 'Depth', 'Min Child Weight', 'Subsample', 'Iteration', 'Validation AUC', 'AUC Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table[table['AUC Diff'] <= 0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Min Child Weight</th>\n",
       "      <th>Subsample</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>AUC Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>92</td>\n",
       "      <td>0.631203</td>\n",
       "      <td>0.014929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>92</td>\n",
       "      <td>0.631203</td>\n",
       "      <td>0.014929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>92</td>\n",
       "      <td>0.631203</td>\n",
       "      <td>0.014929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97</td>\n",
       "      <td>0.630652</td>\n",
       "      <td>0.012580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97</td>\n",
       "      <td>0.630652</td>\n",
       "      <td>0.012580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>97</td>\n",
       "      <td>0.630652</td>\n",
       "      <td>0.012580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.628250</td>\n",
       "      <td>0.005253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.628250</td>\n",
       "      <td>0.005253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.628250</td>\n",
       "      <td>0.005253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.3</td>\n",
       "      <td>82</td>\n",
       "      <td>0.627366</td>\n",
       "      <td>0.015928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.3</td>\n",
       "      <td>82</td>\n",
       "      <td>0.627366</td>\n",
       "      <td>0.015928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.3</td>\n",
       "      <td>82</td>\n",
       "      <td>0.627366</td>\n",
       "      <td>0.015928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>95</td>\n",
       "      <td>0.616057</td>\n",
       "      <td>0.008605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.01</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>95</td>\n",
       "      <td>0.616057</td>\n",
       "      <td>0.008605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.01</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>95</td>\n",
       "      <td>0.616057</td>\n",
       "      <td>0.008605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.05</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.587990</td>\n",
       "      <td>0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.05</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.587990</td>\n",
       "      <td>0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.05</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.587990</td>\n",
       "      <td>0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.570166</td>\n",
       "      <td>0.009010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.570166</td>\n",
       "      <td>0.009010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.570166</td>\n",
       "      <td>0.009010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.03</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.559952</td>\n",
       "      <td>-0.002802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.03</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.559952</td>\n",
       "      <td>-0.002802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.03</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.559952</td>\n",
       "      <td>-0.002802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.05</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.556805</td>\n",
       "      <td>-0.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.05</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.556805</td>\n",
       "      <td>-0.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.05</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.556805</td>\n",
       "      <td>-0.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.556781</td>\n",
       "      <td>-0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.556781</td>\n",
       "      <td>-0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.556781</td>\n",
       "      <td>-0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.03</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.03</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.03</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.03</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.03</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.03</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.03</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.03</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.03</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.03</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.03</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.03</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.03</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.03</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.03</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.03</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.03</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.05</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Learning Rate  Gamma  Depth  Min Child Weight  Subsample  Iteration  \\\n",
       "181           0.01     18      3                14        0.3         92   \n",
       "165           0.01     18      2                14        0.3         92   \n",
       "149           0.01     18      1                14        0.3         92   \n",
       "169           0.01     18      2                16        0.3         97   \n",
       "185           0.01     18      3                16        0.3         97   \n",
       "153           0.01     18      1                16        0.3         97   \n",
       "145           0.01     18      1                12        0.3         29   \n",
       "177           0.01     18      3                12        0.3         29   \n",
       "161           0.01     18      2                12        0.3         29   \n",
       "189           0.01     18      3                18        0.3         82   \n",
       "173           0.01     18      2                18        0.3         82   \n",
       "157           0.01     18      1                18        0.3         82   \n",
       "0             0.01     12      1                12        0.1         95   \n",
       "16            0.01     12      2                12        0.1         95   \n",
       "32            0.01     12      3                12        0.1         95   \n",
       "384           0.05     12      1                12        0.1         52   \n",
       "416           0.05     12      3                12        0.1         52   \n",
       "400           0.05     12      2                12        0.1         52   \n",
       "192           0.03     12      1                12        0.1         55   \n",
       "208           0.03     12      2                12        0.1         55   \n",
       "224           0.03     12      3                12        0.1         55   \n",
       "272           0.03     14      3                12        0.1         52   \n",
       "256           0.03     14      2                12        0.1         52   \n",
       "240           0.03     14      1                12        0.1         52   \n",
       "432           0.05     14      1                12        0.1         52   \n",
       "448           0.05     14      2                12        0.1         52   \n",
       "464           0.05     14      3                12        0.1         52   \n",
       "228           0.03     12      3                14        0.1         52   \n",
       "196           0.03     12      1                14        0.1         52   \n",
       "212           0.03     12      2                14        0.1         52   \n",
       "..             ...    ...    ...               ...        ...        ...   \n",
       "148           0.01     18      1                14        0.1          0   \n",
       "156           0.01     18      1                18        0.1          0   \n",
       "340           0.03     18      1                14        0.1          0   \n",
       "160           0.01     18      2                12        0.1          0   \n",
       "336           0.03     18      1                12        0.1          0   \n",
       "332           0.03     16      3                18        0.1          0   \n",
       "328           0.03     16      3                16        0.1          0   \n",
       "324           0.03     16      3                14        0.1          0   \n",
       "316           0.03     16      2                18        0.1          0   \n",
       "312           0.03     16      2                16        0.1          0   \n",
       "308           0.03     16      2                14        0.1          0   \n",
       "300           0.03     16      1                18        0.1          0   \n",
       "296           0.03     16      1                16        0.1          0   \n",
       "292           0.03     16      1                14        0.1          0   \n",
       "284           0.03     14      3                18        0.1          0   \n",
       "280           0.03     14      3                16        0.1          0   \n",
       "268           0.03     14      2                18        0.1          0   \n",
       "252           0.03     14      1                18        0.1          0   \n",
       "248           0.03     14      1                16        0.1          0   \n",
       "236           0.03     12      3                18        0.1          0   \n",
       "220           0.03     12      2                18        0.1          0   \n",
       "204           0.03     12      1                18        0.1          0   \n",
       "188           0.01     18      3                18        0.1          0   \n",
       "184           0.01     18      3                16        0.1          0   \n",
       "180           0.01     18      3                14        0.1          0   \n",
       "176           0.01     18      3                12        0.1          0   \n",
       "172           0.01     18      2                18        0.1          0   \n",
       "168           0.01     18      2                16        0.1          0   \n",
       "164           0.01     18      2                14        0.1          0   \n",
       "572           0.05     18      3                18        0.1          0   \n",
       "\n",
       "     Validation AUC  AUC Diff  \n",
       "181        0.631203  0.014929  \n",
       "165        0.631203  0.014929  \n",
       "149        0.631203  0.014929  \n",
       "169        0.630652  0.012580  \n",
       "185        0.630652  0.012580  \n",
       "153        0.630652  0.012580  \n",
       "145        0.628250  0.005253  \n",
       "177        0.628250  0.005253  \n",
       "161        0.628250  0.005253  \n",
       "189        0.627366  0.015928  \n",
       "173        0.627366  0.015928  \n",
       "157        0.627366  0.015928  \n",
       "0          0.616057  0.008605  \n",
       "16         0.616057  0.008605  \n",
       "32         0.616057  0.008605  \n",
       "384        0.587990  0.000749  \n",
       "416        0.587990  0.000749  \n",
       "400        0.587990  0.000749  \n",
       "192        0.570166  0.009010  \n",
       "208        0.570166  0.009010  \n",
       "224        0.570166  0.009010  \n",
       "272        0.559952 -0.002802  \n",
       "256        0.559952 -0.002802  \n",
       "240        0.559952 -0.002802  \n",
       "432        0.556805 -0.006129  \n",
       "448        0.556805 -0.006129  \n",
       "464        0.556805 -0.006129  \n",
       "228        0.556781 -0.001090  \n",
       "196        0.556781 -0.001090  \n",
       "212        0.556781 -0.001090  \n",
       "..              ...       ...  \n",
       "148        0.500000  0.000000  \n",
       "156        0.500000  0.000000  \n",
       "340        0.500000  0.000000  \n",
       "160        0.500000  0.000000  \n",
       "336        0.500000  0.000000  \n",
       "332        0.500000  0.000000  \n",
       "328        0.500000  0.000000  \n",
       "324        0.500000  0.000000  \n",
       "316        0.500000  0.000000  \n",
       "312        0.500000  0.000000  \n",
       "308        0.500000  0.000000  \n",
       "300        0.500000  0.000000  \n",
       "296        0.500000  0.000000  \n",
       "292        0.500000  0.000000  \n",
       "284        0.500000  0.000000  \n",
       "280        0.500000  0.000000  \n",
       "268        0.500000  0.000000  \n",
       "252        0.500000  0.000000  \n",
       "248        0.500000  0.000000  \n",
       "236        0.500000  0.000000  \n",
       "220        0.500000  0.000000  \n",
       "204        0.500000  0.000000  \n",
       "188        0.500000  0.000000  \n",
       "184        0.500000  0.000000  \n",
       "180        0.500000  0.000000  \n",
       "176        0.500000  0.000000  \n",
       "172        0.500000  0.000000  \n",
       "168        0.500000  0.000000  \n",
       "164        0.500000  0.000000  \n",
       "572        0.500000  0.000000  \n",
       "\n",
       "[156 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.sort_values(by = 'Validation AUC', axis=0, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameter:\n",
    "- learning rate: 0.01 / depth: 3 / gamma: 18 / min_child_weight: 14 / subsample: 0.3 / iteration: 93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'objective': \"binary:logistic\", 'eta': 0.01, 'gamma': 18, 'max_depth': 3, 'min_child_weight': 14, 'subsample': 0.3, \n",
    "              'colsample_bytree': 1, 'early_stopping_rounds': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = xgb.cv(parameters,trainx, num_boost_round=93, nfold=5, metrics='auc', verbose_eval=False, maximize=True, seed=816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_auc = cv['train-auc-mean'].values\n",
    "test_auc = cv['test-auc-mean'].values\n",
    "best_index = np.where(test_auc == np.max(test_auc))[0][0]\n",
    "\n",
    "test_auc_mean = test_auc[best_index]\n",
    "train_auc_mean = train_auc[best_index]\n",
    "train_auc_std = np.std(train_auc)\n",
    "test_auc_std = np.std(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6461318, 0.6312026000000001, 0.015907731484299262, 0.012420355363758108)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_auc_mean, test_auc_mean, train_auc_std, test_auc_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model\n",
    "-- use 0.5 as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.train(parameters, trainx, num_boost_round=93, verbose_eval=False, maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8118279569892473"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = xgboost.predict(testx)\n",
    "heldout_test_acc = np.mean((pred > 0.5) == y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6238174077578051"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr,tpr,thresholds = roc_curve(y_test, pred)\n",
    "heldout_test_auc = auc(fpr, tpr)\n",
    "heldout_test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- use optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#optimal_index = np.argmin(np.sqrt(np.square(1-tpr) + np.square(fpr)))\n",
    "optimal_index = np.argmax(abs(tpr - fpr))\n",
    "optimal_threshold = thresholds[optimal_index]\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heldout_test_acc = np.mean((pred > optimal_threshold) == y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log model results to the model performance folder, as per standards\n",
    "path = \"C:\\\\Users\\\\binha\\\\Documents\\\\Duke\\\\Cynthia Research\\\\KY-analysis-mytrials\\\\broward\\\\broward models\\\\Baseline Model Results\\\\Without Minor Offenses\\\\Violent\\\\\"\n",
    "                  \n",
    "results = [\"XGBoost\", train_auc_mean, train_auc_std, test_auc_mean, test_auc_std, heldout_test_auc, heldout_test_acc ]\n",
    "\n",
    "with open(path + 'Violent Summary.csv', 'a') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix -- old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(X, Y, nfold, learning_rate, depth, N, min_child_weight = 1, gamma = 0, subsample = 1, colsample_bytree = 1,\n",
    "                    reg_alpha=0, reg_lambda=1, seed=816):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    @parameters:\n",
    "    - X: training set -- features\n",
    "    - Y: training set -- response variable\n",
    "    - nfold: n-folds cross validation\n",
    "    - learning_rate: learning rate\n",
    "    - depth: max split depth\n",
    "    - N: number of estimators\n",
    "    - reg_alpha: L1 regularization term on weights\n",
    "    - reg_lambda: L2 regularization term on weights\n",
    "    - seed: random state\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ## nfolds cross validation set up\n",
    "    cv = KFold(n_splits=nfold, random_state=seed, shuffle=True)\n",
    "    \n",
    "    ## classifier\n",
    "    classifier = xgb.XGBClassifier(learning_rate=learning_rate, \n",
    "                                   max_depth=depth, \n",
    "                                   n_estimators=N, \n",
    "                                   min_child_weight=min_child_weight,\n",
    "                                   gamma = gamma, \n",
    "                                   subsample=subsample,\n",
    "                                   colsample_bylevel=colsample_bytree,\n",
    "                                   reg_alpha=reg_alpha, \n",
    "                                   reg_lambda=reg_lambda,\n",
    "                                   random_state=seed)\n",
    "    train_acc, test_acc = [], []\n",
    "    train_auc, test_auc = [], []\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, Y):\n",
    "    \n",
    "        ## data & classifier\n",
    "        X_train, Y_train = X[train], Y[train]\n",
    "        X_test, Y_test = X[test], Y[test]\n",
    "        fit_model = classifier.fit(X_train, Y_train)\n",
    "    \n",
    "        ## accuracy & probability\n",
    "        train_acc.append(fit_model.score(X_train, Y_train))\n",
    "        test_acc.append(fit_model.score(X_test, Y_test))\n",
    "    \n",
    "        train_prob = fit_model.predict_proba(X_train)[:,1]\n",
    "        test_prob = fit_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "        ## compute ROC curve and AUC\n",
    "    \n",
    "        train_fpr, train_tpr, train_thresholds = roc_curve(Y_train, train_prob)\n",
    "        test_fpr, test_tpr, test_thresholds = roc_curve(Y_test, test_prob)\n",
    "        train_auc.append(auc(train_fpr, train_tpr))\n",
    "        test_auc.append(auc(test_fpr, test_tpr))\n",
    "        i += 1\n",
    "    \n",
    "    return train_acc, test_acc, train_auc, test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters \n",
    "-- To prevent overfitting and get as good performance as possible.\n",
    "\n",
    "-- criteria: difference between the avg. train accuracy and test accuracy and the difference between avg. train auc and avg. test auc are both smaller than 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Depth = [1, 2]\n",
    "child_weight = [2,3,4,5,6]\n",
    "gamma = [2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ACC = []\n",
    "train_AUC = []\n",
    "test_ACC = []\n",
    "test_AUC = []\n",
    "LR = []\n",
    "DEPTH = []\n",
    "Estimator = []\n",
    "Child_weight = []\n",
    "Gamma = []\n",
    "\n",
    "for i in Depth:\n",
    "    for j in child_weight:\n",
    "        for k in gamma:\n",
    "            train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 10, learning_rate=0.1, depth=i, N=100, min_child_weight=j, gamma=k)\n",
    "            \n",
    "            acc_diff = str(round((np.mean(train_acc) - np.mean(test_acc))*100, 2)) + \"%\"\n",
    "            auc_diff = str(round((np.mean(train_auc) - np.mean(test_auc))*100, 2)) + \"%\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Depth = [1, 2]\n",
    "lr = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "num_estimator = [10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate,  Depth,  Number of Estimators,  Avg. ACC Diff,  Avg. AUC Diff,  Avg. Test AUC,  Avg. Test ACC\n",
      "0.01               1            10                  2.6%            2.45%         0.598           0.571\n",
      "0.01               1            20                  2.67%            2.62%         0.611           0.569\n",
      "0.01               2            10                  4.77%            4.1%         0.615           0.566\n",
      "0.01               2            20                  4.24%            4.43%         0.617           0.577\n",
      "0.05               1            10                  1.92%            2.38%         0.622           0.576\n",
      "0.05               1            20                  2.06%            2.69%         0.628           0.58\n",
      "0.05               2            10                  5.09%            4.75%         0.623           0.577\n",
      "0.05               2            20                  5.12%            5.63%         0.627           0.587\n",
      "0.1               1            10                  2.07%            2.57%         0.628           0.579\n",
      "0.1               1            20                  3.32%            3.53%         0.63           0.583\n",
      "0.1               2            10                  4.96%            5.59%         0.627           0.586\n",
      "0.1               2            20                  4.82%            6.54%         0.634           0.606\n",
      "0.2               1            10                  3.88%            3.27%         0.631           0.579\n",
      "0.2               1            20                  4.89%            4.28%         0.636           0.586\n",
      "0.2               2            10                  5.82%            6.63%         0.631           0.592\n",
      "0.2               2            20                  6.4%            7.84%         0.642           0.605\n",
      "0.3               1            10                  5.01%            4.02%         0.63           0.578\n",
      "0.3               1            20                  4.3%            4.78%         0.638           0.599\n",
      "0.3               2            10                  6.47%            7.53%         0.633           0.596\n",
      "0.3               2            20                  7.7%            9.75%         0.637           0.606\n",
      "0.4               1            10                  4.02%            3.99%         0.635           0.596\n",
      "0.4               1            20                  5.22%            5.07%         0.64           0.596\n",
      "0.4               2            10                  5.36%            6.88%         0.646           0.611\n",
      "0.4               2            20                  7.27%            10.32%         0.642           0.617\n",
      "0.5               1            10                  4.84%            5.74%         0.621           0.588\n",
      "0.5               1            20                  5.55%            5.69%         0.638           0.598\n",
      "0.5               2            10                  7.02%            8.68%         0.636           0.599\n",
      "0.5               2            20                  9.11%            11.69%         0.638           0.608\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning Rate, \", \"Depth, \", \"Number of Estimators, \", \"Avg. ACC Diff, \", \"Avg. AUC Diff, \", \"Avg. Test AUC, \", \"Avg. Test ACC\")\n",
    "\n",
    "for k in lr:\n",
    "    for i in Depth:\n",
    "        for j in num_estimator:\n",
    "            train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 10, k, i, j)\n",
    "            acc_diff = str(round((np.mean(train_acc) - np.mean(test_acc))*100, 2)) + \"%\"\n",
    "            auc_diff = str(round((np.mean(train_auc) - np.mean(test_auc))*100, 2)) + \"%\"\n",
    "            print(k, \"             \", i, \"          \", j, \"                \", acc_diff, \"          \", auc_diff, \"       \", round(np.mean(test_auc), 3), \"         \", round(np.mean(test_acc), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 10, learning_rate=0.05, depth=1, N=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6001974985871293, 0.579593336599706, 0.6544994997113768, 0.6275627839190581)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_acc), np.mean(test_acc), np.mean(train_auc), np.mean(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263440860215054"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost = xgb.XGBClassifier(learning_rate=0.05, max_depth=1, n_estimators=20).fit(x_train, y_train)\n",
    "heldout_test_acc=xgboost.score(x_test, y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6551653377110693"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = xgboost.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob)\n",
    "heldout_test_auc = auc(fpr, tpr)\n",
    "heldout_test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- learning rate: 0.1 / depth: 1 / N: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 10, 0.1, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5996286601942533,\n",
       " 0.5789523109586804,\n",
       " 0.6536408805176906,\n",
       " 0.6279567183245163)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_acc), np.mean(test_acc), np.mean(train_auc), np.mean(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263440860215054"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost = xgb.XGBClassifier(learning_rate=0.1, max_depth=1, n_estimators=20).fit(x_train, y_train)\n",
    "heldout_test_acc=xgboost.score(x_test, y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6574372654784241"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = xgboost.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob)\n",
    "heldout_test_auc = auc(fpr, tpr)\n",
    "heldout_test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
