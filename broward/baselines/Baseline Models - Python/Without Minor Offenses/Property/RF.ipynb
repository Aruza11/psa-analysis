{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data sets\n",
    "train_pd = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/Without Minor Offenses/train_recid_property.csv\")\n",
    "test_pd = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward//data/Without Minor Offenses/test_recid_property.csv\")\n",
    "\n",
    "## get rid of the record with 'p_age_first_offense' == 0\n",
    "train_pd = train_pd.drop(['person_id', 'screening_date'], axis=1)\n",
    "test_pd = test_pd.drop(['person_id', 'screening_date'], axis=1)\n",
    "test_pd = test_pd[test_pd['p_age_first_offense'] != 0]\n",
    "\n",
    "## split train and test\n",
    "x_train, y_train = train_pd.values[:, :-1], train_pd.values[:, -1]\n",
    "x_test, y_test = test_pd.values[:, :-1], test_pd.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['sex', 'current_violent', 'current_violent20', 'six_month', 'one_year', 'three_year', 'five_year', 'recid_property']\n",
    "for i in variables:\n",
    "    train_pd[i] = train_pd[i].astype('category')\n",
    "    test_pd[i] = test_pd[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(X, Y, nfold, depth, N, min_samples_split=2, min_impurity_decrease=0, seed=816):\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    @parameters:\n",
    "    - xtrain: training set -- features\n",
    "    - ytrain: training set -- response variable\n",
    "    - nfold: n-folds cross validation\n",
    "    - depth: max split depth\n",
    "    - N: number of trees\n",
    "    - min_samples_splits: the minimum number of samples required to split an internal node\n",
    "    - min_impurity_decrease: a node will be split if that split induced a decrease of the impurity greater\n",
    "                             than or equal to this value\n",
    "    - seed: random state\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ## nfolds cross-validation set up\n",
    "    #cv = KFold(n_splits=nfold, random_state=seed, shuffle=True)\n",
    "    cv = StratifiedKFold(n_splits=nfold, random_state=seed, shuffle=True)\n",
    "    \n",
    "    ## classifier\n",
    "    classifier = RandomForestClassifier(max_depth=depth,\n",
    "                                        n_estimators=N, \n",
    "                                        min_impurity_decrease=min_impurity_decrease,\n",
    "                                        min_samples_split= min_samples_split,\n",
    "                                        bootstrap=True, \n",
    "                                        random_state=seed)\n",
    "    train_acc, test_acc = [], []\n",
    "    train_auc, test_auc = [], []\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, Y):\n",
    "    \n",
    "        ## data & classifier\n",
    "        X_train, Y_train = X[train], Y[train]\n",
    "        X_test, Y_test = X[test], Y[test]\n",
    "        fit_model = classifier.fit(X_train, Y_train)\n",
    "    \n",
    "        ## accuracy & probability\n",
    "        train_acc.append(fit_model.score(X_train, Y_train))\n",
    "        test_acc.append(fit_model.score(X_test, Y_test))\n",
    "    \n",
    "        train_prob = fit_model.predict_proba(X_train)[:,1]\n",
    "        test_prob = fit_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "        ## compute ROC curve and AUC\n",
    "    \n",
    "        train_fpr, train_tpr, train_thresholds = roc_curve(Y_train, train_prob)\n",
    "        test_fpr, test_tpr, test_thresholds = roc_curve(Y_test, test_prob)\n",
    "        train_roc_auc = auc(train_fpr, train_tpr)\n",
    "        test_roc_auc = auc(test_fpr, test_tpr)\n",
    "    \n",
    "        train_auc.append(train_roc_auc)\n",
    "        test_auc.append(test_roc_auc)\n",
    "        i += 1\n",
    "    \n",
    "    return train_acc, test_acc, train_auc, test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters \n",
    "-- To prevent overfitting and get as good performance as possible.\n",
    "\n",
    "-- criteria: difference between the avg. train accuracy and test accuracy and the difference between avg. train auc and avg. test auc are both smaller than 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Depth = [1,2,3,4,5,6,7,8,9]\n",
    "num_estimator = [30, 40, 50, 60, 70, 80, 90]\n",
    "min_impurity_decrease = [0.006, 0.007, 0.008, 0.009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for d in Depth:\n",
    "    for n in num_estimator:\n",
    "        for i in min_impurity_decrease:\n",
    "            train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 5, depth=d, N=n, min_impurity_decrease=i)\n",
    "            auc_diff = np.mean(train_auc) - np.mean(test_auc)\n",
    "            results.append([d, n, i, np.mean(test_auc), auc_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(results, columns=['Depth', 'Number of Estimators', 'Min Impurity Decrease', 'Validation AUC', 'AUC Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table[table['AUC Diff'] < 0.021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Number of Estimators</th>\n",
       "      <th>Min Impurity Decrease</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>AUC Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.686264</td>\n",
       "      <td>0.020291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.686073</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.685284</td>\n",
       "      <td>0.019701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.685031</td>\n",
       "      <td>0.019802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.684706</td>\n",
       "      <td>0.018325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.684321</td>\n",
       "      <td>0.015497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682931</td>\n",
       "      <td>0.013582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682860</td>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682677</td>\n",
       "      <td>0.013938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682654</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682654</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682654</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682654</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682654</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682654</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682654</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.682146</td>\n",
       "      <td>0.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.681760</td>\n",
       "      <td>0.008685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.666095</td>\n",
       "      <td>0.012368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.015470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.015470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.015470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.015470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.015470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.015470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.015470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.015470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>0.015487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.665880</td>\n",
       "      <td>0.019332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.664772</td>\n",
       "      <td>0.018560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.664560</td>\n",
       "      <td>0.018858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.664373</td>\n",
       "      <td>0.019407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.664373</td>\n",
       "      <td>0.019407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.664373</td>\n",
       "      <td>0.019407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.664373</td>\n",
       "      <td>0.019407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.664373</td>\n",
       "      <td>0.019407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.664373</td>\n",
       "      <td>0.019407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.664373</td>\n",
       "      <td>0.019407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.663249</td>\n",
       "      <td>0.020601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.657436</td>\n",
       "      <td>0.018834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.657436</td>\n",
       "      <td>0.018834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.657436</td>\n",
       "      <td>0.018834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.657436</td>\n",
       "      <td>0.018834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.657436</td>\n",
       "      <td>0.018834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.657436</td>\n",
       "      <td>0.018834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.657436</td>\n",
       "      <td>0.018834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.657436</td>\n",
       "      <td>0.018834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.657436</td>\n",
       "      <td>0.018834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Depth  Number of Estimators  Min Impurity Decrease  Validation AUC  \\\n",
       "40       2                    60                  0.006        0.686264   \n",
       "68       3                    60                  0.006        0.686073   \n",
       "96       4                    60                  0.006        0.686073   \n",
       "124      5                    60                  0.006        0.686073   \n",
       "152      6                    60                  0.006        0.686073   \n",
       "180      7                    60                  0.006        0.686073   \n",
       "208      8                    60                  0.006        0.686073   \n",
       "236      9                    60                  0.006        0.686073   \n",
       "20       1                    80                  0.006        0.685284   \n",
       "24       1                    90                  0.006        0.685031   \n",
       "16       1                    70                  0.006        0.684706   \n",
       "12       1                    60                  0.006        0.684321   \n",
       "49       2                    80                  0.007        0.682931   \n",
       "77       3                    80                  0.007        0.682860   \n",
       "105      4                    80                  0.007        0.682860   \n",
       "133      5                    80                  0.007        0.682860   \n",
       "161      6                    80                  0.007        0.682860   \n",
       "189      7                    80                  0.007        0.682860   \n",
       "217      8                    80                  0.007        0.682860   \n",
       "245      9                    80                  0.007        0.682860   \n",
       "53       2                    90                  0.007        0.682677   \n",
       "81       3                    90                  0.007        0.682654   \n",
       "109      4                    90                  0.007        0.682654   \n",
       "137      5                    90                  0.007        0.682654   \n",
       "165      6                    90                  0.007        0.682654   \n",
       "193      7                    90                  0.007        0.682654   \n",
       "221      8                    90                  0.007        0.682654   \n",
       "249      9                    90                  0.007        0.682654   \n",
       "21       1                    80                  0.007        0.682146   \n",
       "25       1                    90                  0.007        0.681760   \n",
       "..     ...                   ...                    ...             ...   \n",
       "231      9                    40                  0.009        0.666095   \n",
       "30       2                    30                  0.008        0.665927   \n",
       "58       3                    30                  0.008        0.665927   \n",
       "86       4                    30                  0.008        0.665927   \n",
       "114      5                    30                  0.008        0.665927   \n",
       "142      6                    30                  0.008        0.665927   \n",
       "170      7                    30                  0.008        0.665927   \n",
       "198      8                    30                  0.008        0.665927   \n",
       "226      9                    30                  0.008        0.665927   \n",
       "2        1                    30                  0.008        0.665927   \n",
       "4        1                    40                  0.006        0.665880   \n",
       "1        1                    30                  0.007        0.664772   \n",
       "29       2                    30                  0.007        0.664560   \n",
       "57       3                    30                  0.007        0.664373   \n",
       "85       4                    30                  0.007        0.664373   \n",
       "113      5                    30                  0.007        0.664373   \n",
       "141      6                    30                  0.007        0.664373   \n",
       "169      7                    30                  0.007        0.664373   \n",
       "197      8                    30                  0.007        0.664373   \n",
       "225      9                    30                  0.007        0.664373   \n",
       "0        1                    30                  0.006        0.663249   \n",
       "3        1                    30                  0.009        0.657436   \n",
       "31       2                    30                  0.009        0.657436   \n",
       "59       3                    30                  0.009        0.657436   \n",
       "87       4                    30                  0.009        0.657436   \n",
       "115      5                    30                  0.009        0.657436   \n",
       "143      6                    30                  0.009        0.657436   \n",
       "171      7                    30                  0.009        0.657436   \n",
       "199      8                    30                  0.009        0.657436   \n",
       "227      9                    30                  0.009        0.657436   \n",
       "\n",
       "     AUC Diff  \n",
       "40   0.020291  \n",
       "68   0.020621  \n",
       "96   0.020621  \n",
       "124  0.020621  \n",
       "152  0.020621  \n",
       "180  0.020621  \n",
       "208  0.020621  \n",
       "236  0.020621  \n",
       "20   0.019701  \n",
       "24   0.019802  \n",
       "16   0.018325  \n",
       "12   0.015497  \n",
       "49   0.013582  \n",
       "77   0.013805  \n",
       "105  0.013805  \n",
       "133  0.013805  \n",
       "161  0.013805  \n",
       "189  0.013805  \n",
       "217  0.013805  \n",
       "245  0.013805  \n",
       "53   0.013938  \n",
       "81   0.014063  \n",
       "109  0.014063  \n",
       "137  0.014063  \n",
       "165  0.014063  \n",
       "193  0.014063  \n",
       "221  0.014063  \n",
       "249  0.014063  \n",
       "21   0.008310  \n",
       "25   0.008685  \n",
       "..        ...  \n",
       "231  0.012368  \n",
       "30   0.015470  \n",
       "58   0.015470  \n",
       "86   0.015470  \n",
       "114  0.015470  \n",
       "142  0.015470  \n",
       "170  0.015470  \n",
       "198  0.015470  \n",
       "226  0.015470  \n",
       "2    0.015487  \n",
       "4    0.019332  \n",
       "1    0.018560  \n",
       "29   0.018858  \n",
       "57   0.019407  \n",
       "85   0.019407  \n",
       "113  0.019407  \n",
       "141  0.019407  \n",
       "169  0.019407  \n",
       "197  0.019407  \n",
       "225  0.019407  \n",
       "0    0.020601  \n",
       "3    0.018834  \n",
       "31   0.018834  \n",
       "59   0.018834  \n",
       "87   0.018834  \n",
       "115  0.018834  \n",
       "143  0.018834  \n",
       "171  0.018834  \n",
       "199  0.018834  \n",
       "227  0.018834  \n",
       "\n",
       "[219 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.sort_values(by = ['Validation AUC', 'AUC Diff'], axis=0, ascending = [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameters:\n",
    "-depth: 1; estimators: 80 ; impurity: 0.006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 5, depth=1, N=80, min_impurity_decrease=0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9065900321984206,\n",
       " 0.9065921375382924,\n",
       " 0.7049851758924407,\n",
       " 0.6852843029910914)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_acc), np.mean(test_acc), np.mean(train_auc), np.mean(test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heldout Test Set\n",
    "-- use 0.5 as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9274193548387096"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=1, n_estimators=80, min_impurity_decrease=0.006, bootstrap=True, random_state=816).fit(x_train, y_train)\n",
    "heldout_test_acc = rf.score(x_test, y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6568438003220612"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = rf.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob)\n",
    "heldout_test_auc = auc(fpr, tpr)\n",
    "heldout_test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- use optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#optimal_index = np.argmin(np.sqrt(np.square(1-tpr) + np.square(fpr)))\n",
    "optimal_index = np.argmax(abs(tpr - fpr))\n",
    "optimal_threshold = thresholds[optimal_index]\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction = rf.predict_proba(x_test)[:,1]\n",
    "heldout_test_acc = np.mean((prediction > optimal_threshold) == y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log model results to the model performance folder, as per standards\n",
    "path = \"C:\\\\Users\\\\binha\\\\Documents\\\\Duke\\\\Cynthia Research\\\\KY-analysis-mytrials\\\\broward\\\\broward models\\\\Baseline Model Results\\\\Without Minor Offenses\\\\Property\\\\\"\n",
    "\n",
    "train_auc_mean, train_auc_std = np.mean(train_auc), np.std(train_auc)\n",
    "test_auc_mean, test_auc_std = np.mean(test_auc), np.std(test_auc)\n",
    "                   \n",
    "results = [\"RF\", train_auc_mean, train_auc_std, test_auc_mean, test_auc_std, heldout_test_auc, heldout_test_acc ]\n",
    "\n",
    "with open(path + 'Property Summary.csv', 'a') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
