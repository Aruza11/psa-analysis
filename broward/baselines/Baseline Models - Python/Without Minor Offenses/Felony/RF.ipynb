{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data sets\n",
    "train_pd = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward/data/Without Minor Offenses/train_recid_F.csv\")\n",
    "test_pd = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/broward//data/Without Minor Offenses/test_recid_F.csv\")\n",
    "\n",
    "## get rid of the record with 'p_age_first_offense' == 0\n",
    "train_pd = train_pd.drop(['person_id', 'screening_date'], axis=1)\n",
    "test_pd = test_pd.drop(['person_id', 'screening_date'], axis=1)\n",
    "test_pd = test_pd[test_pd['p_age_first_offense'] != 0]\n",
    "\n",
    "## split train and test\n",
    "x_train, y_train = train_pd.values[:, :-1], train_pd.values[:, -1]\n",
    "x_test, y_test = test_pd.values[:, :-1], test_pd.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['sex', 'current_violent', 'current_violent20', 'six_month', 'one_year', 'three_year', 'five_year', 'recid_F']\n",
    "for i in variables:\n",
    "    train_pd[i] = train_pd[i].astype('category')\n",
    "    test_pd[i] = test_pd[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(X, Y, nfold, depth, N, min_samples_split=2, min_impurity_decrease=0, seed=816):\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    @parameters:\n",
    "    - xtrain: training set -- features\n",
    "    - ytrain: training set -- response variable\n",
    "    - nfold: n-folds cross validation\n",
    "    - depth: max split depth\n",
    "    - N: number of trees\n",
    "    - min_samples_splits: the minimum number of samples required to split an internal node\n",
    "    - min_impurity_decrease: a node will be split if that split induced a decrease of the impurity greater\n",
    "                             than or equal to this value\n",
    "    - seed: random state\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ## nfolds cross-validation set up\n",
    "    #cv = KFold(n_splits=nfold, random_state=seed, shuffle=True)\n",
    "    cv = StratifiedKFold(n_splits=nfold, random_state=seed, shuffle=True)\n",
    "    \n",
    "    ## classifier\n",
    "    classifier = RandomForestClassifier(max_depth=depth,\n",
    "                                        n_estimators=N, \n",
    "                                        min_impurity_decrease=min_impurity_decrease,\n",
    "                                        min_samples_split= min_samples_split,\n",
    "                                        bootstrap=True, \n",
    "                                        random_state=seed)\n",
    "    train_acc, test_acc = [], []\n",
    "    train_auc, test_auc = [], []\n",
    "\n",
    "    i = 0\n",
    "    for train, test in cv.split(X, Y):\n",
    "    \n",
    "        ## data & classifier\n",
    "        X_train, Y_train = X[train], Y[train]\n",
    "        X_test, Y_test = X[test], Y[test]\n",
    "        fit_model = classifier.fit(X_train, Y_train)\n",
    "    \n",
    "        ## accuracy & probability\n",
    "        train_acc.append(fit_model.score(X_train, Y_train))\n",
    "        test_acc.append(fit_model.score(X_test, Y_test))\n",
    "    \n",
    "        train_prob = fit_model.predict_proba(X_train)[:,1]\n",
    "        test_prob = fit_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "        ## compute ROC curve and AUC\n",
    "    \n",
    "        train_fpr, train_tpr, train_thresholds = roc_curve(Y_train, train_prob)\n",
    "        test_fpr, test_tpr, test_thresholds = roc_curve(Y_test, test_prob)\n",
    "        train_roc_auc = auc(train_fpr, train_tpr)\n",
    "        test_roc_auc = auc(test_fpr, test_tpr)\n",
    "    \n",
    "        train_auc.append(train_roc_auc)\n",
    "        test_auc.append(test_roc_auc)\n",
    "        i += 1\n",
    "    \n",
    "    return train_acc, test_acc, train_auc, test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Parameters \n",
    "-- To prevent overfitting and get as good performance as possible.\n",
    "\n",
    "-- criteria: difference between the avg. train accuracy and test accuracy and the difference between avg. train auc and avg. test auc are both smaller than 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Depth = [1,2,3,4,5]\n",
    "num_estimator = [30, 40, 50, 60, 70, 80, 90, 100]\n",
    "min_impurity_decrease = [0.007, 0.008, 0.009, 0.011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for d in Depth:\n",
    "    for n in num_estimator:\n",
    "        for i in min_impurity_decrease:\n",
    "            train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 5, depth=d, N=n, min_impurity_decrease=i)\n",
    "            auc_diff = np.mean(train_auc) - np.mean(test_auc)\n",
    "            results.append([d, n, i, np.mean(test_auc), auc_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(results, columns=['Depth', 'Number of Estimators', 'Min Impurity Decrease', 'Validation AUC', 'AUC Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Number of Estimators</th>\n",
       "      <th>Min Impurity Decrease</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>AUC Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.624993</td>\n",
       "      <td>0.019701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.624809</td>\n",
       "      <td>0.018714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.623131</td>\n",
       "      <td>0.023486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.623083</td>\n",
       "      <td>0.023702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.623083</td>\n",
       "      <td>0.023702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.623083</td>\n",
       "      <td>0.023702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.622849</td>\n",
       "      <td>0.023271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.622849</td>\n",
       "      <td>0.023271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.622849</td>\n",
       "      <td>0.023271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.622648</td>\n",
       "      <td>0.023283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.622640</td>\n",
       "      <td>0.018506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.622330</td>\n",
       "      <td>0.019925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.622302</td>\n",
       "      <td>0.019945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.622302</td>\n",
       "      <td>0.019945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.622302</td>\n",
       "      <td>0.019945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.621548</td>\n",
       "      <td>0.019977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.621403</td>\n",
       "      <td>0.020307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.619944</td>\n",
       "      <td>0.024777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.619944</td>\n",
       "      <td>0.024777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.619944</td>\n",
       "      <td>0.024777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.619687</td>\n",
       "      <td>0.024844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.619605</td>\n",
       "      <td>0.025068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.619605</td>\n",
       "      <td>0.025129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.619605</td>\n",
       "      <td>0.025129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.619605</td>\n",
       "      <td>0.025129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.616953</td>\n",
       "      <td>0.028661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.616953</td>\n",
       "      <td>0.028661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.616953</td>\n",
       "      <td>0.028661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.616897</td>\n",
       "      <td>0.028684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.616800</td>\n",
       "      <td>0.027673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.593128</td>\n",
       "      <td>0.033402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.593128</td>\n",
       "      <td>0.033402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.593128</td>\n",
       "      <td>0.033402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.593128</td>\n",
       "      <td>0.033402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.592502</td>\n",
       "      <td>0.032844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.591910</td>\n",
       "      <td>0.033839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.591910</td>\n",
       "      <td>0.033839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.591910</td>\n",
       "      <td>0.033839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.591910</td>\n",
       "      <td>0.033839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.591410</td>\n",
       "      <td>0.033281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.584834</td>\n",
       "      <td>0.037790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.584834</td>\n",
       "      <td>0.037790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.584834</td>\n",
       "      <td>0.037790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.584834</td>\n",
       "      <td>0.037790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.583645</td>\n",
       "      <td>0.037840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.580446</td>\n",
       "      <td>0.033432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.579973</td>\n",
       "      <td>0.034166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.579973</td>\n",
       "      <td>0.034166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.579973</td>\n",
       "      <td>0.034166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.579973</td>\n",
       "      <td>0.034166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.571575</td>\n",
       "      <td>0.040181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.571575</td>\n",
       "      <td>0.040181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.571575</td>\n",
       "      <td>0.040181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.571575</td>\n",
       "      <td>0.040181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.570678</td>\n",
       "      <td>0.040088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.556616</td>\n",
       "      <td>0.038427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.556616</td>\n",
       "      <td>0.038427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.556616</td>\n",
       "      <td>0.038427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.556616</td>\n",
       "      <td>0.038427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.556616</td>\n",
       "      <td>0.038427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Depth  Number of Estimators  Min Impurity Decrease  Validation AUC  \\\n",
       "28       1                   100                  0.007        0.624993   \n",
       "24       1                    90                  0.007        0.624809   \n",
       "60       2                   100                  0.007        0.623131   \n",
       "92       3                   100                  0.007        0.623083   \n",
       "124      4                   100                  0.007        0.623083   \n",
       "156      5                   100                  0.007        0.623083   \n",
       "88       3                    90                  0.007        0.622849   \n",
       "120      4                    90                  0.007        0.622849   \n",
       "152      5                    90                  0.007        0.622849   \n",
       "56       2                    90                  0.007        0.622648   \n",
       "12       1                    60                  0.007        0.622640   \n",
       "44       2                    60                  0.007        0.622330   \n",
       "76       3                    60                  0.007        0.622302   \n",
       "108      4                    60                  0.007        0.622302   \n",
       "140      5                    60                  0.007        0.622302   \n",
       "20       1                    80                  0.007        0.621548   \n",
       "16       1                    70                  0.007        0.621403   \n",
       "84       3                    80                  0.007        0.619944   \n",
       "116      4                    80                  0.007        0.619944   \n",
       "148      5                    80                  0.007        0.619944   \n",
       "52       2                    80                  0.007        0.619687   \n",
       "48       2                    70                  0.007        0.619605   \n",
       "80       3                    70                  0.007        0.619605   \n",
       "112      4                    70                  0.007        0.619605   \n",
       "144      5                    70                  0.007        0.619605   \n",
       "93       3                   100                  0.008        0.616953   \n",
       "125      4                   100                  0.008        0.616953   \n",
       "157      5                   100                  0.008        0.616953   \n",
       "61       2                   100                  0.008        0.616897   \n",
       "29       1                   100                  0.008        0.616800   \n",
       "..     ...                   ...                    ...             ...   \n",
       "42       2                    50                  0.009        0.593128   \n",
       "74       3                    50                  0.009        0.593128   \n",
       "106      4                    50                  0.009        0.593128   \n",
       "138      5                    50                  0.009        0.593128   \n",
       "10       1                    50                  0.009        0.592502   \n",
       "38       2                    40                  0.009        0.591910   \n",
       "70       3                    40                  0.009        0.591910   \n",
       "102      4                    40                  0.009        0.591910   \n",
       "134      5                    40                  0.009        0.591910   \n",
       "6        1                    40                  0.009        0.591410   \n",
       "43       2                    50                  0.011        0.584834   \n",
       "75       3                    50                  0.011        0.584834   \n",
       "107      4                    50                  0.011        0.584834   \n",
       "139      5                    50                  0.011        0.584834   \n",
       "11       1                    50                  0.011        0.583645   \n",
       "2        1                    30                  0.009        0.580446   \n",
       "34       2                    30                  0.009        0.579973   \n",
       "66       3                    30                  0.009        0.579973   \n",
       "98       4                    30                  0.009        0.579973   \n",
       "130      5                    30                  0.009        0.579973   \n",
       "39       2                    40                  0.011        0.571575   \n",
       "71       3                    40                  0.011        0.571575   \n",
       "103      4                    40                  0.011        0.571575   \n",
       "135      5                    40                  0.011        0.571575   \n",
       "7        1                    40                  0.011        0.570678   \n",
       "3        1                    30                  0.011        0.556616   \n",
       "35       2                    30                  0.011        0.556616   \n",
       "67       3                    30                  0.011        0.556616   \n",
       "99       4                    30                  0.011        0.556616   \n",
       "131      5                    30                  0.011        0.556616   \n",
       "\n",
       "     AUC Diff  \n",
       "28   0.019701  \n",
       "24   0.018714  \n",
       "60   0.023486  \n",
       "92   0.023702  \n",
       "124  0.023702  \n",
       "156  0.023702  \n",
       "88   0.023271  \n",
       "120  0.023271  \n",
       "152  0.023271  \n",
       "56   0.023283  \n",
       "12   0.018506  \n",
       "44   0.019925  \n",
       "76   0.019945  \n",
       "108  0.019945  \n",
       "140  0.019945  \n",
       "20   0.019977  \n",
       "16   0.020307  \n",
       "84   0.024777  \n",
       "116  0.024777  \n",
       "148  0.024777  \n",
       "52   0.024844  \n",
       "48   0.025068  \n",
       "80   0.025129  \n",
       "112  0.025129  \n",
       "144  0.025129  \n",
       "93   0.028661  \n",
       "125  0.028661  \n",
       "157  0.028661  \n",
       "61   0.028684  \n",
       "29   0.027673  \n",
       "..        ...  \n",
       "42   0.033402  \n",
       "74   0.033402  \n",
       "106  0.033402  \n",
       "138  0.033402  \n",
       "10   0.032844  \n",
       "38   0.033839  \n",
       "70   0.033839  \n",
       "102  0.033839  \n",
       "134  0.033839  \n",
       "6    0.033281  \n",
       "43   0.037790  \n",
       "75   0.037790  \n",
       "107  0.037790  \n",
       "139  0.037790  \n",
       "11   0.037840  \n",
       "2    0.033432  \n",
       "34   0.034166  \n",
       "66   0.034166  \n",
       "98   0.034166  \n",
       "130  0.034166  \n",
       "39   0.040181  \n",
       "71   0.040181  \n",
       "103  0.040181  \n",
       "135  0.040181  \n",
       "7    0.040088  \n",
       "3    0.038427  \n",
       "35   0.038427  \n",
       "67   0.038427  \n",
       "99   0.038427  \n",
       "131  0.038427  \n",
       "\n",
       "[160 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.sort_values(by = ['Validation AUC', 'AUC Diff'], axis=0, ascending = [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameters:\n",
    "- depth: 1 / estimators: 100 / impurity decrease: 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc, train_auc, test_auc = crossvalidation(x_train, y_train, 5, depth=1, N=100, min_impurity_decrease=0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8208572981614708,\n",
       " 0.8208568853936266,\n",
       " 0.6446941940009061,\n",
       " 0.6249931059790161)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_acc), np.mean(test_acc), np.mean(train_auc), np.mean(test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heldout Test Set\n",
    "-- use 0.5 as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387096774193549"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=2, n_estimators=50, min_impurity_decrease=0.007, bootstrap=True, random_state=816).fit(x_train, y_train)\n",
    "heldout_test_acc = rf.score(x_test, y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6808226495726495"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = rf.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob)\n",
    "heldout_test_auc = auc(fpr, tpr)\n",
    "heldout_test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- use optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#optimal_index = np.argmin(np.sqrt(np.square(1-tpr) + np.square(fpr)))\n",
    "optimal_index = np.argmax(abs(tpr - fpr))\n",
    "optimal_threshold = thresholds[optimal_index]\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction = rf.predict_proba(x_test)[:,1]\n",
    "heldout_test_acc = np.mean((prediction > optimal_threshold) == y_test)\n",
    "heldout_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log model results to the model performance folder, as per standards\n",
    "path = \"C:\\\\Users\\\\binha\\\\Documents\\\\Duke\\\\Cynthia Research\\\\KY-analysis-mytrials\\\\broward\\\\broward models\\\\Baseline Model Results\\\\Without Minor Offenses\\\\Felony\\\\\"\n",
    "\n",
    "train_auc_mean, train_auc_std = np.mean(train_auc), np.std(train_auc)\n",
    "test_auc_mean, test_auc_std = np.mean(test_auc), np.std(test_auc)\n",
    "                   \n",
    "results = [\"RF\", train_auc_mean, train_auc_std, test_auc_mean, test_auc_std, heldout_test_auc, heldout_test_acc ]\n",
    "\n",
    "with open(path + 'Felony Summary.csv', 'a') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
