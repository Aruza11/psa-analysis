{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is now:  C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../../../')\n",
    "print(\"Current working directory is now: \", os.getcwd())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import utils.baseline_functions as base\n",
    "\n",
    "# restore saved variables\n",
    "%store -r summary_general_2_KY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_data.csv\")\n",
    "data = data.drop(['fta_risk_score_raw','nca_risk_score_raw','pvf_risk_score_raw', \n",
    "                  'fta_calc', 'nca_calc', 'pvf_calc'], axis=1)\n",
    "x = data.loc[:,:'current_violence']\n",
    "y = data['recid_two_year'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [6217]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [6237]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [6336]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [6331]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [6469]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:87: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  fnr = fn / (fn + tp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [6209]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [6223]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [6339]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [6315]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [6466]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:87: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  fnr = fn / (fn + tp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3312]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [3328]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3464]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3447]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3479]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:87: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  fnr = fn / (fn + tp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3569]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [3586]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [3730]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3682]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3680]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:87: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  fnr = fn / (fn + tp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [3865]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [3972]}\n",
      "get_disparity_predefined_group()\n",
      "model_id, score_thresholds 0 {'rank_abs': [4038]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [4040]}\n",
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: divide by zero encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id, score_thresholds 0 {'rank_abs': [4033]}\n",
      "get_disparity_predefined_group()\n",
      "Stored 'summary_general_2_KY' (dict)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:83: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ppv = tp / (tp + fp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:87: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  fnr = fn / (fn + tp)\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:96: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  ratio = fn / fp\n"
     ]
    }
   ],
   "source": [
    "#### Logistic\n",
    "c = [1e-4, 1e-3, 0.01, 0.1, 1]\n",
    "logistic_summary = base.Logistic(X=x,\n",
    "                                 Y=y,\n",
    "                                 C=c,\n",
    "                                 seed=816)\n",
    "\n",
    "#### Lasso\n",
    "c = [1e-4, 1e-3, 0.01, 0.1, 1]\n",
    "lasso_summary = base.Lasso(X=x,\n",
    "                           Y=y, \n",
    "                           C=c,\n",
    "                           seed=816)\n",
    "\n",
    "#### LinearSVM\n",
    "c = [1e-4, 1e-3, 0.01, 0.1, 1]\n",
    "svm_summary = base.LinearSVM(X=x,\n",
    "                             Y=y,\n",
    "                             C=c,\n",
    "                             seed=816)\n",
    "\n",
    "#### Random Forest\n",
    "n_estimators =  [50,100,150]\n",
    "depth = [8,9,10]\n",
    "rf_summary = base.RF(X=x,\n",
    "                     Y=y,\n",
    "                     depth=depth, \n",
    "                     estimators=n_estimators, \n",
    "                     seed=816)\n",
    "\n",
    "#### XGBoost\n",
    "learning_rate = [0.1]\n",
    "depth = [6,7]\n",
    "n_estimators = [50,100]\n",
    "xgb_summary = base.XGB(X=x,\n",
    "                       Y=y,\n",
    "                       learning_rate=learning_rate, \n",
    "                       depth=depth, \n",
    "                       estimators=n_estimators, \n",
    "                       seed=816)\n",
    "\n",
    "#### save results\n",
    "summary_general_2_KY = {\"Logistic\": logistic_summary,\n",
    "                        \"Lasso\": lasso_summary,\n",
    "                        \"LinearSVM\": svm_summary,\n",
    "                        \"RF\": rf_summary,\n",
    "                        \"XGBoost\": xgb_summary}\n",
    "%store summary_general_2_KY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Logistic', 0.7114573542079802, 0.0007953249451006616],\n",
       " ['Lasso', 0.7114429694349453, 0.0007497783830809679],\n",
       " ['LinearSVM', 0.7088828697367164, 0.0007277599176989779],\n",
       " ['RF', 0.7228134718451455, 0.02550733922218107],\n",
       " ['XGBoost', 0.7274021126020803, 0.024620690381961997]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "auc = [] ## for table writing -- the performance range \n",
    "for model_name, model_summary in summary_general_2_KY.items():\n",
    "    results.append([model_name, np.mean(model_summary['holdout_test_auc']), np.mean(model_summary['auc_diffs'])])\n",
    "    auc.append(np.mean(model_summary['holdout_test_auc']))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Logistic', [{'C': 0.1}, {'C': 1}, {'C': 1}, {'C': 0.1}, {'C': 0.1}]],\n",
       " ['Lasso', [{'C': 0.1}, {'C': 0.1}, {'C': 1}, {'C': 0.1}, {'C': 0.1}]],\n",
       " ['LinearSVM', [{'C': 0.1}, {'C': 0.01}, {'C': 1}, {'C': 0.1}, {'C': 0.1}]],\n",
       " ['RF',\n",
       "  [{'max_depth': 10, 'n_estimators': 150},\n",
       "   {'max_depth': 10, 'n_estimators': 150},\n",
       "   {'max_depth': 10, 'n_estimators': 150},\n",
       "   {'max_depth': 10, 'n_estimators': 150},\n",
       "   {'max_depth': 10, 'n_estimators': 150}]],\n",
       " ['XGBoost',\n",
       "  [{'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}]]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [[model_name, model_summary['best_param']] for model_name, model_summary in summary_general_2_KY.items()]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\binha\\\\Documents\\\\Duke\\\\Cynthia Research\\\\KY-analysis-mytrials\\\\KY Recidivism\\\\KY Results\\\\Baselines\\\\Two Year\\\\\"\n",
    "results = [[\"\", \"Logistic\", \"Lasso\", \"Linear SVM\", \"Random Forest\", \"XGBoost\", \"Performance Range\"],\n",
    "           [\"General\", np.str((round(np.mean(logistic_summary['holdout_test_auc']), 3))) + \" (\" + np.str(round(np.std(logistic_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(lasso_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(lasso_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(svm_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(svm_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(rf_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(rf_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(xgb_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(xgb_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            round(np.max(auc) - np.min(auc), 3)]]\n",
    "with open(path + 'Two Year Baseline Summary.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
