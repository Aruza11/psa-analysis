{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is now:  C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning:\n",
      "\n",
      "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../../../')\n",
    "print(\"Current working directory is now: \", os.getcwd())\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "import utils.interpretable_functions as interpret\n",
    "import utils.RiskSLIM as slim\n",
    "import utils.stumps as stumps\n",
    "import utils.fairness_functions as fairness\n",
    "from utils.load_settings import load_settings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from pprint import pprint\n",
    "from riskslim.helper_functions import load_data_from_csv, print_model\n",
    "\n",
    "# restore saved variables\n",
    "#%store -r summary_property6_KY_interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART & EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_data.csv\").sort_values('person_id')\n",
    "x = data.loc[:,:'current_violence20']\n",
    "y = data['property_six_month'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:43: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:43: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:43: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:43: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:43: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:43: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:43: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:43: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:43: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:43: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### CART\n",
    "depth = [5,6,7,8,9,10]\n",
    "cart_summary =interpret.CART(X=x,\n",
    "                         Y=y,\n",
    "                         depth=depth,\n",
    "                         seed=816)\n",
    "\n",
    "#### EBM\n",
    "estimators = [40]\n",
    "depth = [2]\n",
    "#learning_rate = [0.7]\n",
    "learning_rate = [0.1]\n",
    "ebm_summary = interpret.EBM(X=x,\n",
    "                       Y=y,\n",
    "                       learning_rate=learning_rate,\n",
    "                       depth=depth,\n",
    "                       estimators=estimators,\n",
    "                       seed =816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8191284612161555, 0.012104413959040428)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8308996066143655, 0.008448643949684009)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load whole data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_stumps.csv\").sort_values('person_id')\n",
    "original_data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_data.csv\").sort_values('person_id')\n",
    "original_data = original_data.loc[:, ['person_id', 'age_at_current_charge', 'p_charges']]\n",
    "data = pd.merge(original_data, data, on='person_id')\n",
    "X_stumps, Y_stumps = data.loc[:,:'current_violence201'], data['property_six_month'].values\n",
    "Y_stumps[Y_stumps == -1] = 0\n",
    "cols = X_stumps.columns[5:]\n",
    "\n",
    "## load train & test data\n",
    "train_stumps = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_train_stumps.csv\")\n",
    "test_stumps = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_test_stumps.csv\")\n",
    "X_train_stumps, Y_train_stumps = train_stumps.loc[:,:'current_violence201'], train_stumps['property_six_month'].values\n",
    "X_test_stumps, Y_test_stumps = test_stumps.loc[:,:'current_violence201'], test_stumps['property_six_month'].values\n",
    "Y_train_stumps[Y_train_stumps == -1] = 0\n",
    "Y_test_stumps[Y_test_stumps == -1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Stump Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_stump_model = stumps.stump_model(X_train_stumps, \n",
    "                                      Y_train_stumps, \n",
    "                                      X_test_stumps, \n",
    "                                      Y_test_stumps, \n",
    "                                      c=0.0015, \n",
    "                                      columns=cols, \n",
    "                                      seed=816)\n",
    "len(single_stump_model['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{{tabular}}{{|l|r|r|}} \\hline\n",
      "1. sex1 & 0.15719687206926514 & -... \\\\ \\hline\n",
      "2. age_at_current_charge19 & 0.020239865720874172 & +... \\\\ \\hline\n",
      "3. age_at_current_charge21 & 0.05522252637025812 & +... \\\\ \\hline\n",
      "4. age_at_current_charge35 & 0.19569676309972803 & +... \\\\ \\hline\n",
      "5. p_arrest2 & 0.6115438984043298 & +... \\\\ \\hline\n",
      "6. p_arrest3 & 0.30457909655491616 & +... \\\\ \\hline\n",
      "7. p_arrest4 & 0.23540741821708872 & +... \\\\ \\hline\n",
      "8. p_arrest5 & 0.06597751640048861 & +... \\\\ \\hline\n",
      "9. p_arrest6 & 0.11953516710997794 & +... \\\\ \\hline\n",
      "10. p_arrest7 & 0.0473126273251266 & +... \\\\ \\hline\n",
      "11. p_felony1 & 0.43617083492867254 & +... \\\\ \\hline\n",
      "12. p_misdemeanor1 & 0.30377872155790636 & -... \\\\ \\hline\n",
      "13. p_property1 & 1.1245633236132981 & +... \\\\ \\hline\n",
      "14. p_drug1 & 0.09152700038467995 & -... \\\\ \\hline\n",
      "15. ADE1 & 0.34755114253869324 & -... \\\\ \\hline\n",
      "16. p_pending_charge1 & 0.46677033149151304 & +... \\\\ \\hline\n",
      "17. p_probation1 & 0.10169275456518653 & +... \\\\ \\hline\n",
      "18. p_incarceration1 & 0.4069399721758447 & +... \\\\ \\hline\n",
      "19. current_pending_charge1 & 0.06491040076737263 & +... \\\\ \\hline\n",
      "20. Intercept & -1.442 & +... \\\\ \\hline\n",
      "\\textbf{ADD POINTS FROM ROWS 1 TO 20}  &  \\textbf{SCORE} & = ..... \\\\ \\hline\n",
      "\\multicolumn{{3}}{{l}}{{Pr(Y = 1) = exp(score/100) / (1 + exp(score/100))}} \\\\ \\hline\n"
     ]
    }
   ],
   "source": [
    "stumps.latex_stump_table(single_stump_model['coefs'], \n",
    "                   single_stump_model['features'], \n",
    "                   single_stump_model['intercept'], \n",
    "                   single_stump_model['dictionary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n",
      "C:\\Users\\binha\\Documents\\Duke\\Cynthia Research\\psa-analysis - test2\\utils\\fairness_functions.py:88: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in longlong_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stump_summary = stumps.stump_cv(X = X_stumps, \n",
    "                                Y = Y_stumps, \n",
    "                                columns=cols, \n",
    "                                c_grid={'C': [0.001, 0.0015]}, \n",
    "                                seed = 816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'C': 0.0015}, {'C': 0.0015}, {'C': 0.0015}, {'C': 0.0015}, {'C': 0.0015}],\n",
       " 0.8303545096854028,\n",
       " 0.0013552839542158245)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stump_summary['best_params'], np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RiskSLIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load whole data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_stumps.csv\").sort_values('person_id')\n",
    "original_data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_data.csv\")\n",
    "original_data = original_data.loc[:,['person_id', 'age_at_current_charge', 'p_charges']]\n",
    "\n",
    "## load train & test data\n",
    "train_data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_train_stumps.csv\")\n",
    "test_data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_test_stumps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_stump_model = stumps.stump_model(X_train_stumps, \n",
    "                                      Y_train_stumps, \n",
    "                                      X_test_stumps, \n",
    "                                      Y_test_stumps, \n",
    "                                      c=0.001, \n",
    "                                      columns=cols, \n",
    "                                      seed=816)\n",
    "len(best_stump_model['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = best_stump_model['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset features\n",
    "if 'sex1' in selected_features:\n",
    "    selected_features = ['property_six_month', 'person_id', 'screening_date', 'race'] + selected_features\n",
    "    indicator = 1\n",
    "else:\n",
    "    selected_features = ['property_six_month', 'person_id', 'screening_date', 'race', 'sex1'] + selected_features\n",
    "    indicator = 0\n",
    "\n",
    "sub_data = data[selected_features]\n",
    "sub_data = pd.merge(sub_data, original_data, on='person_id')\n",
    "sub_X, sub_Y = sub_data.iloc[:,1:], sub_data.iloc[:,0].values\n",
    "sub_X.insert(0, '(Intercept)', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "riskslim_summary = slim.risk_nested_cv(X=sub_X, \n",
    "                                       Y=sub_Y, \n",
    "                                       indicator = indicator,\n",
    "                                       y_label='property_six_month', \n",
    "                                       max_coef=5, \n",
    "                                       max_coef_number=5, \n",
    "                                       max_runtime=1000,\n",
    "                                       max_offset=100,\n",
    "                                       c=1e-6, \n",
    "                                       seed=816)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8054049844531537, 0.8046879840090856)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(riskslim_summary['validation_auc']), np.mean(riskslim_summary['test_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single RiskSLIM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"property_six_month\"] + best_stump_model['features']\n",
    "sub_train_data = train_data[selected_features]\n",
    "sub_test_data = test_data[selected_features]\n",
    "\n",
    "## split x \n",
    "sub_train_X = sub_train_data.iloc[:,1:]\n",
    "sub_train_X.insert(0, '(Intercept)', 1)\n",
    "cols = sub_train_X.columns.tolist()\n",
    "sub_train_X = sub_train_X.values\n",
    "sub_test_X = sub_test_data.iloc[:,1:].values\n",
    "\n",
    "## split y\n",
    "sub_train_Y = sub_train_data.iloc[:,0].values.reshape(-1,1)\n",
    "sub_test_Y = sub_test_data.iloc[:,0].values.reshape(-1,1)\n",
    "\n",
    "## sample weight\n",
    "sample_weights = np.repeat(1, len(sub_train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = {\n",
    "    'X': sub_train_X,\n",
    "    'Y': sub_train_Y,\n",
    "    'variable_names': cols,\n",
    "    'outcome_name': 'property_six_month',\n",
    "    'sample_weights': sample_weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting c0 = 0.0 to ensure that intercept is not penalized\n",
      "11/09/19 @ 12:10 PM | 213 rows in lookup table\n",
      "11/09/19 @ 12:10 PM | ------------------------------------------------------------\n",
      "11/09/19 @ 12:10 PM | runnning initialization procedure\n",
      "11/09/19 @ 12:10 PM | ------------------------------------------------------------\n",
      "11/09/19 @ 12:10 PM | CPA produced 2 cuts\n",
      "11/09/19 @ 12:10 PM | running naive rounding on 5 solutions\n",
      "11/09/19 @ 12:10 PM | best objective value: 0.4182\n",
      "11/09/19 @ 12:10 PM | rounding produced 5 integer solutions\n",
      "11/09/19 @ 12:10 PM | best objective value is 0.3930\n",
      "11/09/19 @ 12:10 PM | running sequential rounding on 5 solutions\n",
      "11/09/19 @ 12:10 PM | best objective value: 0.4182\n",
      "11/09/19 @ 12:10 PM | sequential rounding produced 4 integer solutions\n",
      "11/09/19 @ 12:10 PM | best objective value: 0.2159\n",
      "11/09/19 @ 12:10 PM | polishing 9 solutions\n",
      "11/09/19 @ 12:10 PM | best objective value: 0.2159\n",
      "11/09/19 @ 12:10 PM | polishing produced 4 integer solutions\n",
      "11/09/19 @ 12:10 PM | initialization produced 12 feasible solutions\n",
      "11/09/19 @ 12:10 PM | best objective value: 0.0965\n",
      "11/09/19 @ 12:10 PM | ------------------------------------------------------------\n",
      "11/09/19 @ 12:10 PM | completed initialization procedure\n",
      "11/09/19 @ 12:10 PM | ------------------------------------------------------------\n",
      "11/09/19 @ 12:10 PM | 213 rows in lookup table\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_Threads                                 1\n",
      "CPXPARAM_Parallel                                1\n",
      "CPXPARAM_RandomSeed                              0\n",
      "CPXPARAM_TimeLimit                               1000\n",
      "CPXPARAM_MIP_Tolerances_LowerCutoff              0.087444685910174971\n",
      "CPXPARAM_MIP_Tolerances_UpperCutoff              0.09647510465775154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Control callbacks may disable some MIP features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazy constraint(s) or lazy constraint callback is present.\n",
      "    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.\n",
      "    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.\n",
      "         Disabling repeat represolve because of lazy constraint/incumbent callback.\n",
      "11/09/19 @ 12:10 PM | adding 387 initial cuts\n",
      "1 of 1 MIP starts provided solutions.\n",
      "MIP start 'mip_start_0' defined initial solution with objective 0.0965.\n",
      "Tried aggregator 1 time.\n",
      "Reduced MIP has 34 rows, 36 columns, and 99 nonzeros.\n",
      "Reduced MIP has 16 binaries, 18 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.02 sec. (0.05 ticks)\n",
      "Probing time = 0.00 sec. (0.01 ticks)\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: traditional branch-and-cut.\n",
      "Parallel mode: none, using 1 thread.\n",
      "Root relaxation solution time = 0.00 sec. (0.04 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth\n",
      "\n",
      "*     0+    0                            0.0965        0.0874             9.37%\n",
      "      0     0        0.0874     1        0.0965        0.0874       17    9.36%\n",
      "      0     0        0.0874     1        0.0965      Fract: 1       19    9.36%\n",
      "      0     0        0.0874     2        0.0965      Fract: 1       21    9.36%\n",
      "      0     2        0.0874     2        0.0965        0.0874       21    9.36%                        0             0\n",
      "Elapsed time = 0.16 sec. (2.01 ticks, tree = 0.01 MB, solutions = 1)\n",
      "*   220   138      integral     0        0.0957        0.0874      963    8.67%\n",
      "*   250+  150                            0.0952        0.0874             8.19%\n",
      "*   535   277      integral     0        0.0940        0.0874     2514    6.94%\n",
      "*   970   453      integral     0        0.0933        0.0874     5127    6.28%\n",
      "   2304  1023        0.0874     9        0.0933        0.0874    13494    6.28%           rho_8 D   2304   2303      7\n",
      "   3651  1455        0.0913     6        0.0933        0.0874    24054    6.28%          rho_14 D   3651   3650     27\n",
      "   4715  1835        0.0918    14        0.0933        0.0874    33007    6.28%          rho_13 D   4715   4714     18\n",
      "   5654  2120        0.0919     7        0.0933        0.0874    40257    6.28%          rho_10 U   5654   5653     28\n",
      "   6630  2550        0.0905    19        0.0933        0.0874    46707    6.28%           rho_8 D   6630   6629     14\n",
      "*  6936  2509      integral     0        0.0926        0.0874    49419    5.55%\n",
      "   7460  2683        0.0888    17        0.0926        0.0874    52963    5.55%           rho_9 D   7460   7459     15\n",
      "   8126  2888        0.0913    11        0.0926        0.0874    58896    5.55%         alpha_8 N   8126   8125     22\n",
      "*  8440  2513      integral     0        0.0914        0.0874    60531    4.31%\n",
      "*  8450+ 2252                            0.0908        0.0874             3.68%\n",
      "   8766  2357        0.0888     7        0.0908        0.0874    62567    3.68%        alpha_12 D   8766   8765     35\n",
      "*  9363  2230      integral     0        0.0903        0.0874    67191    3.13%\n",
      "   9370  2230        0.0874     8        0.0903        0.0874    67228    3.13%        alpha_13 D   9370   9369     23\n",
      "  11474  2679        cutoff              0.0903        0.0874    86395    3.13%         alpha_9 D  11474   1386     13\n",
      "Elapsed time = 7.33 sec. (3102.81 ticks, tree = 0.74 MB, solutions = 9)\n",
      "  13720  3337        cutoff              0.0903        0.0874   104935    3.13%          rho_10 U  13720  13719     22\n",
      "  15897  3885        0.0879     7        0.0903        0.0874   124109    3.13%          rho_14 D  15897  15895     37\n",
      "  18124  4499        cutoff              0.0903        0.0874   142421    3.13%          rho_13 N  18124  18122     30\n",
      "  20515  5344        cutoff              0.0903        0.0874   159365    3.13%          rho_15 U  20515  20513     16\n",
      "  22578  5901        cutoff              0.0903        0.0874   177163    3.13%          rho_12 D  22578  10735     24\n",
      "  24580  6458        0.0888    11        0.0903        0.0874   195044    3.13%          rho_15 D  24580  24578     28\n",
      "  26569  7052        0.0874     9        0.0903        0.0874   212300    3.13%          rho_16 D  26569  26568     16\n",
      "  28745  7669        cutoff              0.0903        0.0874   227927    3.13%          rho_10 U  28745  28744     15\n",
      "  30918  8330        0.0874    14        0.0903        0.0874   242916    3.13%           rho_1 D  30918  30916     12\n",
      "  32776  8854        0.0893    10        0.0903        0.0874   260075    3.13%           rho_1 D  32776  32774     25\n",
      "Elapsed time = 18.64 sec. (12642.13 ticks, tree = 2.71 MB, solutions = 9)\n",
      "  34815  9481        0.0874    12        0.0903        0.0874   275470    3.13%           rho_2 D  34815  34777     15\n",
      "  36767 10005        0.0899     1        0.0903        0.0874   290840    3.13%          rho_14 D  36767  36765     32\n",
      "  38616 10562        0.0878    21        0.0903        0.0874   305826    3.13%           rho_3 U  38616  38450     10\n",
      "  40272 11047        0.0880    16        0.0903        0.0874   321741    3.13%           rho_3 U  40272  40271     20\n",
      "  42091 11761        cutoff              0.0903        0.0874   336401    3.13%          rho_11 D  42091  42090     21\n",
      "  43716 12219        cutoff              0.0903        0.0874   352345    3.13%           rho_3 U  43716  43715     25\n",
      "  45553 12863        0.0902     8        0.0903        0.0874   365732    3.13%          rho_10 U  45553  45552     32\n",
      "  47389 13598        0.0895    13        0.0903        0.0874   377949    3.13%          rho_15 N  47389  47388     20\n",
      "  48863 14092        0.0874    11        0.0903        0.0874   391935    3.13%          rho_10 U  48863  48850     20\n",
      "  50525 14806        0.0879    15        0.0903        0.0874   404180    3.13%          rho_12 D  50525  50487     21\n",
      "Elapsed time = 29.72 sec. (22186.00 ticks, tree = 4.25 MB, solutions = 9)\n",
      "  51996 15346        cutoff              0.0903        0.0874   417262    3.13%          rho_16 D  51996  51994     24\n",
      "  53428 15813        0.0877    15        0.0903        0.0874   430355    3.13%          rho_15 D  53428  53427     19\n",
      "  54771 16300        0.0883    11        0.0903        0.0874   443608    3.13%          rho_13 N  54771  54770     19\n",
      "  56056 16696        0.0882    11        0.0903        0.0875   456790    3.12%        alpha_10 N  56056  40225     21\n",
      "  57569 16728        0.0896    12        0.0903        0.0876   467711    3.01%           rho_3 D  57569  57567     21\n",
      "  59114 16815        0.0895    11        0.0903        0.0876   478054    2.94%           rho_0 N  59114  48081     25\n",
      "  60626 16911        0.0895    16        0.0903        0.0877   488556    2.88%          rho_11 N  60626  60625     26\n",
      "  62160 16951        cutoff              0.0903        0.0877   498585    2.82%           rho_1 U  62160  46692     27\n",
      "  63723 17071        0.0884    14        0.0903        0.0878   508362    2.76%           rho_8 U  63723  63720     30\n",
      "  65234 17079        cutoff              0.0903        0.0878   518343    2.71%           rho_8 D  65234  65233     25\n",
      "Elapsed time = 38.61 sec. (31729.57 ticks, tree = 5.63 MB, solutions = 9)\n",
      "  66697 16987        0.0882    11        0.0903        0.0879   528252    2.65%          rho_13 U  66697  49051     29\n",
      "  68152 16914        cutoff              0.0903        0.0879   537913    2.58%         alpha_5 U  68152  68150     36\n",
      "  69590 16796        0.0894    16        0.0903        0.0880   547349    2.52%           rho_9 U  69590  60447     25\n",
      "  71028 16722        0.0901     3        0.0903        0.0880   556723    2.47%           rho_7 U  71028  71026     38\n",
      "  72473 16570        cutoff              0.0903        0.0881   566128    2.41%          rho_12 D  72473  34532     24\n",
      "  73895 16387        cutoff              0.0903        0.0882   575116    2.34%          rho_15 D  73895  27169     23\n",
      "  75318 16190        cutoff              0.0903        0.0882   584101    2.28%          rho_13 U  75318  45812     32\n",
      "  76693 16014        cutoff              0.0903        0.0883   593145    2.21%        alpha_16 U  76693  76691     25\n",
      "  78066 15781        0.0892    13        0.0903        0.0883   601957    2.15%          rho_12 U  78066  78064     18\n",
      "  79427 15480        0.0896    15        0.0903        0.0884   610439    2.08%           rho_9 N  79427  79425     20\n",
      "Elapsed time = 47.09 sec. (41270.35 ticks, tree = 5.34 MB, solutions = 9)\n",
      "  80802 15211        cutoff              0.0903        0.0885   619045    2.01%           rho_9 U  80802  39882     18\n",
      "  82138 14908        0.0886    14        0.0903        0.0885   627332    1.94%           rho_3 U  82138  74374     28\n",
      "  83503 14651        0.0896    13        0.0903        0.0886   635634    1.87%          rho_16 U  83503  83501     27\n",
      "  84875 14277        0.0895     7        0.0903        0.0887   644190    1.79%           rho_5 D  84875  84874     33\n",
      "  86324 13941        0.0903    13        0.0903        0.0887   652728    1.72%          rho_16 D  86324  86322     26\n",
      "  87763 13543        0.0900    11        0.0903        0.0888   660651    1.65%           rho_4 U  87763  87762     23\n",
      "  89194 13099        cutoff              0.0903        0.0889   668575    1.57%          rho_16 U  89194  89192     30\n",
      "  90619 12628        cutoff              0.0903        0.0889   676671    1.50%           rho_4 D  90619  50357     30\n",
      "  92066 12205        cutoff              0.0903        0.0890   684141    1.43%          rho_15 D  92066  92065     39\n",
      "  93451 11641        0.0894     5        0.0903        0.0890   691641    1.36%        alpha_14 D  93451  81666     34\n",
      "Elapsed time = 55.09 sec. (50810.56 ticks, tree = 4.44 MB, solutions = 9)\n",
      "  94857 11147        cutoff              0.0903        0.0891   699083    1.28%          rho_16 U  94857  94855     32\n",
      "  96262 10590        cutoff              0.0903        0.0892   706425    1.21%          rho_15 D  96262  96261     22\n",
      "  97659  9994        cutoff              0.0903        0.0892   713326    1.14%           rho_9 U  97659  60756     29\n",
      "  99064  9383        cutoff              0.0903        0.0893   719921    1.06%          rho_11 U  99064  77911     32\n",
      " 100503  8741        0.0898     3        0.0903        0.0894   726464    0.98%         alpha_6 U 100503 100502     36\n",
      " 101928  8105        cutoff              0.0903        0.0895   732933    0.91%           rho_3 D 101928  45216     25\n",
      " 103403  7448        0.0902    10        0.0903        0.0895   739178    0.83%          rho_13 N 103403 103401     26\n",
      " 104820  6685        cutoff              0.0903        0.0896   745173    0.75%           rho_5 D 104820 104819     30\n",
      " 106248  5877        cutoff              0.0903        0.0897   750815    0.66%           rho_5 U 106248 106246     43\n",
      " 107745  5092        0.0902    10        0.0903        0.0897   756438    0.59%          rho_13 N 107745 107743     21\n",
      "Elapsed time = 62.06 sec. (60351.03 ticks, tree = 2.73 MB, solutions = 9)\n",
      " 109222  4209        cutoff              0.0903        0.0898   761600    0.50%          rho_13 U 109222  10561     28\n",
      " 110710  3295        cutoff              0.0903        0.0899   766472    0.40%           rho_9 U 110710  14483     26\n",
      " 112113  2230        0.0900     1        0.0903        0.0900   771047    0.28%         alpha_6 U 112113 106826     37\n",
      " 113591  1105        0.0901     5        0.0903        0.0901   775056    0.16%           rho_5 U 113591  96986     25\n",
      "\n",
      "User cuts applied:  1062\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    0.16 sec. (2.06 ticks)\n",
      "Sequential b&c:\n",
      "  Real time             =   64.78 sec. (65037.12 ticks)\n",
      "                          ------------\n",
      "Total (root+branch&cut) =   64.94 sec. (65039.18 ticks)\n",
      "+----------------------------------------------+------------------+-----------+\n",
      "| Pr(Y = +1) = 1.0/(1.0 + exp(-(-6 + score))   |                  |           |\n",
      "| ============================================ | ================ | ========= |\n",
      "| p_arrest2                                    |         1 points |   + ..... |\n",
      "| p_felony1                                    |         1 points |   + ..... |\n",
      "| p_property1                                  |         1 points |   + ..... |\n",
      "| p_pending_charge1                            |         1 points |   + ..... |\n",
      "| ============================================ | ================ | ========= |\n",
      "| ADD POINTS FROM ROWS 1 to 4                  |            SCORE |   = ..... |\n",
      "+----------------------------------------------+------------------+-----------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prettytable.PrettyTable at 0x244985ac088>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info, mip_info, lcpa_info = slim.risk_slim(new_train_data, \n",
    "                                                 max_coefficient=5, \n",
    "                                                 max_L0_value=5, \n",
    "                                                 c0_value=1e-6, \n",
    "                                                 max_offset=100, \n",
    "                                                 max_runtime=1000)\n",
    "print_model(model_info['solution'], new_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_X = sub_train_X[:,1:]\n",
    "sub_train_Y[sub_train_Y == -1] = 0\n",
    "sub_test_Y[sub_test_Y == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.805136752904265"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(sub_train_Y, slim.riskslim_prediction(sub_train_X, np.array(cols), model_info).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115329314182014"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(sub_test_Y, slim.riskslim_prediction(sub_test_X, np.array(cols), model_info).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arnold PSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data\n",
    "data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_data.csv\").sort_values('person_id')\n",
    "settings = load_settings()\n",
    "for decoder_name, decoder_dict in settings['decoders'].items():\n",
    "    data = data.replace({decoder_name: decoder_dict})  \n",
    "    \n",
    "# compute scaled arnold scores\n",
    "for score in ['arnold_nca' , 'arnold_nvca', 'arnold_fta']:\n",
    "    data[score] = data[score + \"_raw\"]\n",
    "    data = data.replace({score: settings[score + '_scaler'] })\n",
    "    if score != 'arnold_nvca':\n",
    "        data[score] = data[score].astype(int)\n",
    "X_arnold = data.loc[:,['arnold_nca', 'sex', 'race', 'person_id', 'screening_date', 'age_at_current_charge', 'p_charges']]\n",
    "Y_arnold = data['property_six_month'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up cross validation\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=816)\n",
    "arnold_auc = []\n",
    "race_auc = []\n",
    "condition_pn = []\n",
    "no_condition_pn = []\n",
    "\n",
    "i = 0\n",
    "for train, test in cv.split(X_arnold, Y_arnold):\n",
    "    \n",
    "    train_x, train_y = X_arnold.iloc[train], Y_arnold[train]\n",
    "    test_x, test_y = X_arnold.iloc[test], Y_arnold[test]\n",
    "    holdout_with_attrs = test_x.copy()\n",
    "    \n",
    "    ################################\n",
    "    ## arnold_auc\n",
    "    arnold_auc.append(roc_auc_score(test_y, test_x['arnold_nca'].values))\n",
    "    \n",
    "    ################################\n",
    "    ## race_auc\n",
    "    try:\n",
    "        arnold_race_auc = fairness.fairness_in_auc(df = holdout_with_attrs,\n",
    "                                                   probs = test_x['arnold_nca'],\n",
    "                                                   labels = test_y)\n",
    "        arnold_race_auc_final = arnold_race_auc.assign(fold_num = [i]*arnold_race_auc['Attribute'].count())\n",
    "        race_auc.append(arnold_race_auc_final)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ################################\n",
    "    ## condition pn\n",
    "    arnold_condition_pn = fairness.conditional_balance_positive_negative(df = holdout_with_attrs,\n",
    "                                                                         probs = test_x['arnold_nca'],\n",
    "                                                                         labels = test_y)\n",
    "    arnold_condition_pn_final = arnold_condition_pn.assign(fold_num = [i]*arnold_condition_pn['Attribute'].count())\n",
    "    condition_pn.append(arnold_condition_pn_final)\n",
    "    \n",
    "    ################################\n",
    "    ## no condition pn\n",
    "    arnold_no_condition_pn = fairness.balance_positive_negative(df = holdout_with_attrs,\n",
    "                                                                probs = test_x['arnold_nca'],\n",
    "                                                                labels = test_y)\n",
    "    arnold_no_condition_pn_final = arnold_no_condition_pn.assign(fold_num = [i]*arnold_no_condition_pn['Attribute'].count())\n",
    "    no_condition_pn.append(arnold_no_condition_pn_final)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "## race_auc\n",
    "arnold_race_auc = []\n",
    "try:\n",
    "    arnold_race_auc = pd.concat(race_auc, ignore_index=True)\n",
    "    arnold_race_auc.sort_values([\"fold_num\", \"Attribute\"], inplace=True)\n",
    "    arnold_race_auc = arnold_race_auc.reset_index(drop=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "## condition_pn\n",
    "arnold_condition_pn = pd.concat(condition_pn, ignore_index=True)\n",
    "arnold_condition_pn.sort_values([\"fold_num\", \"Attribute\"], inplace=True)\n",
    "arnold_condition_pn = arnold_condition_pn.reset_index(drop=True)\n",
    "\n",
    "## no_condition_pn\n",
    "arnold_no_condition_pn = pd.concat(no_condition_pn, ignore_index=True)\n",
    "arnold_no_condition_pn.sort_values([\"fold_num\", \"Attribute\"], inplace=True)\n",
    "arnold_no_condition_pn = arnold_no_condition_pn.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Arnold PSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data\n",
    "test_data = pd.read_csv(\"~/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY data/kentucky_test.csv\").sort_values('person_id')\n",
    "settings = load_settings()\n",
    "for decoder_name, decoder_dict in settings['decoders'].items():\n",
    "    test_data = test_data.replace({decoder_name: decoder_dict})  \n",
    "    \n",
    "# compute scaled arnold scores\n",
    "for score in ['arnold_nca' , 'arnold_nvca', 'arnold_fta']:\n",
    "    test_data[score] = test_data[score + \"_raw\"]\n",
    "    test_data = test_data.replace({score: settings[score + '_scaler'] })\n",
    "    if score != 'arnold_nvca':\n",
    "        test_data[score] = test_data[score].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7599704104630635"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = test_data['arnold_nca'].values\n",
    "Y = test_data['property_six_month'].values\n",
    "roc_auc_score(Y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'summary_property6_KY_interpret' (dict)\n"
     ]
    }
   ],
   "source": [
    "#### save results\n",
    "summary_property6_KY_interpret = {\"CART\": cart_summary,\n",
    "                                 \"EBM\": ebm_summary, \n",
    "                                 'Lasso Stumps': stump_summary, \n",
    "                                 'RiskSLIM': riskslim_summary,  \n",
    "                                 'Arnold PSA': arnold_auc}\n",
    "%store summary_property6_KY_interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CART', 0.8168869167235389, 0.03250650214089901],\n",
       " ['EBM', 0.8003545924970673, 0.0077845729654996585],\n",
       " ['Lasso Stumps', 0.8303545096854028, 0.0013552839542158245],\n",
       " ['RiskSLIM', 0.8046879840090856],\n",
       " ['Arnold PSA', 0.735]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [[\"CART\", np.mean(cart_summary['holdout_test_auc']), np.mean(cart_summary['auc_diffs'])],\n",
    "           [\"EBM\", np.mean(ebm_summary['holdout_test_auc']), np.mean(ebm_summary['auc_diffs'])], \n",
    "           [\"Lasso Stumps\", np.mean(stump_summary['holdout_test_auc']), np.mean(stump_summary['auc_diffs'])],\n",
    "           ['RiskSLIM', np.mean(riskslim_summary['test_auc'])],\n",
    "           ['Arnold PSA', round(np.mean(arnold_auc), 3)]]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = [np.mean(cart_summary['holdout_test_auc']), \n",
    "       np.mean(ebm_summary['holdout_test_auc']), \n",
    "       np.mean(stump_summary['holdout_test_auc']), \n",
    "       np.mean(riskslim_summary['test_auc'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/KY Results/Models/Six Month/\"\n",
    "results = [[\"Property\", np.str((round(np.mean(cart_summary['holdout_test_auc']), 3))) + \" (\" + np.str(round(np.std(cart_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(ebm_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(ebm_summary['holdout_test_auc']), 3)) + \")\", \n",
    "            np.str(round(np.mean(stump_summary['holdout_test_auc']),3)) + \" (\" + np.str(round(np.std(stump_summary['holdout_test_auc']), 3)) + \")\",             \n",
    "            np.str(round(np.mean(riskslim_summary['test_auc']),3)) + \" (\" + np.str(round(np.std(riskslim_summary['test_auc']), 3)) + \")\", \n",
    "            round(np.max(auc) - np.min(auc), 3),\n",
    "            np.str(round(np.mean(arnold_auc), 3)) + \" (\" + np.str(round(np.std(arnold_auc),3)) + \")\"]]\n",
    "with open(path + 'Interpretable Models Summary.csv', 'a') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_confusion = cart_summary['confusion_matrix_stats']\n",
    "ebm_confusion = ebm_summary['confusion_matrix_stats']\n",
    "riskslim_confusion = riskslim_summary['confusion_matrix_stats']\n",
    "stumps_confusion = stump_summary['confusion_matrix_stats']\n",
    "\n",
    "cart_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/confusion/six-month/property/cart_confusion.csv', index=None,header=True)\n",
    "ebm_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/confusion/six-month/property/ebm_confusion.csv', index=None,header=True)\n",
    "riskslim_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/confusion/six-month/property/riskslim_confusion.csv', index=None,header=True)\n",
    "stumps_confusion.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/confusion/six-month/property/stumps_confusion.csv', index=None,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_calibration = cart_summary['calibration_stats']\n",
    "ebm_calibration = ebm_summary['calibration_stats']\n",
    "riskslim_calibration = riskslim_summary['calibration_stats']\n",
    "stumps_calibration = stump_summary['calibration_stats']\n",
    "\n",
    "cart_calibration.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/calibration/six-month/property/cart_calibration.csv', index=None,header=True)\n",
    "ebm_calibration.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/calibration/six-month/property/ebm_calibration.csv', index=None,header=True)\n",
    "riskslim_calibration.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/calibration/six-month/property/riskslim_calibration.csv', index=None,header=True)\n",
    "stumps_calibration.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/calibration/six-month/property/stumps_calibration.csv', index=None,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### race auc matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_race_auc = cart_summary['race_auc']\n",
    "ebm_race_auc = ebm_summary['race_auc']\n",
    "riskslim_race_auc = riskslim_summary['race_auc']\n",
    "stumps_race_auc = stump_summary['race_auc']\n",
    "\n",
    "cart_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/race-auc/six-month/property/cart_race_auc.csv', index=None,header=True)\n",
    "ebm_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/race-auc/six-month/property/ebm_race_auc.csv', index=None,header=True)\n",
    "riskslim_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/race-auc/six-month/property/riskslim_race_auc.csv', index=None,header=True)\n",
    "stumps_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/race-auc/six-month/property/stumps_race_auc.csv', index=None,header=True)\n",
    "arnold_race_auc.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/race-auc/six-month/property/arnold_race_auc.csv', index=None,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### condition pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_condition_pn = cart_summary['condition_pn']\n",
    "ebm_condition_pn = ebm_summary['condition_pn']\n",
    "riskslim_condition_pn = riskslim_summary['condition_pn']\n",
    "stumps_condition_pn = stump_summary['condition_pn']\n",
    "\n",
    "cart_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/condition-pn/six-month/property/cart_condition_pn.csv', index=None,header=True)\n",
    "ebm_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/condition-pn/six-month/property/ebm_condition_pn.csv', index=None,header=True)\n",
    "riskslim_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/condition-pn/six-month/property/riskslim_condition_pn.csv', index=None,header=True)\n",
    "stumps_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/condition-pn/six-month/property/stumps_condition_pn.csv', index=None,header=True)\n",
    "arnold_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/condition-pn/six-month/property/arnold_conditon_pn.csv', index=None,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no condition pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_no_condition_pn = cart_summary['no_condition_pn']\n",
    "ebm_no_condition_pn = ebm_summary['no_condition_pn']\n",
    "riskslim_no_condition_pn = riskslim_summary['no_condition_pn']\n",
    "stumps_no_condition_pn = stump_summary['no_condition_pn']\n",
    "\n",
    "cart_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/no-condition-pn/six-month/property/cart_no_condition_pn.csv', index=None,header=True)\n",
    "ebm_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/no-condition-pn/six-month/property/ebm_no_condition_pn.csv', index=None,header=True)\n",
    "riskslim_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/no-condition-pn/six-month/property/riskslim_no_condition_pn.csv', index=None,header=True)\n",
    "stumps_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/no-condition-pn/six-month/property/stumps_no_condition_pn.csv', index=None,header=True)\n",
    "arnold_no_condition_pn.to_csv(r'C:/Users/binha/Documents/Duke/Cynthia Research/KY-analysis-mytrials/KY Recidivism/no-condition-pn/six-month/property/arnold_no_conditon_pn.csv', index=None,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
