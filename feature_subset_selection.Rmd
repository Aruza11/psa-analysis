---
title: "feature_subset_selection"
author: 
date: 1/14/2019
output: html_document
---

Here we use xgBoost to evaluate feature subset selections (wrapper method)

```{r include = FALSE}
library(tidyverse)
library(magrittr)
library(pROC)

library(xgboost)
source('util.R')
```

Load in train/test datasets computed/saved in predict_recidivism.Rmd
```{r}
train <- readRDS(file="train.rds")
test <- readRDS(file="test.rds")
```


```{r}
# Specify each parameter as a single value or a vector of values
# Each combination will be tested
# param_xgb <- list(
#   objective = "binary:logistic",
#   eta = c(.05,.1),
#   gamma = c(.5),
#   max_depth = c(2),
#   min_child_weight = c(5),
#   subsample = c(1),
#   colsample_bytree = c(1),
#   early_stopping_rounds=50
# )

param_xgb <- list(
  objective = "binary:logistic",
  eta = c(.1),
  gamma = c(.5),
  max_depth = c(2),
  min_child_weight = c(5),
  subsample = c(1),
  colsample_bytree = c(1),
  early_stopping_rounds=50
)

param_xgb = expand.grid(param_xgb) # Each row is a set of parameters to be cross validated

# Only one value for each of these parameters is allowed
setup_xgb = list(
  nrounds=10000,
  nfold=5
)
```



##Baseline: all features 
```{r}
train_baseline = xgb.DMatrix(
  "data" = train %>% select(-recid_use) %>% as.matrix(),
  "label" = train %>% select(recid_use) %>% as.matrix()
)

set.seed(2812)
out_baseline = fit_xgb_auc(train_baseline, test, param_xgb, setup_xgb)
out_baseline$performance
plot(out_baseline$roc,
     print.auc = T,
     main = paste("XGBoost ROC curve using N = ", nrow(test), " , baseline"),
     legacy.axes = T,
     grid =T )
```


```{r}
names(train)
```

Subsets
```{r}
#seeds 
seeds <- sample.int(10000, n_subsets)

            #features which capture petty offenses (reasoning: easy to recidivate)
subset <-c( #c("p_current_age","p_charge", "p_traffic",  "p_drug", 
             #"p_trespass","p_stealing", "p_misdemassault_arrest"),
            #sanity check
            # c("p_current_age"),
            #arnold var
            # c("p_current_age","p_prison","p_jail30","fail_appear_two_yr", "fail_appear_two_plus","current_violent","current_violent20",  "pending_charge", "prior_conviction_F", "prior_conviction_M", "violent_conviction", "total_convictions"),
            
            c("p_current_age", "p_property","prior_conviction_M", "p_arrest" ), 
            
            #all features
            c("p_current_age","p_age_first_offense","p_charge","p_jail30","p_prison", "p_probation","p_juv_fel_count", "p_felprop_violarrest", "p_murder_arrest","p_felassault_arrest","p_misdemassault_arrest","p_famviol_arrest","p_sex_arrest","p_weapons_arrest","fail_appear_two_yr","fail_appear_two_plus","current_violent","current_violent20","pending_charge","prior_conviction_F","prior_conviction_M","violent_conviction","total_convictions","p_arrest","p_property","p_traffic","p_drug","p_dui","p_domestic","p_stalking","p_voyeurism","p_fraud","p_stealing","p_trespass")
            )
n_subsets <- 


```


```{r}
run_xgb <- function(subset_list, train, test, param, setup, seed){
  train_subset = xgb.DMatrix(
    "data" = train %>% 
              select(-recid_use)%>% #del label
              select(subset_list) %>%
              as.matrix(),
    "label" = train %>% select(recid_use) %>% as.matrix()
  )
  
  test_subset = test %>% select(subset_list, recid_use)
  # print(names(test_subset))
  set.seed(seed)
  out = fit_xgb_auc(train_subset, test_subset, param, setup)
  return(out)
}

```

```{r}

# train_sub = train[1:100,]
# test_sub = test[1:10,]
for (i in c(1:n_subsets)){
  out = run_xgb(subset[i], train, test, param_xgb, setup_xgb, seeds[i])
  print(out$performance)
  plot(out$roc,
       print.auc = T,
       main = paste("XGBoost ROC curve using N = ", nrow(test), " , Subset ", i),
       legacy.axes = T,
       grid =T )
}
```





